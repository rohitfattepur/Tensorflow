{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SO_Home.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SKWwG5iU_Bt2",
        "iutilLUp9AsZ",
        "sjwfJo493IAV",
        "DEyyro-xMnwS",
        "5f2C617e-BFu",
        "g_jgkP3sdF4r",
        "_Dqzlnvmwrr3",
        "q_FhnDE9wzlF",
        "eVLkvAkPatDD",
        "pb4cJKwt2eIK",
        "z_5aAAf82LIE",
        "Iah4GD0dbRBW",
        "-1vXRhpz0mou",
        "Mk6am3SF58J6",
        "2Ip33pHpNOVU",
        "SVB8mbWfNCIF",
        "4s_VHK_PNWCO",
        "Wjw2f-GyThTk",
        "hzPFRXDg4Di0",
        "6kEKp1C76nw6",
        "cWYVNZs-6ujU",
        "0fARWvSOS0xo",
        "sUvdRR4EyO6-",
        "nj1v2ptOIvyc",
        "ssuiDS6xJxkn",
        "nvI2gcXuUZ_A",
        "nyAx1Zp1Us4F",
        "4ecy2vH3X6gU",
        "H0zJAoNLU7pu",
        "5u1qthgoVMUL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKWwG5iU_Bt2",
        "colab_type": "text"
      },
      "source": [
        "# Unwanted Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWPhM3KGN4TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxQKG938OI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZcVrTbBOOA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n1sw4uUOUq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCQEsTdrOaj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#for epoch in range(19, 21):\n",
        "train(model, device, train_loader, optimizer, epoch = 20)\n",
        "test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24tVvrWxp2kU",
        "colab_type": "code",
        "outputId": "c4f7d1fa-4e6b-46ca-b471-7255708f62ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "print(\"Tensorflow Version:\",tf.__version__)\n",
        "  \n",
        "model = MobileNetV2(input_shape=[128, 128, 3], include_top=False) #or whatever model\n",
        "\n",
        "print(\"Weights of the Layer\",model.trainable_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 1.15.0\n",
            "Weights of the Layer [<tf.Variable 'Conv1_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>, <tf.Variable 'bn_Conv1_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'bn_Conv1_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_1/depthwise_kernel:0' shape=(3, 3, 32, 1) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_project_1/kernel:0' shape=(1, 1, 32, 16) dtype=float32>, <tf.Variable 'expanded_conv_project_BN_1/gamma:0' shape=(16,) dtype=float32>, <tf.Variable 'expanded_conv_project_BN_1/beta:0' shape=(16,) dtype=float32>, <tf.Variable 'block_1_expand_1/kernel:0' shape=(1, 1, 16, 96) dtype=float32>, <tf.Variable 'block_1_expand_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_expand_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_depthwise_1/depthwise_kernel:0' shape=(3, 3, 96, 1) dtype=float32>, <tf.Variable 'block_1_depthwise_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_depthwise_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_project_1/kernel:0' shape=(1, 1, 96, 24) dtype=float32>, <tf.Variable 'block_1_project_BN_1/gamma:0' shape=(24,) dtype=float32>, <tf.Variable 'block_1_project_BN_1/beta:0' shape=(24,) dtype=float32>, <tf.Variable 'block_2_expand_1/kernel:0' shape=(1, 1, 24, 144) dtype=float32>, <tf.Variable 'block_2_expand_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_expand_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_depthwise_1/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>, <tf.Variable 'block_2_depthwise_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_depthwise_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_project_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32>, <tf.Variable 'block_2_project_BN_1/gamma:0' shape=(24,) dtype=float32>, <tf.Variable 'block_2_project_BN_1/beta:0' shape=(24,) dtype=float32>, <tf.Variable 'block_3_expand_1/kernel:0' shape=(1, 1, 24, 144) dtype=float32>, <tf.Variable 'block_3_expand_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_expand_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_depthwise_1/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>, <tf.Variable 'block_3_depthwise_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_depthwise_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_project_1/kernel:0' shape=(1, 1, 144, 32) dtype=float32>, <tf.Variable 'block_3_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_3_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_4_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_4_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_4_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_project_1/kernel:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'block_4_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_4_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_5_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_5_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_5_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_project_1/kernel:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'block_5_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_5_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_6_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_6_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_6_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_project_1/kernel:0' shape=(1, 1, 192, 64) dtype=float32>, <tf.Variable 'block_6_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_6_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_7_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_7_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_7_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_7_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_7_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_8_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_8_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_8_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_8_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_8_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_9_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_9_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_9_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_9_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_9_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_10_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_10_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_10_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_project_1/kernel:0' shape=(1, 1, 384, 96) dtype=float32>, <tf.Variable 'block_10_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_10_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_11_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_11_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_11_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_project_1/kernel:0' shape=(1, 1, 576, 96) dtype=float32>, <tf.Variable 'block_11_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_11_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_12_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_12_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_12_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_project_1/kernel:0' shape=(1, 1, 576, 96) dtype=float32>, <tf.Variable 'block_12_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_12_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_13_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_13_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_13_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_project_1/kernel:0' shape=(1, 1, 576, 160) dtype=float32>, <tf.Variable 'block_13_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_13_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_14_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_14_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_14_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_project_1/kernel:0' shape=(1, 1, 960, 160) dtype=float32>, <tf.Variable 'block_14_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_14_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_15_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_15_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_15_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_project_1/kernel:0' shape=(1, 1, 960, 160) dtype=float32>, <tf.Variable 'block_15_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_15_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_16_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_16_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_16_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_project_1/kernel:0' shape=(1, 1, 960, 320) dtype=float32>, <tf.Variable 'block_16_project_BN_1/gamma:0' shape=(320,) dtype=float32>, <tf.Variable 'block_16_project_BN_1/beta:0' shape=(320,) dtype=float32>, <tf.Variable 'Conv_1_1/kernel:0' shape=(1, 1, 320, 1280) dtype=float32>, <tf.Variable 'Conv_1_bn_1/gamma:0' shape=(1280,) dtype=float32>, <tf.Variable 'Conv_1_bn_1/beta:0' shape=(1280,) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0asFNBlrQG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "        self.des = tf.constant([[1.,2.]])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        # y = self.des\n",
        "        return self.dense2(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl7e6GCXrkCf",
        "colab_type": "code",
        "outputId": "de7f73c1-c86c-4cbc-b24b-578b5094cc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = MyModel()\n",
        "print(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW7Ue9vDxQyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "inputs = np.ones((10, 5)) \n",
        "outs = model(inputs) \n",
        "print(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdn72dnmLCJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        print(model.input)\n",
        "        print(model.total_loss)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    #print(\"Total number of epochs run:\", epoch)\n",
        "    #print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBnu4AJrnW_c",
        "colab_type": "code",
        "outputId": "a69e2966-fc1b-4ac1-8f55-3f2209128c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "\n",
        "print(\"I'm a Symbolic tensor:\",model_discriminator)\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    print(\"Value of the model_discriminator function:\",sess.run(model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.14.0\n",
            "I'm a Symbolic tensor: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f5a4d62d438>\n",
            "Value of the model_discriminator function: [[0.00674586]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHuGn1xmoRUB",
        "colab_type": "code",
        "outputId": "dd898966-fb8e-455d-8ce6-535a412cf406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = tf.Variable(1)\n",
        "\n",
        "#@tf.function ... \n",
        "def f(x): \n",
        "  ta = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
        "  for i in tf.range(x): \n",
        "      v.assign_add(i) \n",
        "      ta = ta.write(i, v) \n",
        "  return ta.stack()\n",
        "\n",
        "f(5)\n",
        "ta = tf.TensorArray(tf.int32, size=10, dynamic_size=True)\n",
        "print(ta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f379a0c1dd8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9AfVGylOzPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWuIrI1tQ3Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "graph=K.get_session().graph\n",
        "\n",
        "graph_def=graph.as_graph_def()\n",
        "print(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmAGpwpFaVh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Image\n",
        "import ImageChops\n",
        "\n",
        "im1 = Image.open(\"splash.png\")\n",
        "im2 = Image.open(\"splash2.png\")\n",
        "\n",
        "diff = ImageChops.difference(im2, im1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS-rGAUnZzZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "graph=K.get_session().graph\n",
        "\n",
        "graph_def=graph.as_graph_def()\n",
        "print(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCfwsUo8j7j7",
        "colab_type": "code",
        "outputId": "1252ad90-73ce-4171-efbe-90593e1c68e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def traceme(x):\n",
        "    return model(x)\n",
        "\n",
        "\n",
        "logdir = '/tmp/tensorboard1/'\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "\n",
        "# Forward pass\n",
        "traceme(tf.zeros((1, 28, 28, 1)))\n",
        "with writer.as_default():\n",
        "    tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=logdir)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Trace already enabled\n",
            "WARNING:tensorflow:Model was constructed with shape Tensor(\"flatten_9_input:0\", shape=(None, 28, 28), dtype=float32) for input (None, 28, 28), but it was re-called on a Tensor with incompatible shape (1, 28, 28, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O889UWBikfYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir==logdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o1gfEKP41Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import summary_ops_v2\n",
        "from tensorflow.python.keras.backend import get_graph\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "tb_path = '/tmp/tensorboard/'\n",
        "tb_writer = tf.summary.create_file_writer(tb_path)\n",
        "with tb_writer.as_default():\n",
        "    if not model.run_eagerly:\n",
        "        summary_ops_v2.graph(get_graph(), step=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxsivbfXDhEW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cH7lAzlOiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=tb_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMrpp1JDjRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Comes from Generative Deep Learning by David Foster\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def call(self, inputs):\n",
        "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "# Dummy critic\n",
        "def critic():\n",
        "    critic = Sequential()\n",
        "    inputShape = (28, 28, 1)\n",
        "\n",
        "    critic.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "        input_shape=inputShape))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Flatten())\n",
        "    critic.add(Dense(512))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "    critic.add(Dropout(0.3))\n",
        "    critic.add(Dense(1))\n",
        "\n",
        "    return critic\n",
        "\n",
        "# Gather dataset\n",
        "((X_train, _), (X_test, _)) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Note that I am using test images as fake images for testing purposes\n",
        "interpolated_img = RandomWeightedAverage(32)([X_train[0:32].astype(\"float\"), X_test[32:64].astype(\"float\")])\n",
        "\n",
        "dummy = critic()\n",
        "\n",
        "# Compute gradients of the predictions with respect to the interpolated images\n",
        "with tf.GradientTape() as tape:\n",
        "     y_pred = dummy(interpolated_img)\n",
        "     gradients = tape.gradient(y_pred, interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKHevkcSERhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfbSRTKqETNk",
        "colab_type": "code",
        "outputId": "49556dd7-f061-4bfa-994f-5c331208804a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Comes from Generative Deep Learning by David Foster\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def call(self, inputs):\n",
        "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "# Dummy critic\n",
        "def critic():\n",
        "    critic = Sequential()\n",
        "    inputShape = (28, 28, 1)\n",
        "\n",
        "    critic.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "        input_shape=inputShape))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Flatten())\n",
        "    critic.add(Dense(512))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "    critic.add(Dropout(0.3))\n",
        "    critic.add(Dense(1))\n",
        "\n",
        "    return critic\n",
        "\n",
        "# Gather dataset\n",
        "((X_train, _), (X_test, _)) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Note that I am using test images as fake images for testing purposes\n",
        "interpolated_img = RandomWeightedAverage(32)([X_train[0:32].astype('float'), X_test[32:64].astype('float')])\n",
        "\n",
        "dummy = critic()\n",
        "\n",
        "# Compute gradients of the predictions with respect to the interpolated images\n",
        "with tf.GradientTape() as tape:\n",
        "    y_pred = dummy(interpolated_img)\n",
        "gradients = tape.gradient(y_pred, interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer random_weighted_average_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNyQ36viUI_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy2JljLJTE3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # (1) Importing dependency\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        #Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "        # print(\"Layer of the model:\",model.layers[2])\n",
        "        # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "        # print(model.input)\n",
        "        # print(model.total_loss)\n",
        "        # print(model.trainable_weights)\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    print(\"Total number of epochs run:\", epoch)\n",
        "    print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MgmDrsmHkCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# (5) Define Gradient Function\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# (6) Train the model such that gradients are captured for every epoch\n",
        "epoch_gradient = []\n",
        "for epoch in range(1,5):\n",
        "    model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "    get_gradient = get_gradient_func(model)\n",
        "    grads = get_gradient([x, y, np.ones(len(y))])\n",
        "    #Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "    # print(\"Layer of the model:\",model.layers[2])\n",
        "    # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "    # print(model.input)\n",
        "    # print(model.total_loss)\n",
        "    # print(model.trainable_weights)\n",
        "    epoch_gradient.append(grads)\n",
        "\n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXsTMn1I_oK",
        "colab_type": "code",
        "outputId": "8865e1ea-2c5e-4e85-b417-d1ee78633a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy7BP1P_V1b",
        "colab_type": "code",
        "outputId": "34a301bc-e0c3-4519-b5cd-f210267823ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Modify the load image to have the target size\n",
        "img = load_img(\"/Data/dog.jpg\", color_mode=\"grayscale\",interpolation='nearest', target_size=(200,50))\n",
        "\n",
        "# convert to array\n",
        "img = img_to_array(img)\n",
        "print(\"image to array shape:\",img.shape)\n",
        "\n",
        "# reshape into a single sample with 1 channel\n",
        "img = img[np.newaxis,:,:,:]\n",
        "print(\"Add a new axis to specify number of images:\",img.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image to array shape: (200, 50, 1)\n",
            "Add a new axis to specify number of images: (1, 200, 50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqJyq5h2ArXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgVvCdgvZBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "    import keras\n",
        "    from keras import backend as K\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        # Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "        # print(\"Layer of the model:\",model.layers[2])\n",
        "        # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "        # print(model.input)\n",
        "        # print(model.total_loss)\n",
        "        # print(model.trainable_weights)\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    print(\"Total number of epochs run:\", epoch)\n",
        "    print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhrY8ER0wGyI",
        "colab_type": "code",
        "outputId": "f03028e0-98be-4db0-e0eb-31b28f3c6ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4-tOmttwIhJ",
        "colab_type": "code",
        "outputId": "73a9dd1b-5013-4e1a-d77c-6695418b4327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iutilLUp9AsZ",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks in model.fit\n",
        "https://stackoverflow.com/questions/60808723/how-to-call-a-method-as-a-custom-callback-in-keras/60815917#60815917"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK0RorXYQbgM",
        "colab_type": "code",
        "outputId": "20472657-42a6-487d-c6b2-78611cf34291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epoch_gradient = []\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "    \n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 28,096,769\n",
            "Trainable params: 28,075,633\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "1088/1088 [==============================] - 5s 5ms/step - loss: 3.0726 - acc: 0.2289 - val_loss: 12.3280 - val_acc: 0.1287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 2.2462 - acc: 0.3327 - val_loss: 7.0050 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 1.8286 - acc: 0.4228 - val_loss: 6.0993 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 1.6860 - acc: 0.4642 - val_loss: 3.5253 - val_acc: 0.4081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of epochs run: 4\n",
            "Gradient Array has the shape: (4, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCO9AKLKKjgL",
        "colab_type": "code",
        "outputId": "7b85d8b9-cfe0-49cb-8fec-414bc18acef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 62\n",
            "conv2d_21 (11, 11, 3, 96)\n",
            "conv2d_22 (11, 11, 96, 256)\n",
            "conv2d_23 (3, 3, 256, 384)\n",
            "conv2d_24 (3, 3, 384, 384)\n",
            "conv2d_25 (3, 3, 384, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmsfcXZtL16-",
        "colab_type": "code",
        "outputId": "2a26d2fc-ce8b-4612-ef85-d043f1a5356c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\n",
        "print(filters.shape)\n",
        "print(filters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3, 384, 256)\n",
            "[[[[ 1.33229261e-02  2.78362742e-04 -1.15596037e-03 ... -1.04442742e-02\n",
            "    -1.27202040e-02  2.72896886e-02]\n",
            "   [ 2.04270035e-02  2.09266972e-02 -2.27798354e-02 ...  2.10328754e-02\n",
            "    -1.79852340e-02 -1.31000848e-02]\n",
            "   [ 1.21402023e-02  9.55937244e-03 -9.73658753e-04 ...  2.90534608e-02\n",
            "     8.62147380e-03  3.97700304e-03]\n",
            "   ...\n",
            "   [ 2.05181465e-02 -2.70775743e-02 -1.03279278e-02 ...  4.66628186e-03\n",
            "     2.88294349e-02  3.55665796e-02]\n",
            "   [ 2.56488305e-02  2.02665925e-02 -9.53960046e-03 ...  1.07415328e-02\n",
            "     2.38317680e-02 -1.13734556e-02]\n",
            "   [-6.18373556e-03  7.84027111e-03  4.98771551e-04 ...  1.88040324e-02\n",
            "    -2.21270267e-02  7.43205333e-03]]\n",
            "\n",
            "  [[-3.35427485e-02  2.35256236e-02 -1.55152555e-03 ... -1.82591029e-03\n",
            "    -6.07969100e-03 -2.40267627e-03]\n",
            "   [-5.59751503e-03  3.25453505e-02 -1.27216885e-02 ...  2.22896207e-02\n",
            "    -1.04518968e-03 -3.41729373e-02]\n",
            "   [-1.53387915e-02 -2.15985011e-02 -2.40802132e-02 ...  8.57070833e-03\n",
            "     1.55310007e-02  8.27453937e-03]\n",
            "   ...\n",
            "   [-1.83913186e-02 -2.47003324e-02 -1.77569594e-02 ...  3.14827859e-02\n",
            "     2.37260144e-02  1.35977212e-02]\n",
            "   [-5.08161262e-03  2.33772658e-02 -1.85138639e-02 ... -1.16026518e-03\n",
            "     2.38104146e-02 -1.90851931e-02]\n",
            "   [ 8.57734215e-03 -1.23164626e-02 -1.81618647e-03 ... -1.26188034e-02\n",
            "     2.13982817e-02  1.71989426e-02]]\n",
            "\n",
            "  [[ 2.75964546e-03  4.13805023e-02 -1.22120418e-02 ...  1.71306508e-03\n",
            "    -1.51561396e-02 -2.18702871e-02]\n",
            "   [-3.56088951e-03  3.43757658e-03 -1.16327219e-02 ... -1.19192926e-02\n",
            "     3.88762157e-04 -9.95170232e-03]\n",
            "   [ 3.59454565e-02 -6.90977415e-03 -1.50266113e-02 ... -3.32049071e-03\n",
            "     2.45900005e-02 -2.42324471e-02]\n",
            "   ...\n",
            "   [-1.90636870e-02 -1.24915438e-02  2.68660672e-02 ... -4.73172823e-03\n",
            "    -5.91639895e-03  2.28889082e-02]\n",
            "   [ 3.66363376e-02 -2.24502403e-02 -1.06375702e-02 ... -1.81130767e-02\n",
            "     2.88566016e-02 -2.08211727e-02]\n",
            "   [ 6.01422449e-04 -8.68872181e-03 -2.10836846e-02 ...  1.67874563e-02\n",
            "    -3.84189188e-02  1.78155117e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.22205978e-02  4.27871849e-03 -1.09987976e-02 ...  1.76646598e-02\n",
            "     1.50742009e-02 -3.86701301e-02]\n",
            "   [-2.79729012e-02  2.00011078e-02 -1.31703299e-02 ... -2.00200267e-02\n",
            "    -7.25999195e-03  1.45357484e-02]\n",
            "   [-4.82261041e-03 -4.14834311e-03 -1.76655632e-02 ...  2.20327824e-02\n",
            "     1.72639880e-02 -7.53242476e-03]\n",
            "   ...\n",
            "   [ 1.73690319e-02  3.01635619e-02  1.45886336e-02 ...  1.34067582e-02\n",
            "     3.23755704e-02  1.59694552e-02]\n",
            "   [ 2.47067846e-02  7.35560572e-03 -1.88481305e-02 ...  2.58524362e-02\n",
            "     9.14169010e-04  2.94958130e-02]\n",
            "   [ 2.67407298e-02 -6.96273427e-03  2.19189376e-02 ... -3.23407352e-02\n",
            "     1.11467652e-02 -2.02568714e-02]]\n",
            "\n",
            "  [[-3.33763249e-02 -1.54417353e-02 -8.87046568e-03 ...  1.41540635e-02\n",
            "    -2.68381871e-02  1.22759230e-02]\n",
            "   [-1.30444350e-05 -7.20519293e-03  1.52943395e-02 ... -1.05463304e-02\n",
            "    -1.63246077e-02 -2.80507226e-02]\n",
            "   [ 1.94950942e-02  1.96460653e-02 -5.00125624e-03 ... -1.58436447e-02\n",
            "     1.41756414e-02  1.98035198e-03]\n",
            "   ...\n",
            "   [-2.91450340e-02  1.30721824e-02  1.83877610e-02 ... -1.90879926e-02\n",
            "     1.99749433e-02 -1.05333803e-02]\n",
            "   [ 1.72556620e-02  1.81617010e-02  1.24600148e-02 ...  1.88519955e-02\n",
            "    -8.84543266e-03 -1.60351787e-02]\n",
            "   [ 2.47481037e-02  2.93982169e-03  2.01242752e-02 ...  1.95950232e-02\n",
            "    -2.78105512e-02  2.05665398e-02]]\n",
            "\n",
            "  [[ 1.82851534e-02  3.44641991e-02 -2.00678073e-02 ... -3.24464031e-02\n",
            "    -3.23583074e-02 -2.66336314e-02]\n",
            "   [-1.30740115e-02 -2.40531545e-02  1.92862866e-03 ... -9.58005898e-03\n",
            "    -8.63340776e-03 -2.82395743e-02]\n",
            "   [ 4.19791276e-03  1.45691829e-02  3.42715830e-02 ...  4.06611152e-02\n",
            "    -2.05075163e-02 -3.97980548e-02]\n",
            "   ...\n",
            "   [ 1.23621235e-02 -3.30808535e-02  3.05603142e-03 ... -8.03769939e-03\n",
            "     2.39255354e-02  1.01700425e-02]\n",
            "   [ 1.93574950e-02  2.53207628e-02  3.19945849e-02 ... -1.29298661e-02\n",
            "    -9.71809588e-03 -3.35334092e-02]\n",
            "   [-4.02106047e-02 -2.33742259e-02 -2.70008687e-02 ... -5.98855503e-03\n",
            "    -1.24435341e-02  3.15479822e-02]]]\n",
            "\n",
            "\n",
            " [[[-2.30802242e-02 -1.40459323e-02 -6.23126328e-03 ...  1.52085479e-02\n",
            "    -2.52160486e-02  1.24641499e-02]\n",
            "   [ 1.96760800e-02  1.05630013e-03  2.54229661e-02 ...  1.62760932e-02\n",
            "     2.23252065e-02 -2.22447589e-02]\n",
            "   [ 3.04492004e-02 -1.94075168e-03 -1.97871421e-02 ... -9.06596240e-03\n",
            "     3.24702673e-02 -9.38400440e-03]\n",
            "   ...\n",
            "   [-2.87375692e-02 -1.13275591e-02 -1.56598929e-02 ... -3.06045953e-02\n",
            "    -3.27123553e-02  4.29812027e-03]\n",
            "   [-5.72555349e-04  9.24452208e-03 -1.79962069e-02 ... -1.38692930e-03\n",
            "    -1.69475167e-03 -2.07326356e-02]\n",
            "   [ 2.55298633e-02  2.39779558e-02 -4.83227056e-03 ... -1.02796387e-02\n",
            "    -1.41589378e-04 -1.67643074e-02]]\n",
            "\n",
            "  [[-2.23147380e-03  1.37838507e-02 -4.08266764e-03 ...  1.90702491e-02\n",
            "     9.72075947e-03 -2.66824216e-02]\n",
            "   [-1.86436921e-02 -2.82567251e-03 -1.35208173e-02 ...  3.81241441e-02\n",
            "    -1.62060019e-02 -3.96039486e-02]\n",
            "   [ 5.92509052e-03  1.42326870e-03  5.25515201e-03 ...  2.07302850e-02\n",
            "    -3.06541529e-02 -2.26684157e-02]\n",
            "   ...\n",
            "   [ 2.35446766e-02 -3.54932398e-02 -1.09605016e-02 ...  1.20483274e-02\n",
            "     3.52192447e-02 -8.96899775e-03]\n",
            "   [-1.91081129e-02 -7.72378687e-03  8.51210579e-03 ...  3.27213518e-02\n",
            "    -3.99521226e-03  2.70088650e-02]\n",
            "   [-1.36597576e-02  7.93528836e-03  4.57486464e-03 ... -3.79467532e-02\n",
            "    -1.68086924e-02  3.47109861e-03]]\n",
            "\n",
            "  [[-2.51405891e-02  3.37613821e-02 -1.24929231e-02 ... -4.84925555e-03\n",
            "     1.82562377e-02 -4.42078747e-02]\n",
            "   [-5.84426289e-03 -2.04253178e-02  1.42424544e-02 ...  2.39489395e-02\n",
            "    -3.39500532e-02 -7.58632645e-03]\n",
            "   [ 2.52021682e-02 -2.40255445e-02 -1.36912316e-02 ... -1.96786743e-04\n",
            "     7.05324765e-03 -1.00541944e-02]\n",
            "   ...\n",
            "   [ 9.71514825e-03 -7.74992211e-03 -3.24081630e-02 ...  1.33663723e-02\n",
            "     1.77465230e-02  2.45424472e-02]\n",
            "   [-1.41809247e-02  2.96245646e-02  3.87504548e-02 ...  1.54969441e-02\n",
            "    -2.57334486e-02 -4.18210924e-02]\n",
            "   [-7.17054168e-03  3.36966068e-02 -2.70571802e-02 ... -3.91547196e-03\n",
            "    -1.72355976e-02  2.01625824e-02]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjwfJo493IAV",
        "colab_type": "text"
      },
      "source": [
        "# Tensor to Array(ndarray) \n",
        "https://stackoverflow.com/questions/60824788/how-to-convert-tensor-to-ndarray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9cwPNdunwz7",
        "colab_type": "code",
        "outputId": "e6b65ff5-5de2-4eb5-d06b-cb19c5497844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "output = model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))\n",
        "print(\"Output as a Tensor:\",output)\n",
        "\n",
        "out = np.array(output)\n",
        "print(\"Output as an Array:\",out)\n",
        "print(\"Type of the Array:\",type(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.1.0\n",
            "Output as a Tensor: tf.Tensor([[-0.40550372]], shape=(1, 1), dtype=float32)\n",
            "Output as an Array: [[-0.40550372]]\n",
            "Type of the Array: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHp5zzm0jbd",
        "colab_type": "code",
        "outputId": "7e589da7-084f-4643-8810-5e40c4102e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "output = model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    print(\"Output as a Tensor:\",output)\n",
        "    out = np.array(sess.run(output))\n",
        "    print(\"Output as an Array:\",out)\n",
        "    print(\"Type of the Array:\",type(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.14.0\n",
            "Output as a Tensor: Tensor(\"sequential_7/dense_15/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
            "Output as an Array: [[-0.29746282]]\n",
            "Type of the Array: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEyyro-xMnwS",
        "colab_type": "text"
      },
      "source": [
        "# Switching between Tensorflow Versions without installing everytime\n",
        "https://stackoverflow.com/questions/60810400/how-to-upgrade-tensorflow-to-2-0-in-google-colab-permanently/60810715#60810715"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PKQyncnMmBa",
        "colab_type": "code",
        "outputId": "3e556b13-75f0-4eaf-a708-94638c6e8099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVg8VdqXNHeN",
        "colab_type": "code",
        "outputId": "5f1425f1-d300-47b4-8db3-7e3e900b2d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f2C617e-BFu",
        "colab_type": "text"
      },
      "source": [
        "# One Hot Encoding Using LabelBinarizer\n",
        "https://stackoverflow.com/questions/60868391/how-to-view-class-labels-after-one-hot-encoding-during-training-testing-and-afte/60871869#60871869"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsvwViobiReg",
        "colab_type": "code",
        "outputId": "52777050-e087-4be8-e5c1-aefd120f0c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# define example\n",
        "data = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
        "\n",
        "values = np.array(data)\n",
        "\n",
        "#Binary encode\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "labels = lb.fit_transform(values)\n",
        "labels = to_categorical(labels)\n",
        "print(\"which position represents for cat and dog?:\")\n",
        "print(\"Data is:\",data)\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which position represents for cat and dog?:\n",
            "Data is: ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ4RkAQAKsje",
        "colab_type": "code",
        "outputId": "6ccc26e1-0cbb-41e8-9c73-5ff4ac30442e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# define example\n",
        "data1 = ['cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat']\n",
        "data2 = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
        "\n",
        "values1 = np.array(data1)\n",
        "values2 = np.array(data2)\n",
        "\n",
        "#Binary encode\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "labels1 = lb.fit_transform(values1)\n",
        "labels1 = to_categorical(labels1)\n",
        "print(\"what is value for cat and dog?:\")\n",
        "print(\"Data is:\",data1)\n",
        "print(labels1)\n",
        "print(\"\\n\")\n",
        "\n",
        "labels2 = lb.fit_transform(values2)\n",
        "labels2 = to_categorical(labels2)\n",
        "print(\"what is value for cat and dog?:\")\n",
        "print(\"Data is:\",data2)\n",
        "print(labels2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what is value for cat and dog?:\n",
            "Data is: ['cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat']\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "\n",
            "\n",
            "what is value for cat and dog?:\n",
            "Data is: ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFIx6yucLI-K",
        "colab_type": "code",
        "outputId": "d99da379-cfe0-48ec-9e2e-41f6c23a10e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "rslt = np.array([[0.9550967,0.04490325]])\n",
        "rslt = np.argmax(rslt)\n",
        "print(rslt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIZpkS8Sh223",
        "colab_type": "code",
        "outputId": "0e98fc0b-6ee4-4012-fc7d-3b1563c3026e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "rslt = np.array([[0.04490325,0.9550967, 1]])\n",
        "rslt = np.argmax(rslt)\n",
        "print(rslt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_jgkP3sdF4r",
        "colab_type": "text"
      },
      "source": [
        "# Ragged Tensor\n",
        "https://stackoverflow.com/questions/60924624/is-there-a-way-to-normalize-a-ragged-tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dqzlnvmwrr3",
        "colab_type": "text"
      },
      "source": [
        "## Using math.l2_normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REq-0WuSdgT3",
        "colab_type": "code",
        "outputId": "142206b5-c025-4ce7-ee90-028d2ecc380b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Create a Ragged Tensor\n",
        "rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Normalize\n",
        "rt = tf.math.l2_normalize(rt, axis = None)\n",
        "print(\"Normalized Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Ragged Tensor\n",
        "rt = tf.RaggedTensor.from_tensor(rt, padding=0.0)\n",
        "print(\"Normalized Ragged Tensor:\",\"\\n\",rt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " <tf.RaggedTensor [[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]]> \n",
            "\n",
            "Tensor of same length: \n",
            " tf.Tensor(\n",
            "[[9. 8. 7.]\n",
            " [0. 0. 0.]\n",
            " [6. 5. 0.]\n",
            " [4. 0. 0.]], shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Tensor: \n",
            " tf.Tensor(\n",
            "[[0.546711   0.48596537 0.4252197 ]\n",
            " [0.         0.         0.        ]\n",
            " [0.36447403 0.30372834 0.        ]\n",
            " [0.24298269 0.         0.        ]], shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Ragged Tensor: \n",
            " <tf.RaggedTensor [[0.5467110276222229, 0.485965371131897, 0.42521971464157104], [], [0.36447402834892273, 0.3037283420562744], [0.2429826855659485]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_FhnDE9wzlF",
        "colab_type": "text"
      },
      "source": [
        "## Using tf.linalg.normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHoyROQdpHI",
        "colab_type": "code",
        "outputId": "f16f1518-fc9a-4ed0-83aa-2f3f78f813d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Create a Ragged Tensor\n",
        "rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Normalize\n",
        "rt = tf.linalg.normalize(rt, axis = None)\n",
        "print(\"Normalized and Norm Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "# Get the normalized part\n",
        "rt = tf.convert_to_tensor(rt[0])\n",
        "print(\"Normalized Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Ragged Tensor\n",
        "rt = tf.RaggedTensor.from_tensor(rt, padding=0.0)\n",
        "print(\"Normalized Ragged Tensor:\",\"\\n\",rt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " tf.RaggedTensor(values=Tensor(\"RaggedConstant/values:0\", shape=(6,), dtype=float32), row_splits=Tensor(\"RaggedConstant/Const:0\", shape=(5,), dtype=int64)) \n",
            "\n",
            "Tensor of same length: \n",
            " Tensor(\"RaggedToTensor/GatherV2:0\", shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized and Norm Tensor: \n",
            " (<tf.Tensor 'normalize/truediv:0' shape=(4, 3) dtype=float32>, <tf.Tensor 'normalize/norm/Sqrt:0' shape=(1, 1) dtype=float32>) \n",
            "\n",
            "Normalized Tensor: \n",
            " Tensor(\"normalize/truediv:0\", shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Ragged Tensor: \n",
            " tf.RaggedTensor(values=Tensor(\"RaggedFromTensor/boolean_mask/GatherV2:0\", shape=(?,), dtype=float32), row_splits=Tensor(\"RaggedFromTensor/concat:0\", shape=(5,), dtype=int64))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVLkvAkPatDD",
        "colab_type": "text"
      },
      "source": [
        "# Deleting Layer using Keras Surgeon OR pop\n",
        "https://stackoverflow.com/questions/60637199/error-in-removing-the-first-layer-of-keras-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb4cJKwt2eIK",
        "colab_type": "text"
      },
      "source": [
        "## Deleting the first or middle layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcVNcMX4eV1A",
        "colab_type": "code",
        "outputId": "94ffb433-76fb-4c11-9c99-b449fd298fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install kerassurgeon"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerassurgeon\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/e7/8adbef95f56e2349bf9faf2aec462dee0a38cec7cd6bfb8895de83706762/kerassurgeon-0.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Installing collected packages: kerassurgeon\n",
            "Successfully installed kerassurgeon-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3d88fe8b-4d7c-4c16-9294-e641eefb5d1a",
        "id": "K9OBGZECaruM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon.operations import delete_layer, insert_layer, delete_channels\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# delete 3rd layer .i.e. Conv2D Layer from the model\n",
        "layer_3 = model.layers[2]\n",
        "model = delete_layer(model, layer_3)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19_input (InputLayer) (None, 24, 24, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 61,744\n",
            "Trainable params: 61,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJidi2xObYul",
        "colab_type": "code",
        "outputId": "ad1db41b-aa86-4bd1-f0c5-8cf2f485e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon import Surgeon\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# delete 3rd layer .i.e. Conv2D Layer from the model\n",
        "layer_3 = model.layers[2]\n",
        "surgeon = Surgeon(model)\n",
        "surgeon.add_job('delete_layer', layer_3)\n",
        "model = surgeon.operate()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-79f9b15a709b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0msurgeon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSurgeon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_layer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mnew_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_graph\u001b[0;34m(self, graph_inputs, output_nodes, graph_input_masks)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mnew_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_delete_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# Record that this node has been rebuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of input shape to have '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                                 \u001b[0;34m'value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_2: expected axis -1 of input shape to have value 12 but got shape (None, 24, 24, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9f5b5a2-e93f-483d-c421-12e7b94213b6",
        "id": "GHOS2dQEvPkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model1 = model.layers.pop(0)\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_61 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 28,096,769\n",
            "Trainable params: 28,075,633\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d9f744fc3690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_5aAAf82LIE",
        "colab_type": "text"
      },
      "source": [
        "## To remove the last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aabcfd59-f6e6-4940-9749-cf6667dccbf5",
        "id": "JU19GZBdx4eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon import Surgeon\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "model._layers.pop()\n",
        "\n",
        "new_model = Model(model.input,model.layers[-1].output)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_138 (Conv2D)          (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_139 (Conv2D)          (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_140 (Conv2D)          (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_138_input (InputLayer (None, 24, 24, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_138 (Conv2D)          (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_139 (Conv2D)          (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_140 (Conv2D)          (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "=================================================================\n",
            "Total params: 66,649\n",
            "Trainable params: 66,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iah4GD0dbRBW",
        "colab_type": "text"
      },
      "source": [
        "# Multiple image input for keras application\n",
        "https://stackoverflow.com/questions/60582442/multiple-image-input-for-keras-application/60968842#60968842"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN-AY-jDdpLV",
        "colab_type": "code",
        "outputId": "9ab40775-483d-48cb-d651-e1d7b890a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.python.keras import layers, models, applications\n",
        "\n",
        "# Multiple inputs\n",
        "in1 = layers.Input(shape=(128,128,3))\n",
        "in2 = layers.Input(shape=(128,128,3))\n",
        "in3 = layers.Input(shape=(128,128,3))\n",
        "\n",
        "# CNN output\n",
        "cnn = applications.xception.Xception(include_top=False)\n",
        "cnn.summary()\n",
        "\n",
        "out1 = cnn(in1)\n",
        "out2 = cnn(in2)\n",
        "out3 = cnn(in3)\n",
        "\n",
        "# Flattening the output for the dense layer\n",
        "fout1 = layers.Flatten()(out1)\n",
        "fout2 = layers.Flatten()(out2)\n",
        "fout3 = layers.Flatten()(out3)\n",
        "\n",
        "# Getting the dense output\n",
        "dense = layers.Dense(100, activation='softmax')\n",
        "\n",
        "dout1 = dense(fout1)\n",
        "dout2 = dense(fout2)\n",
        "dout3 = dense(fout3)\n",
        "\n",
        "# Concatenating the final output\n",
        "out = layers.Concatenate(axis=-1)([dout1, dout2, dout3])\n",
        "\n",
        "# Creating the model\n",
        "model = models.Model(inputs=[in1,in2,in3], outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "xception (Model)                multiple             20861480    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32768)        0           xception[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32768)        0           xception[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 32768)        0           xception[3][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          3276900     flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 300)          0           dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "==================================================================================================\n",
            "Total params: 24,138,380\n",
            "Trainable params: 24,083,852\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsDMeCKnrbCJ",
        "colab_type": "code",
        "outputId": "b34b9515-b774-4e25-9bf3-be20aff29de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense\n",
        "from keras.activations import relu\n",
        "\n",
        "input_shape = (32,32,3)\n",
        "#[(None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3)]\n",
        "#rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "\n",
        "in1 = Input(shape=(32,32,3))\n",
        "in2 = Input(shape=(32,32,3))\n",
        "in3 = Input(shape=(32,32,3))\n",
        "in4 = Input(shape=(32,32,3))\n",
        "in5 = Input(shape=(32,32,3))\n",
        "in6 = Input(shape=(32,32,3))\n",
        "in7 = Input(shape=(32,32,3))\n",
        "in8 = Input(shape=(32,32,3))\n",
        "in9 = Input(shape=(32,32,3))\n",
        "in10 = Input(shape=(32,32,3))\n",
        "in11 = Input(shape=(32,32,3))\n",
        "\n",
        "inputs = [in1,in2,in3,in4,in5,in6,in7,in8,in9,in10,in11]\n",
        "densenet_121_model = DenseNet121(include_top=False)(inputs)\n",
        "output = Dense(units=11, activation='relu')(densenet_121_model)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-49d38cc5c930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdensenet_121_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensenet_121_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             if all([s is not None\n\u001b[1;32m    467\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    597\u001b[0m             raise ValueError('Invalid input_shape argument ' +\n\u001b[1;32m    598\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': model has '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                              str(len(self._input_layers)) + ' tensor inputs.')\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid input_shape argument [(None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3)]: model has 1 tensor inputs."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYuZaIyrnGQ",
        "colab_type": "code",
        "outputId": "50552790-7d0e-481b-cf68-e7ce32cd4a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense, Flatten, Concatenate\n",
        "from keras.activations import relu\n",
        "\n",
        "# Multiple inputs\n",
        "in1 = Input(shape=(128,128,3))\n",
        "in2 = Input(shape=(128,128,3))\n",
        "in3 = Input(shape=(128,128,3))\n",
        "\n",
        "# CNN output\n",
        "cnn = DenseNet121(include_top=False)\n",
        "#cnn.summary()\n",
        "\n",
        "out1 = cnn(in1)\n",
        "out2 = cnn(in2)\n",
        "out3 = cnn(in3)\n",
        "\n",
        "# Flattening the output for the dense layer\n",
        "fout1 = Flatten()(out1)\n",
        "fout2 = Flatten()(out2)\n",
        "fout3 = Flatten()(out3)\n",
        "\n",
        "# Getting the dense output\n",
        "dense = Dense(1, activation='softmax')\n",
        "\n",
        "dout1 = dense(fout1)\n",
        "dout2 = dense(fout2)\n",
        "dout3 = dense(fout3)\n",
        "\n",
        "# Concatenating the final output\n",
        "out = Concatenate(axis=-1)([dout1, dout2, dout3])\n",
        "\n",
        "# Creating the model\n",
        "model = Model(inputs=[in1,in2,in3], outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_306 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_307 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_308 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "densenet121 (Model)             multiple             7037504     input_306[0][0]                  \n",
            "                                                                 input_307[0][0]                  \n",
            "                                                                 input_308[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 16384)        0           densenet121[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16384)        0           densenet121[2][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 16384)        0           densenet121[3][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1)            16385       flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3)            0           dense_12[0][0]                   \n",
            "                                                                 dense_12[1][0]                   \n",
            "                                                                 dense_12[2][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,053,889\n",
            "Trainable params: 6,970,241\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1vXRhpz0mou",
        "colab_type": "text"
      },
      "source": [
        "# Padding = Same and Padding = Valid \n",
        "https://stackoverflow.com/questions/60323897/tensorflow-keras-conv2d-layers-with-padding-same-behave-strangely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRHrSh0u0m5p",
        "colab_type": "code",
        "outputId": "4ecd0ad4-7a7e-469b-dc6a-c34a6a9a199a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(5,5,1), kernel_size=(2,2), strides =(2,2) ,padding='Same'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rooePLzj1y5h",
        "colab_type": "code",
        "outputId": "a73f7aa2-3b5b-46e3-a405-087f68ea8dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(5,5,1), kernel_size=(2,2), strides =(2,2) ,padding='Valid'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llW_6Wnp3izz",
        "colab_type": "code",
        "outputId": "c66f1c28-231e-4c32-85f0-eff16eb44b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(6,6,1), kernel_size=(2,2), strides =(2,2) ,padding='Valid'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk6am3SF58J6",
        "colab_type": "text"
      },
      "source": [
        "# model.fit_generator Plot\n",
        "https://stackoverflow.com/questions/60306753/drawing-the-accuracy-of-multiple-validation-of-diffferent-cnn-classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_MWlH9u58Xw",
        "colab_type": "code",
        "outputId": "235a0b2f-abe5-472b-c587-c27303e3ebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lr=0.01\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    adam = Adam(lr)\n",
        "\n",
        "    print(\"Model using learning rate of\",lr)\n",
        "\n",
        "    lr = lr + 0.01\n",
        "\n",
        "    model.compile(optimizer=adam, \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(\n",
        "              train_data_gen,\n",
        "              steps_per_epoch=total_train // batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=val_data_gen,\n",
        "              validation_steps=total_val // batch_size)\n",
        "    \n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['LR=0.01', 'LR=0.02', 'LR=0.03', 'LR=0.04', 'LR=0.05'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Model using learning rate of 0.01\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 546ms/step - loss: 7.3135 - accuracy: 0.5073 - val_loss: 0.6920 - val_accuracy: 0.4989\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 545ms/step - loss: 0.6929 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.5134\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 539ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6930 - val_accuracy: 0.5100\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.6934 - accuracy: 0.4893 - val_loss: 0.6932 - val_accuracy: 0.4978\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4944\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.4955\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.6934 - accuracy: 0.5101 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.6935 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5033\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5022\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4877\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.4967\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.4911\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.5089\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.4877\n",
            "Model using learning rate of 0.02\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6935 - accuracy: 0.5011 - val_loss: 0.6932 - val_accuracy: 0.4933\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 524ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.6931 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6936 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6931 - accuracy: 0.4984 - val_loss: 0.6930 - val_accuracy: 0.4900\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 523ms/step - loss: 0.6934 - accuracy: 0.5096 - val_loss: 0.6934 - val_accuracy: 0.4933\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.6933 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5033\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6936 - accuracy: 0.4850 - val_loss: 0.6937 - val_accuracy: 0.5022\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 528ms/step - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 529ms/step - loss: 0.6933 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.4967\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.6933 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5056\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 529ms/step - loss: 0.6933 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.6935 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 529ms/step - loss: 0.6931 - accuracy: 0.4920 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Model using learning rate of 0.03\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.6935 - accuracy: 0.5150 - val_loss: 0.6939 - val_accuracy: 0.4978\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6948 - accuracy: 0.4904 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 0.6935 - accuracy: 0.5043 - val_loss: 0.6934 - val_accuracy: 0.5067\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 521ms/step - loss: 0.6934 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 528ms/step - loss: 0.6938 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6933 - accuracy: 0.5021 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6933 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5100\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6933 - accuracy: 0.4963 - val_loss: 0.6933 - val_accuracy: 0.5022\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 529ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5067\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 553ms/step - loss: 0.6935 - accuracy: 0.4947 - val_loss: 0.6937 - val_accuracy: 0.5089\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.6936 - accuracy: 0.5021 - val_loss: 0.6930 - val_accuracy: 0.5123\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.6934 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 530ms/step - loss: 0.6933 - accuracy: 0.5011 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.6932 - accuracy: 0.5027 - val_loss: 0.6933 - val_accuracy: 0.4944\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.4922\n",
            "Model using learning rate of 0.04\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 549ms/step - loss: 0.6935 - accuracy: 0.5134 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 547ms/step - loss: 0.6948 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.4933\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.6934 - accuracy: 0.4979 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.6934 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.6935 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.4978\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6934 - val_accuracy: 0.5045\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.4877\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 545ms/step - loss: 0.6936 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5033\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.6931 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.4978\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 527ms/step - loss: 0.6936 - accuracy: 0.5069 - val_loss: 0.6932 - val_accuracy: 0.4933\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 0.6934 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5022\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 528ms/step - loss: 0.6936 - accuracy: 0.4866 - val_loss: 0.6939 - val_accuracy: 0.5022\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.6938 - accuracy: 0.5150 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6939 - accuracy: 0.4915 - val_loss: 0.6933 - val_accuracy: 0.5011\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.6933 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Model using learning rate of 0.05\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 551ms/step - loss: 0.6935 - accuracy: 0.5134 - val_loss: 0.6958 - val_accuracy: 0.4955\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 548ms/step - loss: 0.6955 - accuracy: 0.4973 - val_loss: 0.6933 - val_accuracy: 0.5078\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 545ms/step - loss: 0.6931 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.4944\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6935 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5045\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 527ms/step - loss: 0.6934 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 0.6933 - accuracy: 0.5176 - val_loss: 0.6935 - val_accuracy: 0.5045\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 556ms/step - loss: 0.6938 - accuracy: 0.4920 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.6940 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.5033\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.6933 - accuracy: 0.5036 - val_loss: 0.6934 - val_accuracy: 0.4933\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 573ms/step - loss: 0.6942 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.4944\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.6942 - accuracy: 0.4957 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6930 - accuracy: 0.5166 - val_loss: 0.6935 - val_accuracy: 0.4978\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.6940 - accuracy: 0.4952 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 558ms/step - loss: 0.6932 - accuracy: 0.4845 - val_loss: 0.6933 - val_accuracy: 0.4978\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 546ms/step - loss: 0.6940 - accuracy: 0.5139 - val_loss: 0.6937 - val_accuracy: 0.5033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxqfaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rJtqLmjYX1w",
        "colab_type": "code",
        "outputId": "f8ddbc31-41d4-4883-8564-3649e4ded682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "\n",
        "for i in range(7):\n",
        "\n",
        "    print(\"Model using\",optimizer[i],\"optimizer\")\n",
        "\n",
        "    model.compile(optimizer=optimizer[i], \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(\n",
        "              train_data_gen,\n",
        "              steps_per_epoch=total_train // batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=val_data_gen,\n",
        "              validation_steps=total_val // batch_size)\n",
        "    \n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Validation Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Model using SGD optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 550ms/step - loss: 0.6923 - accuracy: 0.5026 - val_loss: 0.6909 - val_accuracy: 0.5033\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 551ms/step - loss: 0.6898 - accuracy: 0.4989 - val_loss: 0.6900 - val_accuracy: 0.5045\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 539ms/step - loss: 0.6893 - accuracy: 0.5005 - val_loss: 0.6889 - val_accuracy: 0.5022\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 546ms/step - loss: 0.6875 - accuracy: 0.4989 - val_loss: 0.6880 - val_accuracy: 0.5056\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6860 - accuracy: 0.4882 - val_loss: 0.6864 - val_accuracy: 0.4944\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6868 - accuracy: 0.5048 - val_loss: 0.6846 - val_accuracy: 0.4877\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6857 - accuracy: 0.5032 - val_loss: 0.6837 - val_accuracy: 0.4866\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.6830 - accuracy: 0.5016 - val_loss: 0.6832 - val_accuracy: 0.4955\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 547ms/step - loss: 0.6819 - accuracy: 0.5107 - val_loss: 0.6816 - val_accuracy: 0.5022\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.6804 - accuracy: 0.4882 - val_loss: 0.6805 - val_accuracy: 0.5033\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.6798 - accuracy: 0.5037 - val_loss: 0.6800 - val_accuracy: 0.4955\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.6796 - accuracy: 0.4941 - val_loss: 0.6791 - val_accuracy: 0.5022\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.6763 - accuracy: 0.5118 - val_loss: 0.6782 - val_accuracy: 0.5056\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 546ms/step - loss: 0.6758 - accuracy: 0.5048 - val_loss: 0.6743 - val_accuracy: 0.4944\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 539ms/step - loss: 0.6715 - accuracy: 0.5064 - val_loss: 0.6767 - val_accuracy: 0.5000\n",
            "Model using RMSprop optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 544ms/step - loss: 2.3455 - accuracy: 0.4963 - val_loss: 0.6690 - val_accuracy: 0.4944\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 545ms/step - loss: 0.6912 - accuracy: 0.5358 - val_loss: 0.6596 - val_accuracy: 0.5123\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 545ms/step - loss: 0.6488 - accuracy: 0.5953 - val_loss: 0.6589 - val_accuracy: 0.5234\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 555ms/step - loss: 0.6675 - accuracy: 0.5962 - val_loss: 0.6412 - val_accuracy: 0.5714\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.6165 - accuracy: 0.6330 - val_loss: 0.6365 - val_accuracy: 0.6920\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 542ms/step - loss: 0.6762 - accuracy: 0.6512 - val_loss: 0.6145 - val_accuracy: 0.6440\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.5711 - accuracy: 0.6854 - val_loss: 0.5771 - val_accuracy: 0.6641\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 549ms/step - loss: 0.7130 - accuracy: 0.6571 - val_loss: 0.6068 - val_accuracy: 0.6975\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 550ms/step - loss: 0.4837 - accuracy: 0.7719 - val_loss: 0.5689 - val_accuracy: 0.7042\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 548ms/step - loss: 0.5215 - accuracy: 0.7345 - val_loss: 0.8108 - val_accuracy: 0.6685\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 539ms/step - loss: 0.4842 - accuracy: 0.7548 - val_loss: 0.5851 - val_accuracy: 0.6629\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.4333 - accuracy: 0.7821 - val_loss: 0.5866 - val_accuracy: 0.7065\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.4136 - accuracy: 0.8061 - val_loss: 0.6037 - val_accuracy: 0.7232\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 544ms/step - loss: 0.3493 - accuracy: 0.8456 - val_loss: 0.8027 - val_accuracy: 0.5737\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.3735 - accuracy: 0.8210 - val_loss: 0.6215 - val_accuracy: 0.6317\n",
            "Model using Adagrad optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.2212 - accuracy: 0.9017 - val_loss: 0.6342 - val_accuracy: 0.7199\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.1544 - accuracy: 0.9482 - val_loss: 0.6781 - val_accuracy: 0.7087\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 545ms/step - loss: 0.1409 - accuracy: 0.9498 - val_loss: 0.6718 - val_accuracy: 0.7188\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.1133 - accuracy: 0.9610 - val_loss: 0.7026 - val_accuracy: 0.7288\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 551ms/step - loss: 0.1023 - accuracy: 0.9698 - val_loss: 0.6959 - val_accuracy: 0.7243\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 551ms/step - loss: 0.0906 - accuracy: 0.9744 - val_loss: 0.7243 - val_accuracy: 0.7299\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 542ms/step - loss: 0.0821 - accuracy: 0.9813 - val_loss: 0.6867 - val_accuracy: 0.7400\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.7433 - val_accuracy: 0.7388\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.0683 - accuracy: 0.9813 - val_loss: 0.7392 - val_accuracy: 0.7467\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.0584 - accuracy: 0.9877 - val_loss: 0.7992 - val_accuracy: 0.7366\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.0581 - accuracy: 0.9888 - val_loss: 0.8050 - val_accuracy: 0.7355\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0534 - accuracy: 0.9899 - val_loss: 0.8280 - val_accuracy: 0.7299\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0455 - accuracy: 0.9920 - val_loss: 0.8068 - val_accuracy: 0.7254\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0483 - accuracy: 0.9893 - val_loss: 0.8482 - val_accuracy: 0.7411\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.0394 - accuracy: 0.9952 - val_loss: 0.8483 - val_accuracy: 0.7444\n",
            "Model using Adadelta optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.0360 - accuracy: 0.9968 - val_loss: 0.8339 - val_accuracy: 0.7500\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0376 - accuracy: 0.9941 - val_loss: 0.8663 - val_accuracy: 0.7411\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.0380 - accuracy: 0.9947 - val_loss: 0.8333 - val_accuracy: 0.7433\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0332 - accuracy: 0.9968 - val_loss: 0.8508 - val_accuracy: 0.7455\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.0357 - accuracy: 0.9952 - val_loss: 0.8521 - val_accuracy: 0.7444\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.0364 - accuracy: 0.9952 - val_loss: 0.8440 - val_accuracy: 0.7433\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 539ms/step - loss: 0.0362 - accuracy: 0.9953 - val_loss: 0.8540 - val_accuracy: 0.7388\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 549ms/step - loss: 0.0344 - accuracy: 0.9957 - val_loss: 0.8276 - val_accuracy: 0.7500\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0364 - accuracy: 0.9952 - val_loss: 0.8934 - val_accuracy: 0.7355\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 542ms/step - loss: 0.0372 - accuracy: 0.9947 - val_loss: 0.8400 - val_accuracy: 0.7422\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.0336 - accuracy: 0.9963 - val_loss: 0.8363 - val_accuracy: 0.7500\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.0361 - accuracy: 0.9952 - val_loss: 0.8305 - val_accuracy: 0.7533\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0341 - accuracy: 0.9963 - val_loss: 0.8525 - val_accuracy: 0.7433\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.0369 - accuracy: 0.9947 - val_loss: 0.8260 - val_accuracy: 0.7489\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.0359 - accuracy: 0.9947 - val_loss: 0.8301 - val_accuracy: 0.7489\n",
            "Model using Adam optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 552ms/step - loss: 0.3095 - accuracy: 0.8985 - val_loss: 0.6640 - val_accuracy: 0.7065\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 547ms/step - loss: 0.1579 - accuracy: 0.9466 - val_loss: 0.7996 - val_accuracy: 0.7143\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0947 - accuracy: 0.9690 - val_loss: 0.8588 - val_accuracy: 0.7254\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0517 - accuracy: 0.9882 - val_loss: 0.8744 - val_accuracy: 0.7299\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0305 - accuracy: 0.9947 - val_loss: 0.9929 - val_accuracy: 0.7366\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.0201 - accuracy: 0.9973 - val_loss: 1.0628 - val_accuracy: 0.7299\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 0.0112 - accuracy: 0.9995 - val_loss: 1.1092 - val_accuracy: 0.7310\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2584 - val_accuracy: 0.7199\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7277\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 542ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3556 - val_accuracy: 0.7254\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3489 - val_accuracy: 0.7299\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.4395 - val_accuracy: 0.7188\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.7377\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4526 - val_accuracy: 0.7310\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5280 - val_accuracy: 0.7288\n",
            "Model using Adamax optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0850 - accuracy: 0.9760 - val_loss: 1.1438 - val_accuracy: 0.7254\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0121 - accuracy: 0.9984 - val_loss: 1.2295 - val_accuracy: 0.7254\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.7254\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.7333\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2698 - val_accuracy: 0.7366\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.7355\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.7455\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.7388\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3672 - val_accuracy: 0.7377\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3996 - val_accuracy: 0.7377\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3832 - val_accuracy: 0.7388\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 544ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3540 - val_accuracy: 0.7377\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4436 - val_accuracy: 0.7377\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 530ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.7355\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 534ms/step - loss: 9.3525e-04 - accuracy: 1.0000 - val_loss: 1.4467 - val_accuracy: 0.7411\n",
            "Model using Nadam optimizer\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 8s 544ms/step - loss: 0.2377 - accuracy: 0.9546 - val_loss: 1.0978 - val_accuracy: 0.6987\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.0141 - accuracy: 0.9989 - val_loss: 1.1944 - val_accuracy: 0.7087\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2142 - val_accuracy: 0.7199\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.7199\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.7321\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.7254\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4314 - val_accuracy: 0.7299\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 8s 541ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.7299\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 8s 544ms/step - loss: 8.7912e-04 - accuracy: 1.0000 - val_loss: 1.5104 - val_accuracy: 0.7299\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 8s 540ms/step - loss: 7.7580e-04 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.7377\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 8s 533ms/step - loss: 6.9067e-04 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.7355\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 6.0729e-04 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.7344\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 5.3627e-04 - accuracy: 1.0000 - val_loss: 1.5827 - val_accuracy: 0.7243\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 4.9750e-04 - accuracy: 1.0000 - val_loss: 1.6625 - val_accuracy: 0.7199\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 4.4487e-04 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.7299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTIssQRhjjGmRJQhjjDEt+n9W9Pwjt2BEbwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ip33pHpNOVU",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the Conv3D and Conv2D Kernel\n",
        "https://stackoverflow.com/questions/60456336/weight-visualization-of-3d-convolutional-kernel\n",
        "\n",
        "Interesting Read that helps in visualizing the image after every layer - https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "\n",
        "Params of a layer -\n",
        "“(n* m * l+1)*k”\n",
        "- The filter size is “n*m”.\n",
        "- “l” feature maps as the input \n",
        "- “k” feature maps as output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVB8mbWfNCIF",
        "colab_type": "text"
      },
      "source": [
        "## Conv3D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96V691CNOeP",
        "colab_type": "code",
        "outputId": "5c3e41e7-a9b8-4c40-a1d8-f3eb8d8390d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "x = np.expand_dims(x,-1)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv3D(filters=2, input_shape=(224,224,3,1), kernel_size=(3,3,3), strides=(4,4,4), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv3D(filters=4, kernel_size=(4,4,4), strides=(1,1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv3D(filters=2, kernel_size=(4,4,4), strides=(1,1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= 4, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_4 (Conv3D)            (None, 56, 56, 1, 2)      56        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 56, 56, 1, 2)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 56, 56, 1, 4)      516       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 56, 56, 1, 4)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 56, 56, 1, 2)      514       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 56, 56, 1, 2)      0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               627300    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 630,103\n",
            "Trainable params: 630,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 2.8280 - acc: 0.0524 - val_loss: 2.8091 - val_acc: 0.0699\n",
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 698us/step - loss: 2.7028 - acc: 0.1847 - val_loss: 2.5356 - val_acc: 0.2279\n",
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 713us/step - loss: 2.2128 - acc: 0.2978 - val_loss: 2.1192 - val_acc: 0.2574\n",
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 713us/step - loss: 1.7553 - acc: 0.4237 - val_loss: 1.9295 - val_acc: 0.3640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3d006f668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-P_eKgE1yqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = model.layers[4].kernel\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19bc9c7b-f444-42da-9dcf-0eb5cb000dbd",
        "id": "g6rmQdDrNeYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3d_4 (3, 3, 3, 1, 2)\n",
            "conv3d_5 (4, 4, 4, 2, 4)\n",
            "conv3d_6 (4, 4, 4, 4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vQ3EuZqoQi",
        "colab_type": "text"
      },
      "source": [
        "### To print Color Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c5d4258-e392-4964-d7ad-19ca8525ba37",
        "id": "PP5fNoi1qnHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming channels\n",
        "\tincoming_channels = 4\n",
        "\tfor j in range(incoming_channels):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = pyplot.subplot(3, incoming_channels, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tpyplot.imshow(f[:, :, :,j], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAACeCAYAAACGoUnQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBM6yqw3qh3Q",
        "colab_type": "text"
      },
      "source": [
        "### To print Gray scale image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnYdGbqnZ3pg",
        "colab_type": "code",
        "outputId": "dd2d112f-229d-4299-ee37-22e8f2b63000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming channels\n",
        "\tincoming_channels = 4\n",
        "\tfor j in range(incoming_channels):\n",
        "\t\t# Range of Depth of the kernel .i.e. 3\n",
        "\t\tDepth = 4\n",
        "\t\tfor k in range(Depth):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = pyplot.subplot((outgoing_channels*Depth), incoming_channels, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tpyplot.imshow(f[:, :, k,j], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAADrCAYAAAA40BDOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4s_VHK_PNWCO"
      },
      "source": [
        "## Conv2D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a13d4066-6386-4c6c-86c0-0d1d27415c05",
        "id": "1G6Jyc2_NP93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=2, input_shape=(224,224,3), kernel_size=(3,3), strides=(4,4), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=4, kernel_size=(3,3), strides=(1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=2, kernel_size=(3,3), strides=(1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epoch_gradient = []\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "    \n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Succesfully downloaded', '17flowers.tgz', 60270631, 'bytes.')\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 2)         56        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 56, 56, 2)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 4)         76        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 56, 56, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 56, 56, 2)         74        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 56, 56, 2)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               627300    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 629,223\n",
            "Trainable params: 629,223\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1088/1088 [==============================] - 14s 13ms/step - loss: 2.8319 - acc: 0.0533 - val_loss: 2.8246 - val_acc: 0.0662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 567us/step - loss: 2.7434 - acc: 0.2426 - val_loss: 2.7336 - val_acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 579us/step - loss: 2.2730 - acc: 0.4384 - val_loss: 2.4033 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 555us/step - loss: 1.3170 - acc: 0.6884 - val_loss: 2.2917 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of epochs run: 4\n",
            "Gradient Array has the shape: (4, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSYQQEW9vDj",
        "colab_type": "code",
        "outputId": "8cde4e2a-88f5-4416-9858-8523bfcfdb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import numpy as np\n",
        "x = model.layers[4].kernel\n",
        "gr = tf.get_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    conv1_kernel_val = gr.get_tensor_by_name('conv1/kernel:0').eval()\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.07628679  0.31725606]\n",
            "   [-0.29280648  0.10707554]\n",
            "   [-0.1409379  -0.14117424]\n",
            "   [-0.04934797 -0.17769067]]\n",
            "\n",
            "  [[-0.22811215  0.2088342 ]\n",
            "   [ 0.12845007 -0.10234594]\n",
            "   [ 0.29518536  0.22939327]\n",
            "   [-0.102254   -0.16633217]]\n",
            "\n",
            "  [[ 0.23566589  0.06252447]\n",
            "   [ 0.12485743 -0.2845057 ]\n",
            "   [ 0.17910227 -0.09911792]\n",
            "   [ 0.09142479 -0.17152238]]]\n",
            "\n",
            "\n",
            " [[[-0.23811015 -0.16541886]\n",
            "   [-0.33333215 -0.13665256]\n",
            "   [ 0.09643212  0.07662854]\n",
            "   [ 0.05305314 -0.23696613]]\n",
            "\n",
            "  [[ 0.0339109   0.16784325]\n",
            "   [-0.04169551 -0.0482665 ]\n",
            "   [ 0.08657351  0.12973014]\n",
            "   [ 0.05880824  0.05947757]]\n",
            "\n",
            "  [[ 0.11017862 -0.14729127]\n",
            "   [ 0.2464253  -0.19549426]\n",
            "   [-0.2609269   0.25060275]\n",
            "   [-0.26333413 -0.13276713]]]\n",
            "\n",
            "\n",
            " [[[-0.06246376  0.0363799 ]\n",
            "   [-0.02949128  0.32878068]\n",
            "   [ 0.15073076 -0.30452785]\n",
            "   [-0.24252614 -0.09735529]]\n",
            "\n",
            "  [[ 0.23945466  0.01562142]\n",
            "   [ 0.22383246  0.09923801]\n",
            "   [-0.2536789  -0.09304142]\n",
            "   [-0.22144732  0.3057051 ]]\n",
            "\n",
            "  [[ 0.05687061 -0.2811746 ]\n",
            "   [-0.2436115  -0.1616823 ]\n",
            "   [ 0.06709924 -0.24549572]\n",
            "   [ 0.04901949 -0.06542149]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a22d8ba-a297-43c2-b58a-36280e0b695c",
        "id": "lQneZbNRNP98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(filters[:,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_4 (3, 3, 3, 2)\n",
            "conv2d_5 (3, 3, 2, 4)\n",
            "conv2d_6 (3, 3, 4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d82d2727-0fe7-4a83-cf25-de643d609776",
        "id": "xnNFITm2NP-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing filters\n",
        "n_filters, ix = 2, 1 \n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t#print(f)\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming filters\n",
        "\tfor j in range(4):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = pyplot.subplot(3, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
        "\t  #print(f[:, :, j])\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAADrCAYAAADwvPoYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjw2f-GyThTk",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Reduce_max\n",
        "https://stackoverflow.com/questions/60277848/tensorflow-reduce-max-for-different-dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OCxARrThgJ",
        "colab_type": "code",
        "outputId": "d9069138-1565-411e-d052-fab527b16df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a Ragged Tensor of variable length\n",
        "rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Apply reduce_max to get the max value along axis=1\n",
        "rt = tf.reduce_max(rt, axis=1)\n",
        "print(\"Reduce Max Tensor:\",\"\\n\",rt,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " <tf.RaggedTensor [[9, 8, 7], [], [6, 5], [4]]> \n",
            "\n",
            "Tensor of same length: \n",
            " tf.Tensor(\n",
            "[[9 8 7]\n",
            " [0 0 0]\n",
            " [6 5 0]\n",
            " [4 0 0]], shape=(4, 3), dtype=int32) \n",
            "\n",
            "Reduce Max Tensor: \n",
            " tf.Tensor([9 0 6 4], shape=(4,), dtype=int32) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzPFRXDg4Di0",
        "colab_type": "text"
      },
      "source": [
        "# Save and Load Model\n",
        "https://stackoverflow.com/questions/60198878/proper-way-to-save-model-in-keras\n",
        "\n",
        "Good Article for Load and Save in Keras - https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kEKp1C76nw6",
        "colab_type": "text"
      },
      "source": [
        "## Build and Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeSykV1cqtSm",
        "colab_type": "code",
        "outputId": "6ba6877c-33f5-4a33-e2c3-4be5b2f7e936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "acc: 77.08%\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYVNZs-6ujU",
        "colab_type": "text"
      },
      "source": [
        "## Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7iWQwy5KP8",
        "colab_type": "code",
        "outputId": "eb78d817-a764-4b1a-9af3-68a3ea75f74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# summarize model.\n",
        "model.summary()\n",
        "\n",
        "# load dataset\n",
        "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "acc: 77.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fARWvSOS0xo",
        "colab_type": "text"
      },
      "source": [
        "# Feed Dict Example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYzDEyNw-qYu",
        "colab_type": "code",
        "outputId": "8adf273d-edbd-4d44-8412-f382940ad0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = x * 42\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  train_accuracy = y.eval(session=sess,feed_dict={x: (2, 4)})\n",
        "  print(train_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 84. 168.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvdRR4EyO6-",
        "colab_type": "text"
      },
      "source": [
        "# Dealing with Session Error Explained\n",
        "https://stackoverflow.com/questions/61006702/cannot-use-the-given-session-to-evaluate-tensor-the-tensors-graph-is-different"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1v2ptOIvyc",
        "colab_type": "text"
      },
      "source": [
        "## Simple Error and Fix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybmrlAanGFK",
        "colab_type": "code",
        "outputId": "765073db-13b0-4c71-b4fe-a04db6b5d3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "s = tf.Session(graph=g)\n",
        "with s.as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                  # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval()) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-56f6710c85ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5396\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5399\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhZjS6zEqHYg",
        "colab_type": "code",
        "outputId": "cdbf2509-90ca-4d6b-f90e-ce9741d8a828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "  y = tf.constant(2.0) # y is created in graph g\n",
        "\n",
        "s = tf.Session(graph=g)\n",
        "with s.as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  print(y.eval()) # y was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssuiDS6xJxkn",
        "colab_type": "text"
      },
      "source": [
        "## Error and Fix Explained in Detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvI2gcXuUZ_A",
        "colab_type": "text"
      },
      "source": [
        "### Error with default session and using variable created in another graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c68196dd-39c9-4e4f-b074-9630c2d3d207",
        "id": "_MjHucq4TEJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session().as_default() as sess:\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  \n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                  # which is tied to graph g, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f35cb204cf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, and is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;31m# default session, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x was created in graph g and it is evaluated in session s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# which is tied to graph g, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyAx1Zp1Us4F",
        "colab_type": "text"
      },
      "source": [
        "### Error with graph session as default and using variable created in default graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og4q09R-GHlL",
        "colab_type": "code",
        "outputId": "08030e4e-bd58-4126-bad6-51e9a8e86096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval()) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6b8b687c5178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5396\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5399\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ecy2vH3X6gU"
      },
      "source": [
        "### Error with graph session as default and using variable created in default graph and also session=sess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6281a25e-0b0e-48a1-f713-0dc083f4d347",
        "id": "EoznhA2nX6gW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-83809aa4e485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0zJAoNLU7pu",
        "colab_type": "text"
      },
      "source": [
        "### Fix with default session and variable not assigned to any graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "42c47425-d833-4f5b-f9f3-196dbf8bef18",
        "id": "5Nx158TXTCT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(1.0)  # x is in not assigned to any graph\n",
        "\n",
        "with tf.Session().as_default() as sess:\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  \n",
        "  print(x.eval(session=sess)) # x not assigned to any graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1qthgoVMUL",
        "colab_type": "text"
      },
      "source": [
        "### The best fix is to cleanly separate the construction phase and the execution phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UftJHIz3VM4d",
        "colab_type": "code",
        "outputId": "40824b97-fc1e-4135-ada3-a2f657975046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "  y = tf.constant(2.0) # y is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  print(y.eval()) # y was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}