{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SO_Home.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SKWwG5iU_Bt2",
        "iutilLUp9AsZ",
        "sjwfJo493IAV",
        "DEyyro-xMnwS",
        "5f2C617e-BFu",
        "g_jgkP3sdF4r",
        "_Dqzlnvmwrr3",
        "q_FhnDE9wzlF",
        "eVLkvAkPatDD",
        "pb4cJKwt2eIK",
        "z_5aAAf82LIE",
        "Iah4GD0dbRBW",
        "-1vXRhpz0mou",
        "Mk6am3SF58J6",
        "SVB8mbWfNCIF",
        "4s_VHK_PNWCO",
        "Wjw2f-GyThTk",
        "hzPFRXDg4Di0",
        "6kEKp1C76nw6",
        "cWYVNZs-6ujU",
        "0fARWvSOS0xo",
        "sUvdRR4EyO6-",
        "nj1v2ptOIvyc",
        "nvI2gcXuUZ_A",
        "nyAx1Zp1Us4F",
        "4ecy2vH3X6gU",
        "H0zJAoNLU7pu",
        "5u1qthgoVMUL",
        "7x-CnHNIH0r1",
        "xDqxUBulbZua",
        "3yg9AIIvdD7b",
        "OwhjPAkYvkBV",
        "aWjlUrHl0Nr1",
        "n9_kieW013Bh",
        "XjDDrht_4wca",
        "jr6jOpefsMfJ",
        "0bidzXGhKqbi",
        "0qT-WEv-Hcbf",
        "_ua8kbaTRrxQ",
        "Z7tP401fS4a4",
        "M_cMruHV4rl3",
        "le6Ro1z2_h0g",
        "ROLJ4CN3eXkS",
        "pym2SKLNMvdf",
        "koNHbfajsb_x",
        "aw7iHJ7WeP22",
        "QnTpV_VHzrKv",
        "R8t-Tu2Cvqei"
      ],
      "authorship_tag": "ABX9TyNBxxwm0g3y4vhx1PrKUGwY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitfattepur/Tensorflow/blob/master/SO_Home.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKWwG5iU_Bt2",
        "colab_type": "text"
      },
      "source": [
        "# Unwanted Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWPhM3KGN4TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "Loss = 0\n",
        "\n",
        "def loss1(y_true1,y_pred1):\n",
        "    return np.square(np.subtract(y_true1,y_pred1)).mean()\n",
        "\n",
        "def loss2(y_true2,y_pred2):\n",
        "    return np.square(np.subtract(y_true2,y_pred2)).mean()\n",
        "\n",
        "def finalloss(y_pred1, y_true1, y_pred2, y_true2):\n",
        "    Loss = loss1(y_pred1, y_true1) + loss2(y_pred2, y_true2)\n",
        "    if(y_pred1 == y_true1 and y_pred2 == y_true2):\n",
        "       return(0)\n",
        "    elif(y_pred1 == y_true1 and y_pred2 != y_true2):\n",
        "      return(0.5 * Loss)\n",
        "    elif(y_pred1 != y_true1 and y_pred2 == y_true2):\n",
        "      return(0.5 * Loss)    \n",
        "    else:\n",
        "      return(Loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmquaW0AoiYB",
        "colab_type": "code",
        "outputId": "7a1573d5-9109-4d33-f766-9fd2f83059ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "finalloss(1,1,7,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxQKG938OI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZcVrTbBOOA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n1sw4uUOUq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCQEsTdrOaj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#for epoch in range(19, 21):\n",
        "train(model, device, train_loader, optimizer, epoch = 20)\n",
        "test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24tVvrWxp2kU",
        "colab_type": "code",
        "outputId": "c4f7d1fa-4e6b-46ca-b471-7255708f62ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "print(\"Tensorflow Version:\",tf.__version__)\n",
        "  \n",
        "model = MobileNetV2(input_shape=[128, 128, 3], include_top=False) #or whatever model\n",
        "\n",
        "print(\"Weights of the Layer\",model.trainable_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 1.15.0\n",
            "Weights of the Layer [<tf.Variable 'Conv1_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>, <tf.Variable 'bn_Conv1_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'bn_Conv1_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_1/depthwise_kernel:0' shape=(3, 3, 32, 1) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_project_1/kernel:0' shape=(1, 1, 32, 16) dtype=float32>, <tf.Variable 'expanded_conv_project_BN_1/gamma:0' shape=(16,) dtype=float32>, <tf.Variable 'expanded_conv_project_BN_1/beta:0' shape=(16,) dtype=float32>, <tf.Variable 'block_1_expand_1/kernel:0' shape=(1, 1, 16, 96) dtype=float32>, <tf.Variable 'block_1_expand_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_expand_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_depthwise_1/depthwise_kernel:0' shape=(3, 3, 96, 1) dtype=float32>, <tf.Variable 'block_1_depthwise_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_depthwise_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_project_1/kernel:0' shape=(1, 1, 96, 24) dtype=float32>, <tf.Variable 'block_1_project_BN_1/gamma:0' shape=(24,) dtype=float32>, <tf.Variable 'block_1_project_BN_1/beta:0' shape=(24,) dtype=float32>, <tf.Variable 'block_2_expand_1/kernel:0' shape=(1, 1, 24, 144) dtype=float32>, <tf.Variable 'block_2_expand_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_expand_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_depthwise_1/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>, <tf.Variable 'block_2_depthwise_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_depthwise_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_project_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32>, <tf.Variable 'block_2_project_BN_1/gamma:0' shape=(24,) dtype=float32>, <tf.Variable 'block_2_project_BN_1/beta:0' shape=(24,) dtype=float32>, <tf.Variable 'block_3_expand_1/kernel:0' shape=(1, 1, 24, 144) dtype=float32>, <tf.Variable 'block_3_expand_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_expand_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_depthwise_1/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>, <tf.Variable 'block_3_depthwise_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_depthwise_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_project_1/kernel:0' shape=(1, 1, 144, 32) dtype=float32>, <tf.Variable 'block_3_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_3_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_4_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_4_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_4_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_project_1/kernel:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'block_4_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_4_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_5_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_5_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_5_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_project_1/kernel:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'block_5_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_5_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_6_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_6_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_6_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_project_1/kernel:0' shape=(1, 1, 192, 64) dtype=float32>, <tf.Variable 'block_6_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_6_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_7_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_7_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_7_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_7_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_7_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_8_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_8_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_8_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_8_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_8_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_9_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_9_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_9_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_9_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_9_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_10_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_10_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_10_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_project_1/kernel:0' shape=(1, 1, 384, 96) dtype=float32>, <tf.Variable 'block_10_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_10_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_11_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_11_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_11_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_project_1/kernel:0' shape=(1, 1, 576, 96) dtype=float32>, <tf.Variable 'block_11_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_11_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_12_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_12_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_12_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_project_1/kernel:0' shape=(1, 1, 576, 96) dtype=float32>, <tf.Variable 'block_12_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_12_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_13_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_13_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_13_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_project_1/kernel:0' shape=(1, 1, 576, 160) dtype=float32>, <tf.Variable 'block_13_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_13_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_14_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_14_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_14_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_project_1/kernel:0' shape=(1, 1, 960, 160) dtype=float32>, <tf.Variable 'block_14_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_14_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_15_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_15_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_15_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_project_1/kernel:0' shape=(1, 1, 960, 160) dtype=float32>, <tf.Variable 'block_15_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_15_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_16_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_16_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_16_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_project_1/kernel:0' shape=(1, 1, 960, 320) dtype=float32>, <tf.Variable 'block_16_project_BN_1/gamma:0' shape=(320,) dtype=float32>, <tf.Variable 'block_16_project_BN_1/beta:0' shape=(320,) dtype=float32>, <tf.Variable 'Conv_1_1/kernel:0' shape=(1, 1, 320, 1280) dtype=float32>, <tf.Variable 'Conv_1_bn_1/gamma:0' shape=(1280,) dtype=float32>, <tf.Variable 'Conv_1_bn_1/beta:0' shape=(1280,) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0asFNBlrQG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "        self.des = tf.constant([[1.,2.]])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        # y = self.des\n",
        "        return self.dense2(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl7e6GCXrkCf",
        "colab_type": "code",
        "outputId": "de7f73c1-c86c-4cbc-b24b-578b5094cc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = MyModel()\n",
        "print(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW7Ue9vDxQyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "inputs = np.ones((10, 5)) \n",
        "outs = model(inputs) \n",
        "print(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdn72dnmLCJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        print(model.input)\n",
        "        print(model.total_loss)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    #print(\"Total number of epochs run:\", epoch)\n",
        "    #print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBnu4AJrnW_c",
        "colab_type": "code",
        "outputId": "a69e2966-fc1b-4ac1-8f55-3f2209128c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "\n",
        "print(\"I'm a Symbolic tensor:\",model_discriminator)\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    print(\"Value of the model_discriminator function:\",sess.run(model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.14.0\n",
            "I'm a Symbolic tensor: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f5a4d62d438>\n",
            "Value of the model_discriminator function: [[0.00674586]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHuGn1xmoRUB",
        "colab_type": "code",
        "outputId": "dd898966-fb8e-455d-8ce6-535a412cf406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = tf.Variable(1)\n",
        "\n",
        "#@tf.function ... \n",
        "def f(x): \n",
        "  ta = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
        "  for i in tf.range(x): \n",
        "      v.assign_add(i) \n",
        "      ta = ta.write(i, v) \n",
        "  return ta.stack()\n",
        "\n",
        "f(5)\n",
        "ta = tf.TensorArray(tf.int32, size=10, dynamic_size=True)\n",
        "print(ta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f379a0c1dd8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9AfVGylOzPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWuIrI1tQ3Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "graph=K.get_session().graph\n",
        "\n",
        "graph_def=graph.as_graph_def()\n",
        "print(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmAGpwpFaVh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Image\n",
        "import ImageChops\n",
        "\n",
        "im1 = Image.open(\"splash.png\")\n",
        "im2 = Image.open(\"splash2.png\")\n",
        "\n",
        "diff = ImageChops.difference(im2, im1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS-rGAUnZzZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "graph=K.get_session().graph\n",
        "\n",
        "graph_def=graph.as_graph_def()\n",
        "print(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCfwsUo8j7j7",
        "colab_type": "code",
        "outputId": "1252ad90-73ce-4171-efbe-90593e1c68e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def traceme(x):\n",
        "    return model(x)\n",
        "\n",
        "\n",
        "logdir = '/tmp/tensorboard1/'\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "\n",
        "# Forward pass\n",
        "traceme(tf.zeros((1, 28, 28, 1)))\n",
        "with writer.as_default():\n",
        "    tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=logdir)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Trace already enabled\n",
            "WARNING:tensorflow:Model was constructed with shape Tensor(\"flatten_9_input:0\", shape=(None, 28, 28), dtype=float32) for input (None, 28, 28), but it was re-called on a Tensor with incompatible shape (1, 28, 28, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O889UWBikfYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir==logdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o1gfEKP41Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import summary_ops_v2\n",
        "from tensorflow.python.keras.backend import get_graph\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "tb_path = '/tmp/tensorboard/'\n",
        "tb_writer = tf.summary.create_file_writer(tb_path)\n",
        "with tb_writer.as_default():\n",
        "    if not model.run_eagerly:\n",
        "        summary_ops_v2.graph(get_graph(), step=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxsivbfXDhEW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cH7lAzlOiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=tb_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMrpp1JDjRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Comes from Generative Deep Learning by David Foster\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def call(self, inputs):\n",
        "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "# Dummy critic\n",
        "def critic():\n",
        "    critic = Sequential()\n",
        "    inputShape = (28, 28, 1)\n",
        "\n",
        "    critic.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "        input_shape=inputShape))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Flatten())\n",
        "    critic.add(Dense(512))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "    critic.add(Dropout(0.3))\n",
        "    critic.add(Dense(1))\n",
        "\n",
        "    return critic\n",
        "\n",
        "# Gather dataset\n",
        "((X_train, _), (X_test, _)) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Note that I am using test images as fake images for testing purposes\n",
        "interpolated_img = RandomWeightedAverage(32)([X_train[0:32].astype(\"float\"), X_test[32:64].astype(\"float\")])\n",
        "\n",
        "dummy = critic()\n",
        "\n",
        "# Compute gradients of the predictions with respect to the interpolated images\n",
        "with tf.GradientTape() as tape:\n",
        "     y_pred = dummy(interpolated_img)\n",
        "     gradients = tape.gradient(y_pred, interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKHevkcSERhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfbSRTKqETNk",
        "colab_type": "code",
        "outputId": "49556dd7-f061-4bfa-994f-5c331208804a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Comes from Generative Deep Learning by David Foster\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def call(self, inputs):\n",
        "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "# Dummy critic\n",
        "def critic():\n",
        "    critic = Sequential()\n",
        "    inputShape = (28, 28, 1)\n",
        "\n",
        "    critic.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "        input_shape=inputShape))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Flatten())\n",
        "    critic.add(Dense(512))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "    critic.add(Dropout(0.3))\n",
        "    critic.add(Dense(1))\n",
        "\n",
        "    return critic\n",
        "\n",
        "# Gather dataset\n",
        "((X_train, _), (X_test, _)) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Note that I am using test images as fake images for testing purposes\n",
        "interpolated_img = RandomWeightedAverage(32)([X_train[0:32].astype('float'), X_test[32:64].astype('float')])\n",
        "\n",
        "dummy = critic()\n",
        "\n",
        "# Compute gradients of the predictions with respect to the interpolated images\n",
        "with tf.GradientTape() as tape:\n",
        "    y_pred = dummy(interpolated_img)\n",
        "gradients = tape.gradient(y_pred, interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer random_weighted_average_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNyQ36viUI_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy2JljLJTE3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # (1) Importing dependency\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        #Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "        # print(\"Layer of the model:\",model.layers[2])\n",
        "        # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "        # print(model.input)\n",
        "        # print(model.total_loss)\n",
        "        # print(model.trainable_weights)\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    print(\"Total number of epochs run:\", epoch)\n",
        "    print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MgmDrsmHkCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# (5) Define Gradient Function\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# (6) Train the model such that gradients are captured for every epoch\n",
        "epoch_gradient = []\n",
        "for epoch in range(1,5):\n",
        "    model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "    get_gradient = get_gradient_func(model)\n",
        "    grads = get_gradient([x, y, np.ones(len(y))])\n",
        "    #Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "    # print(\"Layer of the model:\",model.layers[2])\n",
        "    # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "    # print(model.input)\n",
        "    # print(model.total_loss)\n",
        "    # print(model.trainable_weights)\n",
        "    epoch_gradient.append(grads)\n",
        "\n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXsTMn1I_oK",
        "colab_type": "code",
        "outputId": "8865e1ea-2c5e-4e85-b417-d1ee78633a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy7BP1P_V1b",
        "colab_type": "code",
        "outputId": "34a301bc-e0c3-4519-b5cd-f210267823ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Modify the load image to have the target size\n",
        "img = load_img(\"/Data/dog.jpg\", color_mode=\"grayscale\",interpolation='nearest', target_size=(200,50))\n",
        "\n",
        "# convert to array\n",
        "img = img_to_array(img)\n",
        "print(\"image to array shape:\",img.shape)\n",
        "\n",
        "# reshape into a single sample with 1 channel\n",
        "img = img[np.newaxis,:,:,:]\n",
        "print(\"Add a new axis to specify number of images:\",img.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image to array shape: (200, 50, 1)\n",
            "Add a new axis to specify number of images: (1, 200, 50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqJyq5h2ArXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgVvCdgvZBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "    import keras\n",
        "    from keras import backend as K\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        # Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "        # print(\"Layer of the model:\",model.layers[2])\n",
        "        # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "        # print(model.input)\n",
        "        # print(model.total_loss)\n",
        "        # print(model.trainable_weights)\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    print(\"Total number of epochs run:\", epoch)\n",
        "    print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhrY8ER0wGyI",
        "colab_type": "code",
        "outputId": "f03028e0-98be-4db0-e0eb-31b28f3c6ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4-tOmttwIhJ",
        "colab_type": "code",
        "outputId": "73a9dd1b-5013-4e1a-d77c-6695418b4327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iutilLUp9AsZ",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks in model.fit\n",
        "https://stackoverflow.com/questions/60808723/how-to-call-a-method-as-a-custom-callback-in-keras/60815917#60815917"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK0RorXYQbgM",
        "colab_type": "code",
        "outputId": "f932bb6d-56bc-4a44-95e7-5c5dd5ebda77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epoch_gradient = []\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "    \n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 28,096,769\n",
            "Trainable params: 28,075,633\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "1088/1088 [==============================] - 3s 3ms/step - loss: 2.9722 - accuracy: 0.2206 - val_loss: 39.5700 - val_accuracy: 0.0551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 2.2246 - accuracy: 0.3300 - val_loss: 34.5585 - val_accuracy: 0.1287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 1.7876 - accuracy: 0.4182 - val_loss: 6.3751 - val_accuracy: 0.1544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 1.5633 - accuracy: 0.5074 - val_loss: 2.7399 - val_accuracy: 0.2426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of epochs run: 4\n",
            "Gradient Array has the shape: (4, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCO9AKLKKjgL",
        "colab_type": "code",
        "outputId": "7b85d8b9-cfe0-49cb-8fec-414bc18acef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 62\n",
            "conv2d_21 (11, 11, 3, 96)\n",
            "conv2d_22 (11, 11, 96, 256)\n",
            "conv2d_23 (3, 3, 256, 384)\n",
            "conv2d_24 (3, 3, 384, 384)\n",
            "conv2d_25 (3, 3, 384, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmsfcXZtL16-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\n",
        "print(filters.shape)\n",
        "print(filters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjwfJo493IAV",
        "colab_type": "text"
      },
      "source": [
        "# Tensor to Array(ndarray) \n",
        "https://stackoverflow.com/questions/60824788/how-to-convert-tensor-to-ndarray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9cwPNdunwz7",
        "colab_type": "code",
        "outputId": "e6b65ff5-5de2-4eb5-d06b-cb19c5497844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "output = model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))\n",
        "print(\"Output as a Tensor:\",output)\n",
        "\n",
        "out = np.array(output)\n",
        "print(\"Output as an Array:\",out)\n",
        "print(\"Type of the Array:\",type(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.1.0\n",
            "Output as a Tensor: tf.Tensor([[-0.40550372]], shape=(1, 1), dtype=float32)\n",
            "Output as an Array: [[-0.40550372]]\n",
            "Type of the Array: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHp5zzm0jbd",
        "colab_type": "code",
        "outputId": "7e589da7-084f-4643-8810-5e40c4102e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "output = model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    print(\"Output as a Tensor:\",output)\n",
        "    out = np.array(sess.run(output))\n",
        "    print(\"Output as an Array:\",out)\n",
        "    print(\"Type of the Array:\",type(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.14.0\n",
            "Output as a Tensor: Tensor(\"sequential_7/dense_15/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
            "Output as an Array: [[-0.29746282]]\n",
            "Type of the Array: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEyyro-xMnwS",
        "colab_type": "text"
      },
      "source": [
        "# Switching between Tensorflow Versions without installing everytime\n",
        "https://stackoverflow.com/questions/60810400/how-to-upgrade-tensorflow-to-2-0-in-google-colab-permanently/60810715#60810715"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PKQyncnMmBa",
        "colab_type": "code",
        "outputId": "3e556b13-75f0-4eaf-a708-94638c6e8099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVg8VdqXNHeN",
        "colab_type": "code",
        "outputId": "5f1425f1-d300-47b4-8db3-7e3e900b2d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f2C617e-BFu",
        "colab_type": "text"
      },
      "source": [
        "# One Hot Encoding Using LabelBinarizer\n",
        "https://stackoverflow.com/questions/60868391/how-to-view-class-labels-after-one-hot-encoding-during-training-testing-and-afte/60871869#60871869"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsvwViobiReg",
        "colab_type": "code",
        "outputId": "52777050-e087-4be8-e5c1-aefd120f0c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# define example\n",
        "data = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
        "\n",
        "values = np.array(data)\n",
        "\n",
        "#Binary encode\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "labels = lb.fit_transform(values)\n",
        "labels = to_categorical(labels)\n",
        "print(\"which position represents for cat and dog?:\")\n",
        "print(\"Data is:\",data)\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which position represents for cat and dog?:\n",
            "Data is: ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ4RkAQAKsje",
        "colab_type": "code",
        "outputId": "6ccc26e1-0cbb-41e8-9c73-5ff4ac30442e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# define example\n",
        "data1 = ['cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat']\n",
        "data2 = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
        "\n",
        "values1 = np.array(data1)\n",
        "values2 = np.array(data2)\n",
        "\n",
        "#Binary encode\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "labels1 = lb.fit_transform(values1)\n",
        "labels1 = to_categorical(labels1)\n",
        "print(\"what is value for cat and dog?:\")\n",
        "print(\"Data is:\",data1)\n",
        "print(labels1)\n",
        "print(\"\\n\")\n",
        "\n",
        "labels2 = lb.fit_transform(values2)\n",
        "labels2 = to_categorical(labels2)\n",
        "print(\"what is value for cat and dog?:\")\n",
        "print(\"Data is:\",data2)\n",
        "print(labels2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what is value for cat and dog?:\n",
            "Data is: ['cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat']\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "\n",
            "\n",
            "what is value for cat and dog?:\n",
            "Data is: ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFIx6yucLI-K",
        "colab_type": "code",
        "outputId": "d99da379-cfe0-48ec-9e2e-41f6c23a10e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "rslt = np.array([[0.9550967,0.04490325]])\n",
        "rslt = np.argmax(rslt)\n",
        "print(rslt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIZpkS8Sh223",
        "colab_type": "code",
        "outputId": "0e98fc0b-6ee4-4012-fc7d-3b1563c3026e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "rslt = np.array([[0.04490325,0.9550967, 1]])\n",
        "rslt = np.argmax(rslt)\n",
        "print(rslt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_jgkP3sdF4r",
        "colab_type": "text"
      },
      "source": [
        "# Ragged Tensor\n",
        "https://stackoverflow.com/questions/60924624/is-there-a-way-to-normalize-a-ragged-tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dqzlnvmwrr3",
        "colab_type": "text"
      },
      "source": [
        "## Using math.l2_normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REq-0WuSdgT3",
        "colab_type": "code",
        "outputId": "142206b5-c025-4ce7-ee90-028d2ecc380b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Create a Ragged Tensor\n",
        "rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Normalize\n",
        "rt = tf.math.l2_normalize(rt, axis = None)\n",
        "print(\"Normalized Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Ragged Tensor\n",
        "rt = tf.RaggedTensor.from_tensor(rt, padding=0.0)\n",
        "print(\"Normalized Ragged Tensor:\",\"\\n\",rt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " <tf.RaggedTensor [[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]]> \n",
            "\n",
            "Tensor of same length: \n",
            " tf.Tensor(\n",
            "[[9. 8. 7.]\n",
            " [0. 0. 0.]\n",
            " [6. 5. 0.]\n",
            " [4. 0. 0.]], shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Tensor: \n",
            " tf.Tensor(\n",
            "[[0.546711   0.48596537 0.4252197 ]\n",
            " [0.         0.         0.        ]\n",
            " [0.36447403 0.30372834 0.        ]\n",
            " [0.24298269 0.         0.        ]], shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Ragged Tensor: \n",
            " <tf.RaggedTensor [[0.5467110276222229, 0.485965371131897, 0.42521971464157104], [], [0.36447402834892273, 0.3037283420562744], [0.2429826855659485]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_FhnDE9wzlF",
        "colab_type": "text"
      },
      "source": [
        "## Using tf.linalg.normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHoyROQdpHI",
        "colab_type": "code",
        "outputId": "f16f1518-fc9a-4ed0-83aa-2f3f78f813d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Create a Ragged Tensor\n",
        "rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Normalize\n",
        "rt = tf.linalg.normalize(rt, axis = None)\n",
        "print(\"Normalized and Norm Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "# Get the normalized part\n",
        "rt = tf.convert_to_tensor(rt[0])\n",
        "print(\"Normalized Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Ragged Tensor\n",
        "rt = tf.RaggedTensor.from_tensor(rt, padding=0.0)\n",
        "print(\"Normalized Ragged Tensor:\",\"\\n\",rt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " tf.RaggedTensor(values=Tensor(\"RaggedConstant/values:0\", shape=(6,), dtype=float32), row_splits=Tensor(\"RaggedConstant/Const:0\", shape=(5,), dtype=int64)) \n",
            "\n",
            "Tensor of same length: \n",
            " Tensor(\"RaggedToTensor/GatherV2:0\", shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized and Norm Tensor: \n",
            " (<tf.Tensor 'normalize/truediv:0' shape=(4, 3) dtype=float32>, <tf.Tensor 'normalize/norm/Sqrt:0' shape=(1, 1) dtype=float32>) \n",
            "\n",
            "Normalized Tensor: \n",
            " Tensor(\"normalize/truediv:0\", shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Ragged Tensor: \n",
            " tf.RaggedTensor(values=Tensor(\"RaggedFromTensor/boolean_mask/GatherV2:0\", shape=(?,), dtype=float32), row_splits=Tensor(\"RaggedFromTensor/concat:0\", shape=(5,), dtype=int64))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVLkvAkPatDD",
        "colab_type": "text"
      },
      "source": [
        "# Deleting Layer using Keras Surgeon OR pop\n",
        "https://stackoverflow.com/questions/60637199/error-in-removing-the-first-layer-of-keras-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb4cJKwt2eIK",
        "colab_type": "text"
      },
      "source": [
        "## Deleting the first or middle layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcVNcMX4eV1A",
        "colab_type": "code",
        "outputId": "94ffb433-76fb-4c11-9c99-b449fd298fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install kerassurgeon"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerassurgeon\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/e7/8adbef95f56e2349bf9faf2aec462dee0a38cec7cd6bfb8895de83706762/kerassurgeon-0.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Installing collected packages: kerassurgeon\n",
            "Successfully installed kerassurgeon-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3d88fe8b-4d7c-4c16-9294-e641eefb5d1a",
        "id": "K9OBGZECaruM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon.operations import delete_layer, insert_layer, delete_channels\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# delete 3rd layer .i.e. Conv2D Layer from the model\n",
        "layer_3 = model.layers[2]\n",
        "model = delete_layer(model, layer_3)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19_input (InputLayer) (None, 24, 24, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 61,744\n",
            "Trainable params: 61,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJidi2xObYul",
        "colab_type": "code",
        "outputId": "ad1db41b-aa86-4bd1-f0c5-8cf2f485e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon import Surgeon\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# delete 3rd layer .i.e. Conv2D Layer from the model\n",
        "layer_3 = model.layers[2]\n",
        "surgeon = Surgeon(model)\n",
        "surgeon.add_job('delete_layer', layer_3)\n",
        "model = surgeon.operate()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-79f9b15a709b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0msurgeon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSurgeon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_layer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mnew_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_graph\u001b[0;34m(self, graph_inputs, output_nodes, graph_input_masks)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mnew_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_delete_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# Record that this node has been rebuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of input shape to have '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                                 \u001b[0;34m'value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_2: expected axis -1 of input shape to have value 12 but got shape (None, 24, 24, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9f5b5a2-e93f-483d-c421-12e7b94213b6",
        "id": "GHOS2dQEvPkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model1 = model.layers.pop(0)\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_61 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 28,096,769\n",
            "Trainable params: 28,075,633\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d9f744fc3690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_5aAAf82LIE",
        "colab_type": "text"
      },
      "source": [
        "## To remove the last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aabcfd59-f6e6-4940-9749-cf6667dccbf5",
        "id": "JU19GZBdx4eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon import Surgeon\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "model._layers.pop()\n",
        "\n",
        "new_model = Model(model.input,model.layers[-1].output)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_138 (Conv2D)          (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_139 (Conv2D)          (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_140 (Conv2D)          (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_138_input (InputLayer (None, 24, 24, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_138 (Conv2D)          (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_139 (Conv2D)          (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_140 (Conv2D)          (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "=================================================================\n",
            "Total params: 66,649\n",
            "Trainable params: 66,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iah4GD0dbRBW",
        "colab_type": "text"
      },
      "source": [
        "# Multiple image input for keras application\n",
        "https://stackoverflow.com/questions/60582442/multiple-image-input-for-keras-application/60968842#60968842"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN-AY-jDdpLV",
        "colab_type": "code",
        "outputId": "9ab40775-483d-48cb-d651-e1d7b890a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.python.keras import layers, models, applications\n",
        "\n",
        "# Multiple inputs\n",
        "in1 = layers.Input(shape=(128,128,3))\n",
        "in2 = layers.Input(shape=(128,128,3))\n",
        "in3 = layers.Input(shape=(128,128,3))\n",
        "\n",
        "# CNN output\n",
        "cnn = applications.xception.Xception(include_top=False)\n",
        "cnn.summary()\n",
        "\n",
        "out1 = cnn(in1)\n",
        "out2 = cnn(in2)\n",
        "out3 = cnn(in3)\n",
        "\n",
        "# Flattening the output for the dense layer\n",
        "fout1 = layers.Flatten()(out1)\n",
        "fout2 = layers.Flatten()(out2)\n",
        "fout3 = layers.Flatten()(out3)\n",
        "\n",
        "# Getting the dense output\n",
        "dense = layers.Dense(100, activation='softmax')\n",
        "\n",
        "dout1 = dense(fout1)\n",
        "dout2 = dense(fout2)\n",
        "dout3 = dense(fout3)\n",
        "\n",
        "# Concatenating the final output\n",
        "out = layers.Concatenate(axis=-1)([dout1, dout2, dout3])\n",
        "\n",
        "# Creating the model\n",
        "model = models.Model(inputs=[in1,in2,in3], outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "xception (Model)                multiple             20861480    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32768)        0           xception[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32768)        0           xception[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 32768)        0           xception[3][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          3276900     flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 300)          0           dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "==================================================================================================\n",
            "Total params: 24,138,380\n",
            "Trainable params: 24,083,852\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsDMeCKnrbCJ",
        "colab_type": "code",
        "outputId": "b34b9515-b774-4e25-9bf3-be20aff29de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense\n",
        "from keras.activations import relu\n",
        "\n",
        "input_shape = (32,32,3)\n",
        "#[(None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3)]\n",
        "#rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "\n",
        "in1 = Input(shape=(32,32,3))\n",
        "in2 = Input(shape=(32,32,3))\n",
        "in3 = Input(shape=(32,32,3))\n",
        "in4 = Input(shape=(32,32,3))\n",
        "in5 = Input(shape=(32,32,3))\n",
        "in6 = Input(shape=(32,32,3))\n",
        "in7 = Input(shape=(32,32,3))\n",
        "in8 = Input(shape=(32,32,3))\n",
        "in9 = Input(shape=(32,32,3))\n",
        "in10 = Input(shape=(32,32,3))\n",
        "in11 = Input(shape=(32,32,3))\n",
        "\n",
        "inputs = [in1,in2,in3,in4,in5,in6,in7,in8,in9,in10,in11]\n",
        "densenet_121_model = DenseNet121(include_top=False)(inputs)\n",
        "output = Dense(units=11, activation='relu')(densenet_121_model)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-49d38cc5c930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdensenet_121_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensenet_121_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             if all([s is not None\n\u001b[1;32m    467\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    597\u001b[0m             raise ValueError('Invalid input_shape argument ' +\n\u001b[1;32m    598\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': model has '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                              str(len(self._input_layers)) + ' tensor inputs.')\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid input_shape argument [(None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3)]: model has 1 tensor inputs."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYuZaIyrnGQ",
        "colab_type": "code",
        "outputId": "50552790-7d0e-481b-cf68-e7ce32cd4a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense, Flatten, Concatenate\n",
        "from keras.activations import relu\n",
        "\n",
        "# Multiple inputs\n",
        "in1 = Input(shape=(128,128,3))\n",
        "in2 = Input(shape=(128,128,3))\n",
        "in3 = Input(shape=(128,128,3))\n",
        "\n",
        "# CNN output\n",
        "cnn = DenseNet121(include_top=False)\n",
        "#cnn.summary()\n",
        "\n",
        "out1 = cnn(in1)\n",
        "out2 = cnn(in2)\n",
        "out3 = cnn(in3)\n",
        "\n",
        "# Flattening the output for the dense layer\n",
        "fout1 = Flatten()(out1)\n",
        "fout2 = Flatten()(out2)\n",
        "fout3 = Flatten()(out3)\n",
        "\n",
        "# Getting the dense output\n",
        "dense = Dense(1, activation='softmax')\n",
        "\n",
        "dout1 = dense(fout1)\n",
        "dout2 = dense(fout2)\n",
        "dout3 = dense(fout3)\n",
        "\n",
        "# Concatenating the final output\n",
        "out = Concatenate(axis=-1)([dout1, dout2, dout3])\n",
        "\n",
        "# Creating the model\n",
        "model = Model(inputs=[in1,in2,in3], outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_306 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_307 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_308 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "densenet121 (Model)             multiple             7037504     input_306[0][0]                  \n",
            "                                                                 input_307[0][0]                  \n",
            "                                                                 input_308[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 16384)        0           densenet121[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16384)        0           densenet121[2][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 16384)        0           densenet121[3][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1)            16385       flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3)            0           dense_12[0][0]                   \n",
            "                                                                 dense_12[1][0]                   \n",
            "                                                                 dense_12[2][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,053,889\n",
            "Trainable params: 6,970,241\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1vXRhpz0mou",
        "colab_type": "text"
      },
      "source": [
        "# Padding = Same and Padding = Valid \n",
        "https://stackoverflow.com/questions/60323897/tensorflow-keras-conv2d-layers-with-padding-same-behave-strangely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRHrSh0u0m5p",
        "colab_type": "code",
        "outputId": "4ecd0ad4-7a7e-469b-dc6a-c34a6a9a199a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(5,5,1), kernel_size=(2,2), strides =(2,2) ,padding='Same'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rooePLzj1y5h",
        "colab_type": "code",
        "outputId": "a73f7aa2-3b5b-46e3-a405-087f68ea8dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(5,5,1), kernel_size=(2,2), strides =(2,2) ,padding='Valid'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llW_6Wnp3izz",
        "colab_type": "code",
        "outputId": "c66f1c28-231e-4c32-85f0-eff16eb44b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(6,6,1), kernel_size=(2,2), strides =(2,2) ,padding='Valid'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk6am3SF58J6",
        "colab_type": "text"
      },
      "source": [
        "# model.fit_generator Plot\n",
        "https://stackoverflow.com/questions/60306753/drawing-the-accuracy-of-multiple-validation-of-diffferent-cnn-classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_MWlH9u58Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lr=0.01\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    adam = Adam(lr)\n",
        "\n",
        "    print(\"Model using learning rate of\",lr)\n",
        "\n",
        "    lr = lr + 0.01\n",
        "\n",
        "    model.compile(optimizer=adam, \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(\n",
        "              train_data_gen,\n",
        "              steps_per_epoch=total_train // batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=val_data_gen,\n",
        "              validation_steps=total_val // batch_size)\n",
        "    \n",
        "    plt.plot(100 * history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['LR=0.01', 'LR=0.02', 'LR=0.03', 'LR=0.04', 'LR=0.05'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rJtqLmjYX1w",
        "colab_type": "code",
        "outputId": "da76c5d1-05fd-4ec8-83f6-5d12348adada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "\n",
        "for i in range(7):\n",
        "\n",
        "    print(\"Model using\",optimizer[i],\"optimizer\")\n",
        "\n",
        "    model.compile(optimizer=optimizer[i], \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(\n",
        "              train_data_gen,\n",
        "              steps_per_epoch=total_train // batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=val_data_gen,\n",
        "              validation_steps=total_val // batch_size)\n",
        "    \n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Validation Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-559fbc13edeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mvalidation_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnum_cats_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnum_dogs_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dogs_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_cats_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ip33pHpNOVU",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the Conv3D and Conv2D Kernel\n",
        "https://stackoverflow.com/questions/60456336/weight-visualization-of-3d-convolutional-kernel\n",
        "\n",
        "Interesting Read that helps in visualizing the image after every layer - https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "\n",
        "Params of a layer -\n",
        "(n* m * l+1)*k\n",
        "- The filter size is n*m.\n",
        "- l feature maps as the input \n",
        "- k feature maps as output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVB8mbWfNCIF",
        "colab_type": "text"
      },
      "source": [
        "## Conv3D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96V691CNOeP",
        "colab_type": "code",
        "outputId": "5c3e41e7-a9b8-4c40-a1d8-f3eb8d8390d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "x = np.expand_dims(x,-1)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv3D(filters=2, input_shape=(224,224,3,1), kernel_size=(3,3,3), strides=(4,4,4), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv3D(filters=4, kernel_size=(4,4,4), strides=(1,1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv3D(filters=2, kernel_size=(4,4,4), strides=(1,1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= 4, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_4 (Conv3D)            (None, 56, 56, 1, 2)      56        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 56, 56, 1, 2)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 56, 56, 1, 4)      516       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 56, 56, 1, 4)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 56, 56, 1, 2)      514       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 56, 56, 1, 2)      0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               627300    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 630,103\n",
            "Trainable params: 630,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 2.8280 - acc: 0.0524 - val_loss: 2.8091 - val_acc: 0.0699\n",
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 698us/step - loss: 2.7028 - acc: 0.1847 - val_loss: 2.5356 - val_acc: 0.2279\n",
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 713us/step - loss: 2.2128 - acc: 0.2978 - val_loss: 2.1192 - val_acc: 0.2574\n",
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 713us/step - loss: 1.7553 - acc: 0.4237 - val_loss: 1.9295 - val_acc: 0.3640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3d006f668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-P_eKgE1yqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = model.layers[4].kernel\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19bc9c7b-f444-42da-9dcf-0eb5cb000dbd",
        "id": "g6rmQdDrNeYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3d_4 (3, 3, 3, 1, 2)\n",
            "conv3d_5 (4, 4, 4, 2, 4)\n",
            "conv3d_6 (4, 4, 4, 4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vQ3EuZqoQi",
        "colab_type": "text"
      },
      "source": [
        "### To print Color Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c5d4258-e392-4964-d7ad-19ca8525ba37",
        "id": "PP5fNoi1qnHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming channels\n",
        "\tincoming_channels = 4\n",
        "\tfor j in range(incoming_channels):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = pyplot.subplot(3, incoming_channels, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tpyplot.imshow(f[:, :, :,j], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAACeCAYAAACGoUnQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBM6yqw3qh3Q",
        "colab_type": "text"
      },
      "source": [
        "### To print Gray scale image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnYdGbqnZ3pg",
        "colab_type": "code",
        "outputId": "dd2d112f-229d-4299-ee37-22e8f2b63000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming channels\n",
        "\tincoming_channels = 4\n",
        "\tfor j in range(incoming_channels):\n",
        "\t\t# Range of Depth of the kernel .i.e. 3\n",
        "\t\tDepth = 4\n",
        "\t\tfor k in range(Depth):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = pyplot.subplot((outgoing_channels*Depth), incoming_channels, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tpyplot.imshow(f[:, :, k,j], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAADrCAYAAAA40BDOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4s_VHK_PNWCO"
      },
      "source": [
        "## Conv2D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a13d4066-6386-4c6c-86c0-0d1d27415c05",
        "id": "1G6Jyc2_NP93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=2, input_shape=(224,224,3), kernel_size=(3,3), strides=(4,4), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=4, kernel_size=(3,3), strides=(1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=2, kernel_size=(3,3), strides=(1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epoch_gradient = []\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "    \n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Succesfully downloaded', '17flowers.tgz', 60270631, 'bytes.')\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 2)         56        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 56, 56, 2)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 4)         76        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 56, 56, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 56, 56, 2)         74        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 56, 56, 2)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               627300    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 629,223\n",
            "Trainable params: 629,223\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1088/1088 [==============================] - 14s 13ms/step - loss: 2.8319 - acc: 0.0533 - val_loss: 2.8246 - val_acc: 0.0662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 567us/step - loss: 2.7434 - acc: 0.2426 - val_loss: 2.7336 - val_acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 579us/step - loss: 2.2730 - acc: 0.4384 - val_loss: 2.4033 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 555us/step - loss: 1.3170 - acc: 0.6884 - val_loss: 2.2917 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of epochs run: 4\n",
            "Gradient Array has the shape: (4, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSYQQEW9vDj",
        "colab_type": "code",
        "outputId": "8cde4e2a-88f5-4416-9858-8523bfcfdb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import numpy as np\n",
        "x = model.layers[4].kernel\n",
        "gr = tf.get_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    conv1_kernel_val = gr.get_tensor_by_name('conv1/kernel:0').eval()\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.07628679  0.31725606]\n",
            "   [-0.29280648  0.10707554]\n",
            "   [-0.1409379  -0.14117424]\n",
            "   [-0.04934797 -0.17769067]]\n",
            "\n",
            "  [[-0.22811215  0.2088342 ]\n",
            "   [ 0.12845007 -0.10234594]\n",
            "   [ 0.29518536  0.22939327]\n",
            "   [-0.102254   -0.16633217]]\n",
            "\n",
            "  [[ 0.23566589  0.06252447]\n",
            "   [ 0.12485743 -0.2845057 ]\n",
            "   [ 0.17910227 -0.09911792]\n",
            "   [ 0.09142479 -0.17152238]]]\n",
            "\n",
            "\n",
            " [[[-0.23811015 -0.16541886]\n",
            "   [-0.33333215 -0.13665256]\n",
            "   [ 0.09643212  0.07662854]\n",
            "   [ 0.05305314 -0.23696613]]\n",
            "\n",
            "  [[ 0.0339109   0.16784325]\n",
            "   [-0.04169551 -0.0482665 ]\n",
            "   [ 0.08657351  0.12973014]\n",
            "   [ 0.05880824  0.05947757]]\n",
            "\n",
            "  [[ 0.11017862 -0.14729127]\n",
            "   [ 0.2464253  -0.19549426]\n",
            "   [-0.2609269   0.25060275]\n",
            "   [-0.26333413 -0.13276713]]]\n",
            "\n",
            "\n",
            " [[[-0.06246376  0.0363799 ]\n",
            "   [-0.02949128  0.32878068]\n",
            "   [ 0.15073076 -0.30452785]\n",
            "   [-0.24252614 -0.09735529]]\n",
            "\n",
            "  [[ 0.23945466  0.01562142]\n",
            "   [ 0.22383246  0.09923801]\n",
            "   [-0.2536789  -0.09304142]\n",
            "   [-0.22144732  0.3057051 ]]\n",
            "\n",
            "  [[ 0.05687061 -0.2811746 ]\n",
            "   [-0.2436115  -0.1616823 ]\n",
            "   [ 0.06709924 -0.24549572]\n",
            "   [ 0.04901949 -0.06542149]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a22d8ba-a297-43c2-b58a-36280e0b695c",
        "id": "lQneZbNRNP98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(filters[:,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_4 (3, 3, 3, 2)\n",
            "conv2d_5 (3, 3, 2, 4)\n",
            "conv2d_6 (3, 3, 4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d82d2727-0fe7-4a83-cf25-de643d609776",
        "id": "xnNFITm2NP-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing filters\n",
        "n_filters, ix = 2, 1 \n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t#print(f)\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming filters\n",
        "\tfor j in range(4):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = pyplot.subplot(3, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
        "\t  #print(f[:, :, j])\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAADrCAYAAADwvPoYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjw2f-GyThTk",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Reduce_max\n",
        "https://stackoverflow.com/questions/60277848/tensorflow-reduce-max-for-different-dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OCxARrThgJ",
        "colab_type": "code",
        "outputId": "d9069138-1565-411e-d052-fab527b16df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a Ragged Tensor of variable length\n",
        "rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Apply reduce_max to get the max value along axis=1\n",
        "rt = tf.reduce_max(rt, axis=1)\n",
        "print(\"Reduce Max Tensor:\",\"\\n\",rt,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " <tf.RaggedTensor [[9, 8, 7], [], [6, 5], [4]]> \n",
            "\n",
            "Tensor of same length: \n",
            " tf.Tensor(\n",
            "[[9 8 7]\n",
            " [0 0 0]\n",
            " [6 5 0]\n",
            " [4 0 0]], shape=(4, 3), dtype=int32) \n",
            "\n",
            "Reduce Max Tensor: \n",
            " tf.Tensor([9 0 6 4], shape=(4,), dtype=int32) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzPFRXDg4Di0",
        "colab_type": "text"
      },
      "source": [
        "# Save and Load Model using Keras\n",
        "https://stackoverflow.com/questions/60198878/proper-way-to-save-model-in-keras\n",
        "\n",
        "Good Article for Load and Save in Keras - https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kEKp1C76nw6",
        "colab_type": "text"
      },
      "source": [
        "## Build and Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeSykV1cqtSm",
        "colab_type": "code",
        "outputId": "2fae9b6e-49b2-4a3e-e660-8390293f6ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# MLP for Pima Indians Dataset saved to single file\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "#model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "accuracy: 75.39%\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYVNZs-6ujU",
        "colab_type": "text"
      },
      "source": [
        "## Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7iWQwy5KP8",
        "colab_type": "code",
        "outputId": "c925bc56-29c0-4bab-8623-52856e91661d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# summarize model.\n",
        "model.summary()\n",
        "\n",
        "# load dataset\n",
        "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "accuracy: 75.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fARWvSOS0xo",
        "colab_type": "text"
      },
      "source": [
        "# Feed Dict Example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYzDEyNw-qYu",
        "colab_type": "code",
        "outputId": "8adf273d-edbd-4d44-8412-f382940ad0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = x * 42\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  train_accuracy = y.eval(session=sess,feed_dict={x: (2, 4)})\n",
        "  print(train_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 84. 168.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvdRR4EyO6-",
        "colab_type": "text"
      },
      "source": [
        "# Dealing with Session Error Explained\n",
        "https://stackoverflow.com/questions/61006702/cannot-use-the-given-session-to-evaluate-tensor-the-tensors-graph-is-different"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1v2ptOIvyc",
        "colab_type": "text"
      },
      "source": [
        "## Simple Error and Fix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybmrlAanGFK",
        "colab_type": "code",
        "outputId": "765073db-13b0-4c71-b4fe-a04db6b5d3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "s = tf.Session(graph=g)\n",
        "with s.as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                  # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval()) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-56f6710c85ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5396\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5399\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhZjS6zEqHYg",
        "colab_type": "code",
        "outputId": "cdbf2509-90ca-4d6b-f90e-ce9741d8a828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "  y = tf.constant(2.0) # y is created in graph g\n",
        "\n",
        "s = tf.Session(graph=g)\n",
        "with s.as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  print(y.eval()) # y was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssuiDS6xJxkn",
        "colab_type": "text"
      },
      "source": [
        "## Error and Fix Explained in Detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvI2gcXuUZ_A",
        "colab_type": "text"
      },
      "source": [
        "### Error with default session and using variable created in another graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c68196dd-39c9-4e4f-b074-9630c2d3d207",
        "id": "_MjHucq4TEJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session().as_default() as sess:\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  \n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                  # which is tied to graph g, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f35cb204cf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, and is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;31m# default session, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x was created in graph g and it is evaluated in session s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# which is tied to graph g, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyAx1Zp1Us4F",
        "colab_type": "text"
      },
      "source": [
        "### Error with graph session as default and using variable created in default graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og4q09R-GHlL",
        "colab_type": "code",
        "outputId": "08030e4e-bd58-4126-bad6-51e9a8e86096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval()) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6b8b687c5178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5396\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5399\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ecy2vH3X6gU"
      },
      "source": [
        "### Error with graph session as default and using variable created in default graph and also session=sess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6281a25e-0b0e-48a1-f713-0dc083f4d347",
        "id": "EoznhA2nX6gW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-83809aa4e485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0zJAoNLU7pu",
        "colab_type": "text"
      },
      "source": [
        "### Fix with default session and variable not assigned to any graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "42c47425-d833-4f5b-f9f3-196dbf8bef18",
        "id": "5Nx158TXTCT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(1.0)  # x is in not assigned to any graph\n",
        "\n",
        "with tf.Session().as_default() as sess:\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  \n",
        "  print(x.eval(session=sess)) # x not assigned to any graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1qthgoVMUL",
        "colab_type": "text"
      },
      "source": [
        "### The best fix is to cleanly separate the construction phase and the execution phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UftJHIz3VM4d",
        "colab_type": "code",
        "outputId": "40824b97-fc1e-4135-ada3-a2f657975046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "  y = tf.constant(2.0) # y is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  print(y.eval()) # y was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x-CnHNIH0r1",
        "colab_type": "text"
      },
      "source": [
        "# softmax, log_softmax and sigmoid\n",
        "https://stackoverflow.com/questions/59129169/some-clarification-about-what-an-image-recognition-cnn-should-return-on-predicti/61389763#61389763\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odVe5AwJH023",
        "colab_type": "code",
        "outputId": "54337266-afc8-430d-eb5e-033b4944937c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "x = tf.nn.softmax([0.12345,0.3256,0.2356,-0.3256,0.13562])\n",
        "y = tf.nn.log_softmax([0.12345,0.3256,0.2356,-0.3256,0.13562])\n",
        "\n",
        "x1 = tf.nn.softmax([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "y1 = tf.nn.log_softmax([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "   print(x.eval())\n",
        "   print(y.eval())\n",
        "   print(x1.eval())\n",
        "   print(y1.eval())   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20027274 0.24514017 0.22404124 0.12782091 0.20272495]\n",
            "[-1.6080751 -1.4059252 -1.4959252 -2.057125  -1.5959052]\n",
            "[0.01165623 0.03168492 0.08612854 0.23412165 0.6364086 ]\n",
            "[-4.4519143 -3.4519143 -2.4519143 -1.4519144 -0.4519144]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "04e87947-47db-4d19-833d-b8b079f402c8",
        "id": "Gbt3FIIsVzJl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assume below is the input to last layer\n",
        "Input = tf.constant(np.array([[0.1, 0.3, 0.5, 1.5]]))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "   # Computes softmax activations. softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
        "   # Output sums upto 1, as this is the probability\n",
        "   print(tf.nn.softmax(Input).eval()) \n",
        "\n",
        "   # Computes log softmax activations.For each batch i and class j we have logsoftmax = logits - log(reduce_sum(exp(logits), axis))\n",
        "   # Gives log(softmax(input)) as output which is log likelihood and value doesn't sum up to 1.\n",
        "   print(tf.nn.log_softmax(Input).eval()) \n",
        "\n",
        "   # Manual computation of log_softmax\n",
        "   a = tf.nn.softmax(Input).eval()\n",
        "   b = np.array(a)\n",
        "   print(np.log(b))\n",
        "\n",
        "   # Computes sigmoid of x element-wise. Specifically, y = 1 / (1 + exp(-x)).\n",
        "   print(tf.nn.sigmoid(Input).eval())  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.12872618 0.15722651 0.1920369  0.52201041]]\n",
            "[[-2.05006775 -1.85006775 -1.65006775 -0.65006775]]\n",
            "[[-2.05006775 -1.85006775 -1.65006775 -0.65006775]]\n",
            "[[0.52497919 0.57444252 0.62245933 0.81757448]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDqxUBulbZua",
        "colab_type": "text"
      },
      "source": [
        "# Tensor to array\n",
        "https://stackoverflow.com/questions/59875172/typeerror-when-trying-to-use-earlystopping-with-f1-metric-as-stopping-criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syOHTseMZN5F",
        "colab_type": "code",
        "outputId": "9adb1ba5-0d4e-443a-e71b-468f7661ec19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "print(tf.__version__)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.constant([1,2,3,4,5,6])\n",
        "print(\"Type of x:\",x)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  y = np.array(x.eval())\n",
        "  print(\"Type of y:\",y.shape,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "Type of x: Tensor(\"Const_24:0\", shape=(6,), dtype=int32)\n",
            "Type of y: (6,) [1 2 3 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yg9AIIvdD7b",
        "colab_type": "text"
      },
      "source": [
        "# Fit_generator simple example.\n",
        "\n",
        "https://stackoverflow.com/questions/59417210/keras-losing-axis-with-brightness-range-during-image-augmentation\n",
        "\n",
        "\n",
        "Also example on hanling list. You can find it during Visualization where I have mulitplied list value by 100.\n",
        "\n",
        "https://stackoverflow.com/questions/61080410/cnn-accuracy-y-axis-range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b1ac404-0b84-4e1e-a583-b7c2ed854848",
        "id": "iJ2O5F28dF3i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", \n",
        "          loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "          train_data_gen,\n",
        "          steps_per_epoch=total_train // batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=val_data_gen,\n",
        "          validation_steps=total_val // batch_size)\n",
        "\n",
        "val_accuracy = [i * 100 for i in history.history['val_accuracy']]\n",
        "plt.plot(val_accuracy)\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Val Accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From <ipython-input-32-0eb8b71d03a3>:74: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 10s 689ms/step - loss: 0.9475 - accuracy: 0.5068 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 11s 700ms/step - loss: 0.6876 - accuracy: 0.5021 - val_loss: 0.6813 - val_accuracy: 0.4955\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 11s 733ms/step - loss: 0.6599 - accuracy: 0.5529 - val_loss: 0.6421 - val_accuracy: 0.6105\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 11s 748ms/step - loss: 0.6041 - accuracy: 0.6480 - val_loss: 0.6185 - val_accuracy: 0.6920\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 10s 697ms/step - loss: 0.5682 - accuracy: 0.6843 - val_loss: 0.6029 - val_accuracy: 0.6540\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 11s 707ms/step - loss: 0.5207 - accuracy: 0.7372 - val_loss: 0.5908 - val_accuracy: 0.6719\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 11s 708ms/step - loss: 0.4971 - accuracy: 0.7404 - val_loss: 0.6015 - val_accuracy: 0.6752\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 10s 692ms/step - loss: 0.4628 - accuracy: 0.7740 - val_loss: 0.5982 - val_accuracy: 0.7042\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 11s 701ms/step - loss: 0.4281 - accuracy: 0.7837 - val_loss: 0.6484 - val_accuracy: 0.6484\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 10s 689ms/step - loss: 0.4054 - accuracy: 0.7965 - val_loss: 0.6130 - val_accuracy: 0.6775\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 11s 703ms/step - loss: 0.3732 - accuracy: 0.8178 - val_loss: 0.6456 - val_accuracy: 0.7165\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 11s 702ms/step - loss: 0.3402 - accuracy: 0.8365 - val_loss: 0.6787 - val_accuracy: 0.6540\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 10s 695ms/step - loss: 0.3025 - accuracy: 0.8627 - val_loss: 0.7162 - val_accuracy: 0.7031\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 10s 682ms/step - loss: 0.2735 - accuracy: 0.8798 - val_loss: 0.7543 - val_accuracy: 0.6797\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 10s 697ms/step - loss: 0.2449 - accuracy: 0.8819 - val_loss: 0.8991 - val_accuracy: 0.6652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV0G_dRbOUoa",
        "colab_type": "code",
        "outputId": "4132f3be-b163-484f-89a9-059249453b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "val_accuracy = [i * 100 for i in history.history['val_accuracy']]\n",
        "plt.plot(val_accuracy)\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Val Accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwhjPAkYvkBV",
        "colab_type": "text"
      },
      "source": [
        "# Convert Functional Model to Sequential and Vice Versa\n",
        "https://stackoverflow.com/questions/61130836/convert-functional-model-to-sequential-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWjlUrHl0Nr1",
        "colab_type": "text"
      },
      "source": [
        "## User Code has one functional model and another sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbKDJJn5vka7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "#load in data using imagedatagenreator\n",
        "input_img = Input(shape=(128, 128,3))\n",
        "\n",
        "x = Convolution2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (8, 4, 4) i.e. 128-dimensional\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Convolution2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "#compile and run\n",
        "\n",
        "##save weights and and model start conv network with these weights\n",
        "encoder = Model(input_img, encoded)\n",
        "encoder.save('Encoded.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-lHnunPzC4q",
        "colab_type": "code",
        "outputId": "e229e05b-a444-475a-c065-29f517502e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#load in data using imagedatagenreator\n",
        "x = load_model('Encoded.h5')\n",
        "x.summary()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(encoded)\n",
        "model.add(Conv2D(64,(3,3), input_shape=(424,424,3), activation='relu'))#3x3 is default\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "#model.add(Dropout(.1))#test\n",
        "model.add(Dense(32, activation='relu'))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(.3))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Flatten(input_shape=(424,424,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 128, 128, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_72 (MaxPooling (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 64, 64, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_73 (MaxPooling (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_74 (MaxPooling (None, 16, 16, 8)         0         \n",
            "=================================================================\n",
            "Total params: 2,192\n",
            "Trainable params: 2,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-abc7db2e7aa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m424\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m424\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#3x3 is default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    172\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    173\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"max_pooling2d_74/Identity:0\", shape=(None, 16, 16, 8), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9_kieW013Bh"
      },
      "source": [
        "## Convert functional model to sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dFclXAGr1u3Q",
        "outputId": "2aad0bd2-ed53-41c4-dbeb-a978e21b6d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "# Create the Sequential Model\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(16, (3, 3), input_shape=(424,424,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Save the Model and Architecture\n",
        "model.save('Encoded.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 53, 53, 8)         0         \n",
            "=================================================================\n",
            "Total params: 2,192\n",
            "Trainable params: 2,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0b3bd82b-5ec8-4264-a6a0-ab73bf2b647c",
        "id": "PIp5DMAb1u3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the previoulsy saved enocdermodel \n",
        "model = load_model('Encoded.h5')\n",
        "\n",
        "# Add the additonal layers \n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#3x3 is default\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "#model.add(Dropout(.1))#test\n",
        "model.add(Dense(32, activation='relu'))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(.3))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Flatten(input_shape=(424,424,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Model summary \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 53, 53, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 51, 51, 64)        4672      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 17, 17, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5, 5, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 68,914\n",
            "Trainable params: 68,786\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XjDDrht_4wca"
      },
      "source": [
        "## Convert sequential model to functional model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "283hoBLI49D4",
        "outputId": "e1e91253-5ea9-469b-b632-12ffa2414a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "#load in data using imagedatagenreator\n",
        "input_img = Input(shape=(424,424,3))\n",
        "\n",
        "x = Convolution2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "##save weights and and model start conv network with these weights\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# Model Summary\n",
        "encoder.summary()\n",
        "\n",
        "encoder.save('Encoded.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 424, 424, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 53, 53, 8)         0         \n",
            "=================================================================\n",
            "Total params: 2,192\n",
            "Trainable params: 2,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e09aee33-71c0-4197-8acc-e2635825bd46",
        "id": "tlicujIp4wcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the previoulsy saved enocdermodel \n",
        "load_model('Encoded.h5')\n",
        "\n",
        "# Add the additonal layers \n",
        "x = Convolution2D(64,(3,3), activation='relu')(encoded)#3x3 is default\n",
        "x = MaxPooling2D(pool_size=(3,3))(x)\n",
        "#model.add(Dropout(.1))#test\n",
        "x = Dense(32, activation='relu')(x)#test\n",
        "x = Conv2D(64,(3,3), activation='relu')(x)#input_shape=(424,424,3)\n",
        "x = MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(.3)(x)#test\n",
        "x = Conv2D(64,(3,3), activation='relu')(x)#input_shape=(424,424,3)\n",
        "x = MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = Dropout(.3)(x)\n",
        "x = Flatten(input_shape=(424,424,3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "##save weights and and model start conv network with these weights\n",
        "model = Model(input_img, output)\n",
        "\n",
        "# Model summary \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 424, 424, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 53, 53, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 51, 51, 64)        4672      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 17, 17, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 5, 5, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 68,914\n",
            "Trainable params: 68,786\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr6jOpefsMfJ",
        "colab_type": "text"
      },
      "source": [
        "# Custom Loss Function Example\n",
        "https://stackoverflow.com/questions/59415275/custom-metric-in-multi-output-keras-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iqSwN-KLsMyo",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define custom loss\n",
        "# Create a loss function that adds the MSE loss to the mean of all squared activations\n",
        "def custom_loss(y_pred1, y_true1, y_pred2, y_true2):\n",
        "    Loss = 0\n",
        "\n",
        "    def loss1(y_true1,y_pred1):\n",
        "        return np.square(np.subtract(y_true1,y_pred1)).mean()\n",
        "\n",
        "    def loss2(y_true2,y_pred2):\n",
        "        return np.square(np.subtract(y_true2,y_pred2)).mean()\n",
        "\n",
        "    def finalloss(y_pred1, y_true1, y_pred2, y_true2):\n",
        "        Loss = loss1(y_pred1, y_true1) + loss2(y_pred2, y_true2)\n",
        "        if(y_pred1 == y_true1 and y_pred2 == y_true2):\n",
        "           return(0)\n",
        "        elif(y_pred1 == y_true1 and y_pred2 != y_true2):\n",
        "            return(0.5 * Loss)\n",
        "        elif(y_pred1 != y_true1 and y_pred2 == y_true2):\n",
        "            return(0.5 * Loss)    \n",
        "        else:\n",
        "            return(Loss)\n",
        "    \n",
        "    return finalloss(y_pred1, y_true1, y_pred2, y_true2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d6355f1a-9e19-4e4c-9cd2-1c864c8386d3",
        "id": "WS7_W346sMyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "custom_loss(1,1,7,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bidzXGhKqbi",
        "colab_type": "text"
      },
      "source": [
        "# Layer Concatentation\n",
        "https://stackoverflow.com/questions/59470195/how-to-achieve-elementwise-convolution-for-two-tensors-using-tensorflow/61206149#61206149"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c5af32b7-8f38-4e13-bdd2-eabde96fe0e0",
        "id": "pStHKGBpKrGB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Conv2D, ZeroPadding2D\n",
        "from keras.optimizers import Adagrad\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "input_img1 = Input(shape=(44,44,3))\n",
        "x1 = Conv2D(3, (3, 3), activation='relu', padding='same')(input_img1)\n",
        "\n",
        "input_img2 = Input(shape=(34,34,3))\n",
        "x2 = Conv2D(3, (3, 3), activation='relu', padding='same')(input_img2)\n",
        "# Zero Padding of 5 at the top, bottom, left and right side of an image tensor\n",
        "x3 = ZeroPadding2D(padding = (5,5))(x2)\n",
        "\n",
        "# Concatenate works as layers have same size output\n",
        "x4 = concatenate([x1,x3])\n",
        "\n",
        "output = Dense(18, activation='relu')(x4)\n",
        "\n",
        "model = Model(inputs=[input_img1,input_img2], outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_91 (InputLayer)           (None, 34, 34, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_90 (InputLayer)           (None, 44, 44, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 34, 34, 3)    84          input_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 44, 44, 3)    84          input_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 44, 44, 3)    0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 44, 44, 6)    0           conv2d_72[0][0]                  \n",
            "                                                                 zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 44, 44, 18)   126         concatenate_30[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 294\n",
            "Trainable params: 294\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxJFmEBwNETf",
        "colab_type": "code",
        "outputId": "393f585f-a114-456b-c6b6-f2ad449a5294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
        "from keras.optimizers import Adagrad\n",
        "\n",
        "first_input = Input(shape=(5, ))\n",
        "first_dense = Dense(8, )(first_input)\n",
        "\n",
        "second_input = Input(shape=(2, ))\n",
        "second_dense = Dense(1, )(second_input)\n",
        "\n",
        "merge_one = concatenate([first_dense, second_dense])\n",
        "\n",
        "third_input = Input(shape=(1, ))\n",
        "merge_two = concatenate([merge_one, third_input])\n",
        "\n",
        "model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
        "model.summary()\n",
        "ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 2)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 8)            48          input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            3           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 9)            0           dense_7[0][0]                    \n",
            "                                                                 dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 10)           0           concatenate_7[0][0]              \n",
            "                                                                 input_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qT-WEv-Hcbf",
        "colab_type": "text"
      },
      "source": [
        "# Simple CNN Model\n",
        "https://stackoverflow.com/questions/59211403/find-the-output-node-in-a-alexnet-implementation-in-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yhu0tLPwwUv",
        "colab_type": "code",
        "outputId": "9217a0a2-3429-4e7b-a17f-253932d0dce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Add the layers \n",
        "model = Sequential()\n",
        "model.add(Conv2D(64,(3,3), input_shape=(424,424,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(.3))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Flatten(input_shape=(424,424,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Model summary \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 422, 422, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 140, 140, 64)      0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 140, 140, 32)      2080      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 138, 138, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 46, 46, 64)        4160      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 25090     \n",
            "=================================================================\n",
            "Total params: 138,722\n",
            "Trainable params: 113,634\n",
            "Non-trainable params: 25,088\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Y-P2iRET0Q",
        "colab_type": "code",
        "outputId": "3cd0e62c-f497-4e2e-e288-4e23ab78c8a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# To print all the layers of the Model\n",
        "print(\"All the Layers of the Model:\")\n",
        "for layers in model.layers:\n",
        "    print(layers)\n",
        "print(\"\\n\")\n",
        "\n",
        "# To print first layer OR Input layer of the Model\n",
        "print(\"Input Layer of the Model:\",\"\\n\",model.layers[0],\"\\n\")\n",
        "\n",
        "# To print last layer OR Output layer of the Model\n",
        "print(\"Output Layer of the Model:\",\"\\n\",model.layers[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All the Layers of the Model:\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7faa09294550>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7faa09294cf8>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7faa09294d30>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7faa0044e780>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7faa0046fda0>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7faa09294f98>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7faa00477da0>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7faa0046ff60>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7faa004412b0>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7faa00477f60>\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7faa004802b0>\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7faa003d0b00>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7faa00441588>\n",
            "\n",
            "\n",
            "Input Layer of the Model: \n",
            " <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7faa09294550> \n",
            "\n",
            "Output Layer of the Model: \n",
            " <tensorflow.python.keras.layers.core.Dense object at 0x7faa00441588>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ua8kbaTRrxQ",
        "colab_type": "text"
      },
      "source": [
        "# Build, Save and Load the Model using Tensorflow\n",
        "https://stackoverflow.com/questions/57320623/how-to-load-a-pre-trained-cnn-model-in-tensorflow-and-test-the-results-with-unkn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaHu9z86RC8c",
        "colab_type": "code",
        "outputId": "de32094e-95dd-41ba-f8af-3edb7ce763e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5py\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "accuracy: 75.00%\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: model.h5py/assets\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7oGxTd1R991",
        "colab_type": "code",
        "outputId": "114d3757-3162-46b3-bf0c-598be174bf23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from tensorflow.keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('model.h5py')\n",
        "\n",
        "# summarize model\n",
        "model.summary()\n",
        "\n",
        "# LOAD THE NEW DATASET HERE\n",
        "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "accuracy: 75.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7tP401fS4a4",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks with Kernel Visualization for Tensorflow\n",
        "\n",
        "https://stackoverflow.com/questions/56921769/how-we-can-implement-gradient-based-neural-network-visualization-using-tensorflo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "96abbc0e-38bf-45fb-ca05-67862b79661d",
        "id": "ARlELIXphJ4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=5, input_shape=(224,224,3), kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=10, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=5, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(5, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epoch_gradient = []\n",
        "epoch_count = 0\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model._feed_inputs + model._feed_targets + model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      print(\"\\n\",\"Calculating Gradient for Epoch \",(epoch+1))\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "\n",
        "      # Visualize the Kernels for Layer 5 of the Model\n",
        "      print(\"\\n\",\"Visualizing the kernels for Layer 5 of the Model for Epoch \",(epoch+1))  \n",
        "      # retrieve weights from the second hidden layer\n",
        "      filters, biases = model.layers[4].get_weights()\n",
        "      # normalize filter values to 0-1 so we can visualize them\n",
        "      f_min, f_max = filters.min(), filters.max()\n",
        "      filters = (filters - f_min) / (f_max - f_min)\n",
        "      # plot all the filters\n",
        "      # n_filters = outgoing filters\n",
        "      n_filters, ix = 10, 1 \n",
        "      for i in range(n_filters):\n",
        "      \t# get the filter\n",
        "      \tf = filters[:, :, :, i]\n",
        "      \t# Range of incoming filters\n",
        "      \tfor j in range(5):\n",
        "      \t\t# specify subplot and turn of axis\n",
        "      \t\tax = pyplot.subplot(10, 5, ix)\n",
        "      \t\tax.set_xticks([])\n",
        "      \t\tax.set_yticks([])\n",
        "      \t\t# plot filter channel in grayscale\n",
        "      \t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
        "      \t\tix += 1\n",
        "      # show the figure\n",
        "      pyplot.show()\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "\n",
        "# Convert to a array\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Shape of the Captured Gradient Array :\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_87 (Conv2D)           (None, 224, 224, 5)       140       \n",
            "_________________________________________________________________\n",
            "activation_145 (Activation)  (None, 224, 224, 5)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 112, 112, 5)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 112, 112, 5)       20        \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 112, 112, 10)      460       \n",
            "_________________________________________________________________\n",
            "activation_146 (Activation)  (None, 112, 112, 10)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 56, 56, 10)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 56, 56, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 56, 56, 5)         455       \n",
            "_________________________________________________________________\n",
            "activation_147 (Activation)  (None, 56, 56, 5)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 28, 28, 5)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 28, 28, 5)         20        \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 3920)              0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 5)                 19605     \n",
            "_________________________________________________________________\n",
            "activation_148 (Activation)  (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 17)                102       \n",
            "_________________________________________________________________\n",
            "activation_149 (Activation)  (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 20,842\n",
            "Trainable params: 20,802\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            " 960/1088 [=========================>....] - ETA: 0s - loss: 2.8102 - acc: 0.1094\n",
            " Calculating Gradient for Epoch  1\n",
            "\n",
            " Visualizing the kernels for Layer 5 of the Model for Epoch  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 50 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1088/1088 [==============================] - 9s 8ms/sample - loss: 2.7977 - acc: 0.1121 - val_loss: 2.8206 - val_acc: 0.1250\n",
            "Epoch 2/4\n",
            " 960/1088 [=========================>....] - ETA: 0s - loss: 2.5060 - acc: 0.1979\n",
            " Calculating Gradient for Epoch  2\n",
            "\n",
            " Visualizing the kernels for Layer 5 of the Model for Epoch  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 50 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1088/1088 [==============================] - 6s 5ms/sample - loss: 2.5227 - acc: 0.1921 - val_loss: 2.8027 - val_acc: 0.1140\n",
            "Epoch 3/4\n",
            " 960/1088 [=========================>....] - ETA: 0s - loss: 2.3459 - acc: 0.2583\n",
            " Calculating Gradient for Epoch  3\n",
            "\n",
            " Visualizing the kernels for Layer 5 of the Model for Epoch  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 50 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1088/1088 [==============================] - 5s 5ms/sample - loss: 2.3493 - acc: 0.2592 - val_loss: 2.7985 - val_acc: 0.0956\n",
            "Epoch 4/4\n",
            " 960/1088 [=========================>....] - ETA: 0s - loss: 2.1954 - acc: 0.3063\n",
            " Calculating Gradient for Epoch  4\n",
            "\n",
            " Visualizing the kernels for Layer 5 of the Model for Epoch  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 50 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1088/1088 [==============================] - 6s 5ms/sample - loss: 2.1978 - acc: 0.3006 - val_loss: 2.8202 - val_acc: 0.0551\n",
            "Shape of the Captured Gradient Array : (4, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu7KSLAKiAvN",
        "colab_type": "code",
        "outputId": "a9064279-b6aa-4a6b-d6ae-9d95d69cd2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_3 (3, 3, 3, 5)\n",
            "conv2d_4 (3, 3, 5, 10)\n",
            "conv2d_5 (3, 3, 10, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_cMruHV4rl3",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Calculation using tf.grandienttape\n",
        "https://stackoverflow.com/questions/59447329/how-to-compute-final-gradients-from-multiple-intermediate-gradients-in-neural-ne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LQPYsd17Ovv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WAuqVktBCod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.convert_to_tensor(x)\n",
        "y = tf.convert_to_tensor(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSV5KdR55eBv",
        "colab": {}
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import math\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "#optimizer = Adam(lr=0.001)\n",
        "#weight_init = RandomNormal()\n",
        "    \n",
        "bs = 5\n",
        "text_len_1 = 772\n",
        "text_len_2 = 741\n",
        "embed_size = 300\n",
        "in_channels = 1\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=10, kernel_size=(2, embed_size),\n",
        "                                                    dilation_rate=(dilation, 1),\n",
        "                                                    padding='valid'))\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=5, input_shape=(224,224,3), kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=10, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=5, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(5, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    preds = model(x)\n",
        "\n",
        "grads = tape.gradient(preds, model.trainable_variables)\n",
        "print(grads)\n",
        "\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "# def step(real_x, real_y):\n",
        "#     with tf.GradientTape() as tape:\n",
        "#         # Make prediction\n",
        "#         pred_y = model(x)\n",
        "#         # Calculate loss\n",
        "#         model_loss = tf.keras.losses.categorical_crossentropy(real_y, pred_y)\n",
        "    \n",
        "#     # Calculate gradients\n",
        "#     model_gradients = tape.gradient(model_loss, model.trainable_variables)\n",
        "#     # Update model\n",
        "#     optimizer.apply_gradients(zip(model_gradients, model.trainable_variables))\n",
        "\n",
        "# # Training loop\n",
        "# bat_per_epoch = math.floor(x.shape / batch_size)\n",
        "# for epoch in range(epochs):\n",
        "#     print('=', end='')\n",
        "#     for i in range(bat_per_epoch):\n",
        "#         n = i*batch_size\n",
        "#         step(x[n:n+batch_size], y[n:n+batch_size])\n",
        "\n",
        "# # Calculate accuracy\n",
        "# # Compile \n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# #model.compile(optimizer=optimizer, loss=tf.keras.losses.categorical_crossentropy, metrics=['acc']) # Compile just for evaluation\n",
        "# #print('\\n', model.evaluate(x_test, y_test, verbose=0)[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQPHM90E6DE-",
        "colab_type": "code",
        "outputId": "a58dd9cf-2c74-4e1b-8e25-3eb60932e8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "print(grads.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7e64d0b63cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grads' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8DyK9MYq80E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le6Ro1z2_h0g",
        "colab_type": "text"
      },
      "source": [
        "# MobileNetV2 with Statistics\n",
        "https://stackoverflow.com/questions/58868086/validation-loss-and-validation-accuracy-curve-fluctuating/61360288#61360288"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raU9vkDMFawR",
        "colab_type": "code",
        "outputId": "beaddbb4-b8c3-41e4-9028-728b3fe7a45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.utils.layer_utils import count_params\n",
        "\n",
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False)\n",
        "\n",
        "#base_model.summary()\n",
        "trainable_count = count_params(base_model.trainable_weights)\n",
        "non_trainable_count = count_params(base_model.non_trainable_weights)\n",
        "print(\"\\n\",color.BOLD + '  base_model Statistics !' + color.END)\n",
        "print(\"Trainable Parameters :\", color.BOLD + str(trainable_count) + color.END)\n",
        "print(\"Non Trainable Parameters :\", non_trainable_count,\"\\n\")\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1025, activation='relu')(x)\n",
        "x = Dense(1025, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "preds = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=preds)\n",
        "\n",
        "#model.summary()\n",
        "trainable_count = count_params(model.trainable_weights)\n",
        "non_trainable_count = count_params(model.non_trainable_weights)\n",
        "print(color.BOLD + '    model Statistics !' + color.END)\n",
        "print(\"Trainable Parameters :\", color.BOLD + str(trainable_count) + color.END)\n",
        "print(\"Non Trainable Parameters :\", non_trainable_count,\"\\n\")\n",
        "\n",
        "new_weights_added = count_params(model.trainable_weights) - count_params(base_model.trainable_weights)\n",
        "print(\"Additional trainable weights added to the model excluding basel model trainable weights :\", color.BOLD + str(new_weights_added) + color.END)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "\n",
            " \u001b[1m  base_model Statistics !\u001b[0m\n",
            "Trainable Parameters : \u001b[1m2223872\u001b[0m\n",
            "Non Trainable Parameters : 34112 \n",
            "\n",
            "\u001b[1m    model Statistics !\u001b[0m\n",
            "Trainable Parameters : \u001b[1m5115398\u001b[0m\n",
            "Non Trainable Parameters : 34112 \n",
            "\n",
            "Additional trainable weights added to the model excluding basel model trainable weights : \u001b[1m2891526\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvskLZ4CwFbr",
        "colab_type": "code",
        "outputId": "a85608fd-ab11-42c3-d4f1-611fe95ae327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROLJ4CN3eXkS",
        "colab_type": "text"
      },
      "source": [
        "# Simple CNN + LSTM Model\n",
        "https://stackoverflow.com/questions/58182882/cnn-lstm-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HixjAcBeXti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Conv2D, TimeDistributed, LSTM, MaxPooling2D, Flatten, Dense\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import math\n",
        "\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv2D(32, 5, 5,input_shape=(100,6,5,1))))\n",
        "model.add(TimeDistributed(MaxPooling2D(pool_size=(4, 4))))\n",
        "model.add(Activation('relu'))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(5)))  \n",
        "\n",
        "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pym2SKLNMvdf",
        "colab_type": "text"
      },
      "source": [
        "# VGG16 Model Example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9JArukgeth8",
        "colab_type": "code",
        "outputId": "77d4dbb9-b58b-4224-9f01-8ff14f7c0c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
        "from keras.utils.layer_utils import count_params\n",
        "\n",
        "resnet50_imagenet_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3),\n",
        "                           pooling='avg')\n",
        "resnet50_imagenet_model.output\n",
        "\n",
        "x = resnet50_imagenet_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(12, activation='softmax')(x)\n",
        "model = Model(inputs = resnet50_imagenet_model.input, outputs = x)\n",
        "\n",
        "count=0\n",
        "#Putting the first 176 of resnet50 layers as trainable false \n",
        "for l in resnet50_imagenet_model.layers:\n",
        "    count=count+1\n",
        "    if count <=176:\n",
        "      l.trainable = False\n",
        "\n",
        "print(count)\n",
        "#choix de l'algo d'apprentissage\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "20\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 12)                1548      \n",
            "=================================================================\n",
            "Total params: 14,781,900\n",
            "Trainable params: 67,212\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koNHbfajsb_x",
        "colab_type": "text"
      },
      "source": [
        "# Custom tf.keras.layers.RNN\n",
        "https://stackoverflow.com/questions/58872675/embed-custom-rnn-cell-with-init-that-takes-more-arguments-3-vs-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7txs2poXNW_i",
        "colab_type": "code",
        "outputId": "4f53e801-4571-4ad9-bc2a-3af4c07ee3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import RNN\n",
        "\n",
        "class MinimalRNNCell(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                      initializer='uniform',\n",
        "                                      name='kernel')\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer='uniform',\n",
        "            name='recurrent_kernel')\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        h = K.dot(inputs, self.kernel)\n",
        "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
        "        return output, [output]\n",
        "\n",
        "# Let's use this cell in a RNN layer:\n",
        "\n",
        "cell = MinimalRNNCell(32)\n",
        "x = keras.Input((None, 5))\n",
        "layer = RNN(cell)\n",
        "y = layer(x)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0f3bed686a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4090\u001b[0m     \u001b[0;31m# the value is discarded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4091\u001b[0m     output_time_zero, _ = step_function(\n\u001b[0;32m-> 4092\u001b[0;31m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4093\u001b[0m     output_ta = tuple(\n\u001b[1;32m   4094\u001b[0m         tensor_array_ops.TensorArray(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_rnn_cell\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m           \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Mrb4JWkhkJ",
        "colab_type": "code",
        "outputId": "989c0feb-de68-4989-ee89-de41a60197ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import RNN\n",
        "\n",
        "# First, let's define a RNN Cell, as a layer subclass.\n",
        "\n",
        "class MinimalRNNCell(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                      initializer='uniform',\n",
        "                                      name='kernel')\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer='uniform',\n",
        "            name='recurrent_kernel')\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        h = K.dot(inputs, self.kernel)\n",
        "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
        "        return output, [output]\n",
        "\n",
        "# Let's use this cell in a RNN layer:\n",
        "\n",
        "cell = MinimalRNNCell(32)\n",
        "x = keras.Input((None, 5))\n",
        "layer = RNN(cell)\n",
        "y = layer(x)\n",
        "\n",
        "print(\"I Ran Successfully\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "I Ran Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw7iHJ7WeP22",
        "colab_type": "text"
      },
      "source": [
        "# InceptionResNetV2 Pretrained layer output\n",
        "https://stackoverflow.com/questions/61418475/how-to-access-the-fully-connected-layer-from-pretrained-models-in-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HFVEZyomeQ_1",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.utils.layer_utils import count_params\n",
        "import numpy as np\n",
        "\n",
        "base_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1025, activation='relu')(x)\n",
        "x = Dense(1025, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "preds = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=preds)\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "count = 0\n",
        "for layer in model.layers:\n",
        "  print(count,\")\",layer,\"\\n\")\n",
        "  count = count + 1\n",
        "\n",
        "print(model.layers[782].output)  \n",
        "\n",
        "# To get weights of layer 782\n",
        "weights = model.layers[782].get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgbwAoFVgzNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnTpV_VHzrKv",
        "colab_type": "text"
      },
      "source": [
        "# Unresloved Question\n",
        "\n",
        "https://stackoverflow.com/questions/61479030/variational-autoencoder-graph-disconnected-cannot-obtain-value-for-tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByUPZS7bJTv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a12d079-562e-4ca9-f851-cf615bd4724a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Reshape, Concatenate, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.losses import mse, categorical_crossentropy\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var ) * epsilon\n",
        "\n",
        "beta = 0.5\n",
        "n_particles = 9 \n",
        "n_classes = 5 \n",
        "latent_size = 3 \n",
        "activation_func = 'relu'\n",
        "\n",
        "'Network parameters'\n",
        "input_shape_class = (n_particles, )\n",
        "input_shape_regress = (3 * n_particles + 2, )\n",
        "hidden_layer_dim = 512\n",
        "latent_dim = latent_size * n_particles\n",
        "'Build encoder'\n",
        "encoder_inputs_class = tf.keras.Input(shape=input_shape_class)\n",
        "inputs_class_t = Lambda(lambda x: K.one_hot(K.cast(x, 'int32'), n_classes))(encoder_inputs_class)\n",
        "inputs_class_t2 = Reshape((n_particles*n_classes,))(inputs_class_t)\n",
        "encoder_inputs_regress = tf.keras.Input(shape=input_shape_regress)\n",
        "inputs = Concatenate()([inputs_class_t2, encoder_inputs_regress])\n",
        "x_1 = Dense(hidden_layer_dim, activation=activation_func)(inputs)\n",
        "x_2 = Dense(int(hidden_layer_dim/2), activation=activation_func)(x_1)\n",
        "x_3 = Dense(int(hidden_layer_dim/4), activation=activation_func)(x_2)\n",
        "'Latent space'\n",
        "z_mean = Dense(latent_dim, activation='linear', name='z_mean')(x_3)\n",
        "z_log_var = Dense(latent_dim, activation='linear', name='z_log_var')(x_3)\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "encoder = Model([encoder_inputs_class, encoder_inputs_regress], [z_mean, z_log_var, z])\n",
        "encoder.summary()\n",
        "'Build decoder'\n",
        "decoder_inputs_latent = tf.keras.Input(shape=(latent_dim,))\n",
        "decoder_inputs_n_particles = tf.keras.Input(shape=(1,))\n",
        "decoder_inputs_n_particles_mask = tf.keras.Input(shape=(latent_dim, ))\n",
        "# Implement mask\n",
        "masked_latent = Lambda(lambda x: x[0]*x[1])([decoder_inputs_latent, decoder_inputs_n_particles_mask])\n",
        "x_4 = Dense(int(hidden_layer_dim/4), activation=activation_func)(masked_latent)\n",
        "x_5 = Dense(int(hidden_layer_dim/2), activation=activation_func)(x_4)\n",
        "x_6 = Dense(hidden_layer_dim, activation=activation_func)(x_5)\n",
        "outputs_class_t = Dense(n_particles*n_classes, activation='elu')(x_6)\n",
        "outputs_class_t2 = Reshape((n_particles, n_classes))(outputs_class_t)\n",
        "decoder_outputs_class = Dense(n_classes, activation='softmax')(outputs_class_t2)\n",
        "decoder_outputs_regress = Dense(n_particles*3+2, activation='linear')(x_6)\n",
        "decoder_outputs_n_particles = Dense(1, activation='linear')(x_6)\n",
        "decoder = Model([decoder_inputs_latent, decoder_inputs_n_particles, decoder_inputs_n_particles_mask], [decoder_outputs_class, decoder_outputs_regress, decoder_outputs_n_particles], name='decoder')\n",
        "decoder.summary()\n",
        "'Build autoencoder'\n",
        "vae_input_1 = tf.keras.Input(shape=input_shape_class, name = 'vae_input_1')\n",
        "vae_input_2 = tf.keras.Input(shape=input_shape_regress, name = 'vae_input_2')\n",
        "vae_input_3 = tf.keras.Input(shape=(1,), name = 'vae_input_3')\n",
        "vae_input_4 = tf.keras.Input(shape=(latent_dim, ), name = 'vae_input_4')\n",
        "outputs = decoder([encoder([vae_input_1, vae_input_2])[2], vae_input_3, vae_input_4])\n",
        "print(encoder([vae_input_1, vae_input_2])[2])\n",
        "vae = Model([vae_input_1, vae_input_2, vae_input_3, vae_input_4], outputs, name='bvae')\n",
        "vae.summary()\n",
        "'Calculate loss'\n",
        "n_particles_loss = mse(decoder_inputs_n_particles, outputs[2])\n",
        "classification_loss = categorical_crossentropy(inputs_class_t, outputs[0])\n",
        "regression_loss = mse(encoder_inputs_regress, outputs[1])\n",
        "reconstruction_loss = 100*K.mean(n_particles_loss) + K.mean(regression_loss)\n",
        "reconstruction_loss = 100*K.mean(n_particles_loss) + 10*K.mean(classification_loss) + K.mean(regression_loss)\n",
        "kl_loss = -0.5 * K.sum((1+z_log_var-K.square(z_mean)-K.exp(z_log_var)), axis=-1)\n",
        "vae_loss = K.mean((1-beta) * reconstruction_loss + beta * kl_loss)\n",
        "print(encoder([vae_input_1, vae_input_2])[2])\n",
        "print(vae_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 9, 5)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_26 (Reshape)            (None, 45)           0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 29)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 74)           0           reshape_26[0][0]                 \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_130 (Dense)               (None, 512)          38400       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_131 (Dense)               (None, 256)          131328      dense_130[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_132 (Dense)               (None, 128)          32896       dense_131[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 27)           3483        dense_132[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 27)           3483        dense_132[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 27)           0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 209,590\n",
            "Trainable params: 209,590\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_27 (Lambda)              (None, 27)           0           input_3[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_133 (Dense)               (None, 128)          3584        lambda_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_134 (Dense)               (None, 256)          33024       dense_133[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_135 (Dense)               (None, 512)          131584      dense_134[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_136 (Dense)               (None, 45)           23085       dense_135[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_27 (Reshape)            (None, 9, 5)         0           dense_136[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_137 (Dense)               (None, 9, 5)         30          reshape_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_138 (Dense)               (None, 29)           14877       dense_135[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_139 (Dense)               (None, 1)            513         dense_135[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 206,697\n",
            "Trainable params: 206,697\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Tensor(\"model_1/Identity_2:0\", shape=(None, 27), dtype=float32)\n",
            "Model: \"bvae\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "vae_input_1 (InputLayer)        [(None, 9)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vae_input_2 (InputLayer)        [(None, 29)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Model)                   [(None, 27), (None,  209590      vae_input_1[0][0]                \n",
            "                                                                 vae_input_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "vae_input_3 (InputLayer)        [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vae_input_4 (InputLayer)        [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 [(None, 9, 5), (None 206697      model[1][2]                      \n",
            "                                                                 vae_input_3[0][0]                \n",
            "                                                                 vae_input_4[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 416,287\n",
            "Trainable params: 416,287\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Tensor(\"model_2/Identity_2:0\", shape=(None, 27), dtype=float32)\n",
            "Tensor(\"Mean_83:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8c9302e944e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvae_input_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_input_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_loss\u001b[0;34m(self, losses, inputs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_graph_network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m           \u001b[0;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[0;34m(self, symbolic_loss)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m     \u001b[0mnew_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_subgraph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m     \u001b[0;31m# Losses must be keyed on inputs no matter what in order to be supported in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0;31m# DistributionStrategy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_subgraph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m   \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m   \u001b[0;31m# Keep only nodes and layers in the topology between inputs and outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1820\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1821\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1793\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_1:0\", shape=(None, 9), dtype=float32) at layer \"input_1\". The following previous layers were accessed without issue: ['vae_input_1', 'vae_input_2', 'model', 'vae_input_4', 'lambda_27', 'dense_133', 'dense_134', 'dense_135', 'dense_136', 'reshape_27', 'tf_op_layer_decoder_12/dense_137/Tensordot/Shape', 'tf_op_layer_decoder_12/dense_137/Tensordot/GatherV2', 'tf_op_layer_decoder_12/dense_137/Tensordot/GatherV2_1', 'tf_op_layer_decoder_12/dense_137/Tensordot/Prod', 'tf_op_layer_decoder_12/dense_137/Tensordot/Prod_1', 'tf_op_layer_decoder_12/dense_137/Tensordot/transpose', 'tf_op_layer_decoder_12/dense_137/Tensordot/stack', 'tf_op_layer_decoder_12/dense_137/Tensordot/Reshape', 'tf_op_layer_decoder_12/dense_137/Tensordot/MatMul', 'tf_op_layer_decoder_12/dense_137/Tensordot/concat_1', 'tf_op_layer_decoder_12/dense_137/Tensordot', 'tf_op_layer_decoder_12/dense_137/BiasAdd', 'tf_op_layer_decoder_12/dense_137/Max', 'tf_op_layer_decoder_12/dense_137/sub', 'tf_op_layer_decoder_12/dense_137/Exp', 'tf_op_layer_decoder_12/dense_137/Sum', 'tf_op_layer_decoder_12/dense_137/truediv']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8t-Tu2Cvqei",
        "colab_type": "text"
      },
      "source": [
        "# Model.fit error\n",
        "https://stackoverflow.com/questions/61469811/list-index-out-of-range-while-training-with-model-fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f30e6440-304a-4a43-9c20-15f59a9692b4",
        "id": "9wmzYL6iv1Fg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5py\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b9b0f557b27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0mindices_for_conversion_to_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m       \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGvIpFywWHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "2c50fadd-d944-4694-e99a-95911b14448c"
      },
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5py\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "acc: 70.96%\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}