{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SO_Home.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SKWwG5iU_Bt2",
        "iutilLUp9AsZ",
        "sjwfJo493IAV",
        "DEyyro-xMnwS",
        "5f2C617e-BFu",
        "g_jgkP3sdF4r",
        "_Dqzlnvmwrr3",
        "q_FhnDE9wzlF",
        "eVLkvAkPatDD",
        "pb4cJKwt2eIK",
        "z_5aAAf82LIE",
        "Iah4GD0dbRBW",
        "-1vXRhpz0mou",
        "Mk6am3SF58J6",
        "2Ip33pHpNOVU",
        "SVB8mbWfNCIF",
        "4s_VHK_PNWCO",
        "Wjw2f-GyThTk",
        "6kEKp1C76nw6",
        "cWYVNZs-6ujU",
        "0fARWvSOS0xo",
        "sUvdRR4EyO6-",
        "nj1v2ptOIvyc",
        "nvI2gcXuUZ_A",
        "nyAx1Zp1Us4F",
        "4ecy2vH3X6gU",
        "H0zJAoNLU7pu",
        "5u1qthgoVMUL",
        "7x-CnHNIH0r1",
        "xDqxUBulbZua",
        "3yg9AIIvdD7b",
        "OwhjPAkYvkBV",
        "aWjlUrHl0Nr1",
        "n9_kieW013Bh",
        "XjDDrht_4wca"
      ],
      "authorship_tag": "ABX9TyOfOJ3C0Ahc0G3UyjIOK8bA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitfattepur/Tensorflow/blob/master/SO_Home.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKWwG5iU_Bt2",
        "colab_type": "text"
      },
      "source": [
        "# Unwanted Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWPhM3KGN4TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxQKG938OI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZcVrTbBOOA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n1sw4uUOUq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCQEsTdrOaj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#for epoch in range(19, 21):\n",
        "train(model, device, train_loader, optimizer, epoch = 20)\n",
        "test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24tVvrWxp2kU",
        "colab_type": "code",
        "outputId": "c4f7d1fa-4e6b-46ca-b471-7255708f62ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "print(\"Tensorflow Version:\",tf.__version__)\n",
        "  \n",
        "model = MobileNetV2(input_shape=[128, 128, 3], include_top=False) #or whatever model\n",
        "\n",
        "print(\"Weights of the Layer\",model.trainable_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 1.15.0\n",
            "Weights of the Layer [<tf.Variable 'Conv1_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>, <tf.Variable 'bn_Conv1_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'bn_Conv1_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_1/depthwise_kernel:0' shape=(3, 3, 32, 1) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_depthwise_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'expanded_conv_project_1/kernel:0' shape=(1, 1, 32, 16) dtype=float32>, <tf.Variable 'expanded_conv_project_BN_1/gamma:0' shape=(16,) dtype=float32>, <tf.Variable 'expanded_conv_project_BN_1/beta:0' shape=(16,) dtype=float32>, <tf.Variable 'block_1_expand_1/kernel:0' shape=(1, 1, 16, 96) dtype=float32>, <tf.Variable 'block_1_expand_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_expand_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_depthwise_1/depthwise_kernel:0' shape=(3, 3, 96, 1) dtype=float32>, <tf.Variable 'block_1_depthwise_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_depthwise_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_1_project_1/kernel:0' shape=(1, 1, 96, 24) dtype=float32>, <tf.Variable 'block_1_project_BN_1/gamma:0' shape=(24,) dtype=float32>, <tf.Variable 'block_1_project_BN_1/beta:0' shape=(24,) dtype=float32>, <tf.Variable 'block_2_expand_1/kernel:0' shape=(1, 1, 24, 144) dtype=float32>, <tf.Variable 'block_2_expand_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_expand_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_depthwise_1/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>, <tf.Variable 'block_2_depthwise_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_depthwise_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_2_project_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32>, <tf.Variable 'block_2_project_BN_1/gamma:0' shape=(24,) dtype=float32>, <tf.Variable 'block_2_project_BN_1/beta:0' shape=(24,) dtype=float32>, <tf.Variable 'block_3_expand_1/kernel:0' shape=(1, 1, 24, 144) dtype=float32>, <tf.Variable 'block_3_expand_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_expand_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_depthwise_1/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>, <tf.Variable 'block_3_depthwise_BN_1/gamma:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_depthwise_BN_1/beta:0' shape=(144,) dtype=float32>, <tf.Variable 'block_3_project_1/kernel:0' shape=(1, 1, 144, 32) dtype=float32>, <tf.Variable 'block_3_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_3_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_4_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_4_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_4_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_4_project_1/kernel:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'block_4_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_4_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_5_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_5_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_5_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_5_project_1/kernel:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'block_5_project_BN_1/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'block_5_project_BN_1/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'block_6_expand_1/kernel:0' shape=(1, 1, 32, 192) dtype=float32>, <tf.Variable 'block_6_expand_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_expand_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_depthwise_1/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>, <tf.Variable 'block_6_depthwise_BN_1/gamma:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_depthwise_BN_1/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'block_6_project_1/kernel:0' shape=(1, 1, 192, 64) dtype=float32>, <tf.Variable 'block_6_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_6_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_7_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_7_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_7_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_7_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_7_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_7_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_8_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_8_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_8_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_8_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_8_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_8_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_9_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_9_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_9_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_9_project_1/kernel:0' shape=(1, 1, 384, 64) dtype=float32>, <tf.Variable 'block_9_project_BN_1/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'block_9_project_BN_1/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'block_10_expand_1/kernel:0' shape=(1, 1, 64, 384) dtype=float32>, <tf.Variable 'block_10_expand_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_expand_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_depthwise_1/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>, <tf.Variable 'block_10_depthwise_BN_1/gamma:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_depthwise_BN_1/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'block_10_project_1/kernel:0' shape=(1, 1, 384, 96) dtype=float32>, <tf.Variable 'block_10_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_10_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_11_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_11_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_11_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_11_project_1/kernel:0' shape=(1, 1, 576, 96) dtype=float32>, <tf.Variable 'block_11_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_11_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_12_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_12_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_12_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_12_project_1/kernel:0' shape=(1, 1, 576, 96) dtype=float32>, <tf.Variable 'block_12_project_BN_1/gamma:0' shape=(96,) dtype=float32>, <tf.Variable 'block_12_project_BN_1/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'block_13_expand_1/kernel:0' shape=(1, 1, 96, 576) dtype=float32>, <tf.Variable 'block_13_expand_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_expand_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_depthwise_1/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>, <tf.Variable 'block_13_depthwise_BN_1/gamma:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_depthwise_BN_1/beta:0' shape=(576,) dtype=float32>, <tf.Variable 'block_13_project_1/kernel:0' shape=(1, 1, 576, 160) dtype=float32>, <tf.Variable 'block_13_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_13_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_14_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_14_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_14_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_14_project_1/kernel:0' shape=(1, 1, 960, 160) dtype=float32>, <tf.Variable 'block_14_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_14_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_15_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_15_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_15_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_15_project_1/kernel:0' shape=(1, 1, 960, 160) dtype=float32>, <tf.Variable 'block_15_project_BN_1/gamma:0' shape=(160,) dtype=float32>, <tf.Variable 'block_15_project_BN_1/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'block_16_expand_1/kernel:0' shape=(1, 1, 160, 960) dtype=float32>, <tf.Variable 'block_16_expand_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_expand_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_depthwise_1/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>, <tf.Variable 'block_16_depthwise_BN_1/gamma:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_depthwise_BN_1/beta:0' shape=(960,) dtype=float32>, <tf.Variable 'block_16_project_1/kernel:0' shape=(1, 1, 960, 320) dtype=float32>, <tf.Variable 'block_16_project_BN_1/gamma:0' shape=(320,) dtype=float32>, <tf.Variable 'block_16_project_BN_1/beta:0' shape=(320,) dtype=float32>, <tf.Variable 'Conv_1_1/kernel:0' shape=(1, 1, 320, 1280) dtype=float32>, <tf.Variable 'Conv_1_bn_1/gamma:0' shape=(1280,) dtype=float32>, <tf.Variable 'Conv_1_bn_1/beta:0' shape=(1280,) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0asFNBlrQG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "        self.des = tf.constant([[1.,2.]])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        # y = self.des\n",
        "        return self.dense2(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl7e6GCXrkCf",
        "colab_type": "code",
        "outputId": "de7f73c1-c86c-4cbc-b24b-578b5094cc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = MyModel()\n",
        "print(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW7Ue9vDxQyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "inputs = np.ones((10, 5)) \n",
        "outs = model(inputs) \n",
        "print(model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdn72dnmLCJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        print(model.input)\n",
        "        print(model.total_loss)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    #print(\"Total number of epochs run:\", epoch)\n",
        "    #print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBnu4AJrnW_c",
        "colab_type": "code",
        "outputId": "a69e2966-fc1b-4ac1-8f55-3f2209128c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "\n",
        "print(\"I'm a Symbolic tensor:\",model_discriminator)\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    print(\"Value of the model_discriminator function:\",sess.run(model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.14.0\n",
            "I'm a Symbolic tensor: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f5a4d62d438>\n",
            "Value of the model_discriminator function: [[0.00674586]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHuGn1xmoRUB",
        "colab_type": "code",
        "outputId": "dd898966-fb8e-455d-8ce6-535a412cf406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = tf.Variable(1)\n",
        "\n",
        "#@tf.function ... \n",
        "def f(x): \n",
        "  ta = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
        "  for i in tf.range(x): \n",
        "      v.assign_add(i) \n",
        "      ta = ta.write(i, v) \n",
        "  return ta.stack()\n",
        "\n",
        "f(5)\n",
        "ta = tf.TensorArray(tf.int32, size=10, dynamic_size=True)\n",
        "print(ta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f379a0c1dd8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9AfVGylOzPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWuIrI1tQ3Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "graph=K.get_session().graph\n",
        "\n",
        "graph_def=graph.as_graph_def()\n",
        "print(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmAGpwpFaVh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Image\n",
        "import ImageChops\n",
        "\n",
        "im1 = Image.open(\"splash.png\")\n",
        "im2 = Image.open(\"splash2.png\")\n",
        "\n",
        "diff = ImageChops.difference(im2, im1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS-rGAUnZzZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "graph=K.get_session().graph\n",
        "\n",
        "graph_def=graph.as_graph_def()\n",
        "print(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCfwsUo8j7j7",
        "colab_type": "code",
        "outputId": "1252ad90-73ce-4171-efbe-90593e1c68e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def traceme(x):\n",
        "    return model(x)\n",
        "\n",
        "\n",
        "logdir = '/tmp/tensorboard1/'\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "\n",
        "# Forward pass\n",
        "traceme(tf.zeros((1, 28, 28, 1)))\n",
        "with writer.as_default():\n",
        "    tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=logdir)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Trace already enabled\n",
            "WARNING:tensorflow:Model was constructed with shape Tensor(\"flatten_9_input:0\", shape=(None, 28, 28), dtype=float32) for input (None, 28, 28), but it was re-called on a Tensor with incompatible shape (1, 28, 28, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O889UWBikfYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir==logdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o1gfEKP41Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import summary_ops_v2\n",
        "from tensorflow.python.keras.backend import get_graph\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "tb_path = '/tmp/tensorboard/'\n",
        "tb_writer = tf.summary.create_file_writer(tb_path)\n",
        "with tb_writer.as_default():\n",
        "    if not model.run_eagerly:\n",
        "        summary_ops_v2.graph(get_graph(), step=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxsivbfXDhEW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cH7lAzlOiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=tb_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMrpp1JDjRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Comes from Generative Deep Learning by David Foster\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def call(self, inputs):\n",
        "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "# Dummy critic\n",
        "def critic():\n",
        "    critic = Sequential()\n",
        "    inputShape = (28, 28, 1)\n",
        "\n",
        "    critic.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "        input_shape=inputShape))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Flatten())\n",
        "    critic.add(Dense(512))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "    critic.add(Dropout(0.3))\n",
        "    critic.add(Dense(1))\n",
        "\n",
        "    return critic\n",
        "\n",
        "# Gather dataset\n",
        "((X_train, _), (X_test, _)) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Note that I am using test images as fake images for testing purposes\n",
        "interpolated_img = RandomWeightedAverage(32)([X_train[0:32].astype(\"float\"), X_test[32:64].astype(\"float\")])\n",
        "\n",
        "dummy = critic()\n",
        "\n",
        "# Compute gradients of the predictions with respect to the interpolated images\n",
        "with tf.GradientTape() as tape:\n",
        "     y_pred = dummy(interpolated_img)\n",
        "     gradients = tape.gradient(y_pred, interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKHevkcSERhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfbSRTKqETNk",
        "colab_type": "code",
        "outputId": "49556dd7-f061-4bfa-994f-5c331208804a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Comes from Generative Deep Learning by David Foster\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    def __init__(self, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def call(self, inputs):\n",
        "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "# Dummy critic\n",
        "def critic():\n",
        "    critic = Sequential()\n",
        "    inputShape = (28, 28, 1)\n",
        "\n",
        "    critic.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "        input_shape=inputShape))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    critic.add(Flatten())\n",
        "    critic.add(Dense(512))\n",
        "    critic.add(LeakyReLU(alpha=0.2))\n",
        "    critic.add(Dropout(0.3))\n",
        "    critic.add(Dense(1))\n",
        "\n",
        "    return critic\n",
        "\n",
        "# Gather dataset\n",
        "((X_train, _), (X_test, _)) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Note that I am using test images as fake images for testing purposes\n",
        "interpolated_img = RandomWeightedAverage(32)([X_train[0:32].astype('float'), X_test[32:64].astype('float')])\n",
        "\n",
        "dummy = critic()\n",
        "\n",
        "# Compute gradients of the predictions with respect to the interpolated images\n",
        "with tf.GradientTape() as tape:\n",
        "    y_pred = dummy(interpolated_img)\n",
        "gradients = tape.gradient(y_pred, interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer random_weighted_average_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNyQ36viUI_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(interpolated_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy2JljLJTE3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # (1) Importing dependency\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        #Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "        # print(\"Layer of the model:\",model.layers[2])\n",
        "        # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "        # print(model.input)\n",
        "        # print(model.total_loss)\n",
        "        # print(model.trainable_weights)\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    print(\"Total number of epochs run:\", epoch)\n",
        "    print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MgmDrsmHkCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# (5) Define Gradient Function\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# (6) Train the model such that gradients are captured for every epoch\n",
        "epoch_gradient = []\n",
        "for epoch in range(1,5):\n",
        "    model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "    get_gradient = get_gradient_func(model)\n",
        "    grads = get_gradient([x, y, np.ones(len(y))])\n",
        "    #Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "    # print(\"Layer of the model:\",model.layers[2])\n",
        "    # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "    # print(model.input)\n",
        "    # print(model.total_loss)\n",
        "    # print(model.trainable_weights)\n",
        "    epoch_gradient.append(grads)\n",
        "\n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXsTMn1I_oK",
        "colab_type": "code",
        "outputId": "8865e1ea-2c5e-4e85-b417-d1ee78633a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy7BP1P_V1b",
        "colab_type": "code",
        "outputId": "34a301bc-e0c3-4519-b5cd-f210267823ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Modify the load image to have the target size\n",
        "img = load_img(\"/Data/dog.jpg\", color_mode=\"grayscale\",interpolation='nearest', target_size=(200,50))\n",
        "\n",
        "# convert to array\n",
        "img = img_to_array(img)\n",
        "print(\"image to array shape:\",img.shape)\n",
        "\n",
        "# reshape into a single sample with 1 channel\n",
        "img = img[np.newaxis,:,:,:]\n",
        "print(\"Add a new axis to specify number of images:\",img.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image to array shape: (200, 50, 1)\n",
            "Add a new axis to specify number of images: (1, 200, 50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqJyq5h2ArXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgVvCdgvZBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "    import keras\n",
        "    from keras import backend as K\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "    from keras.layers.normalization import BatchNormalization\n",
        "    import numpy as np\n",
        "    np.random.seed(1000)\n",
        "    \n",
        "    # (2) Get Data\n",
        "    import tflearn.datasets.oxflower17 as oxflower17\n",
        "    x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "    # (3) Create a sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation before passing it to the next layer\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 2nd Dense Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # 3rd Dense Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "    # Batch Normalisation\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(17))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    # (4) Compile \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # (5) Define Gradient Function\n",
        "    def get_gradient_func(model):\n",
        "        grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "        inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "        func = K.function(inputs, grads)\n",
        "        return func\n",
        "    \n",
        "    # (6) Train the model such that gradients are captured for every epoch\n",
        "    epoch_gradient = []\n",
        "    for epoch in range(1,5):\n",
        "        model.fit(x, y, batch_size=64, epochs= epoch, initial_epoch = (epoch-1), verbose=1, validation_split=0.2, shuffle=True)\n",
        "        get_gradient = get_gradient_func(model)\n",
        "        grads = get_gradient([x, y, np.ones(len(y))])\n",
        "        # Similarly define your function to play with your model.layers,model.layers[].get_weights(),model.input,model.total_loss,model.trainable_weights etc\n",
        "        # print(\"Layer of the model:\",model.layers[2])\n",
        "        # print(\"Weights of the Layer\",model.layers[2].get_weights())\n",
        "        # print(model.input)\n",
        "        # print(model.total_loss)\n",
        "        # print(model.trainable_weights)\n",
        "        epoch_gradient.append(grads)\n",
        "    \n",
        "    # (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "    gradient = np.asarray(epoch_gradient)\n",
        "    print(\"Total number of epochs run:\", epoch)\n",
        "    print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhrY8ER0wGyI",
        "colab_type": "code",
        "outputId": "f03028e0-98be-4db0-e0eb-31b28f3c6ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4-tOmttwIhJ",
        "colab_type": "code",
        "outputId": "73a9dd1b-5013-4e1a-d77c-6695418b4327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iutilLUp9AsZ",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks in model.fit\n",
        "https://stackoverflow.com/questions/60808723/how-to-call-a-method-as-a-custom-callback-in-keras/60815917#60815917"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK0RorXYQbgM",
        "colab_type": "code",
        "outputId": "20472657-42a6-487d-c6b2-78611cf34291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epoch_gradient = []\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "    \n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 28,096,769\n",
            "Trainable params: 28,075,633\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "1088/1088 [==============================] - 5s 5ms/step - loss: 3.0726 - acc: 0.2289 - val_loss: 12.3280 - val_acc: 0.1287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 2.2462 - acc: 0.3327 - val_loss: 7.0050 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 1.8286 - acc: 0.4228 - val_loss: 6.0993 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 1.6860 - acc: 0.4642 - val_loss: 3.5253 - val_acc: 0.4081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of epochs run: 4\n",
            "Gradient Array has the shape: (4, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCO9AKLKKjgL",
        "colab_type": "code",
        "outputId": "7b85d8b9-cfe0-49cb-8fec-414bc18acef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 62\n",
            "conv2d_21 (11, 11, 3, 96)\n",
            "conv2d_22 (11, 11, 96, 256)\n",
            "conv2d_23 (3, 3, 256, 384)\n",
            "conv2d_24 (3, 3, 384, 384)\n",
            "conv2d_25 (3, 3, 384, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmsfcXZtL16-",
        "colab_type": "code",
        "outputId": "2a26d2fc-ce8b-4612-ef85-d043f1a5356c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\n",
        "print(filters.shape)\n",
        "print(filters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3, 384, 256)\n",
            "[[[[ 1.33229261e-02  2.78362742e-04 -1.15596037e-03 ... -1.04442742e-02\n",
            "    -1.27202040e-02  2.72896886e-02]\n",
            "   [ 2.04270035e-02  2.09266972e-02 -2.27798354e-02 ...  2.10328754e-02\n",
            "    -1.79852340e-02 -1.31000848e-02]\n",
            "   [ 1.21402023e-02  9.55937244e-03 -9.73658753e-04 ...  2.90534608e-02\n",
            "     8.62147380e-03  3.97700304e-03]\n",
            "   ...\n",
            "   [ 2.05181465e-02 -2.70775743e-02 -1.03279278e-02 ...  4.66628186e-03\n",
            "     2.88294349e-02  3.55665796e-02]\n",
            "   [ 2.56488305e-02  2.02665925e-02 -9.53960046e-03 ...  1.07415328e-02\n",
            "     2.38317680e-02 -1.13734556e-02]\n",
            "   [-6.18373556e-03  7.84027111e-03  4.98771551e-04 ...  1.88040324e-02\n",
            "    -2.21270267e-02  7.43205333e-03]]\n",
            "\n",
            "  [[-3.35427485e-02  2.35256236e-02 -1.55152555e-03 ... -1.82591029e-03\n",
            "    -6.07969100e-03 -2.40267627e-03]\n",
            "   [-5.59751503e-03  3.25453505e-02 -1.27216885e-02 ...  2.22896207e-02\n",
            "    -1.04518968e-03 -3.41729373e-02]\n",
            "   [-1.53387915e-02 -2.15985011e-02 -2.40802132e-02 ...  8.57070833e-03\n",
            "     1.55310007e-02  8.27453937e-03]\n",
            "   ...\n",
            "   [-1.83913186e-02 -2.47003324e-02 -1.77569594e-02 ...  3.14827859e-02\n",
            "     2.37260144e-02  1.35977212e-02]\n",
            "   [-5.08161262e-03  2.33772658e-02 -1.85138639e-02 ... -1.16026518e-03\n",
            "     2.38104146e-02 -1.90851931e-02]\n",
            "   [ 8.57734215e-03 -1.23164626e-02 -1.81618647e-03 ... -1.26188034e-02\n",
            "     2.13982817e-02  1.71989426e-02]]\n",
            "\n",
            "  [[ 2.75964546e-03  4.13805023e-02 -1.22120418e-02 ...  1.71306508e-03\n",
            "    -1.51561396e-02 -2.18702871e-02]\n",
            "   [-3.56088951e-03  3.43757658e-03 -1.16327219e-02 ... -1.19192926e-02\n",
            "     3.88762157e-04 -9.95170232e-03]\n",
            "   [ 3.59454565e-02 -6.90977415e-03 -1.50266113e-02 ... -3.32049071e-03\n",
            "     2.45900005e-02 -2.42324471e-02]\n",
            "   ...\n",
            "   [-1.90636870e-02 -1.24915438e-02  2.68660672e-02 ... -4.73172823e-03\n",
            "    -5.91639895e-03  2.28889082e-02]\n",
            "   [ 3.66363376e-02 -2.24502403e-02 -1.06375702e-02 ... -1.81130767e-02\n",
            "     2.88566016e-02 -2.08211727e-02]\n",
            "   [ 6.01422449e-04 -8.68872181e-03 -2.10836846e-02 ...  1.67874563e-02\n",
            "    -3.84189188e-02  1.78155117e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.22205978e-02  4.27871849e-03 -1.09987976e-02 ...  1.76646598e-02\n",
            "     1.50742009e-02 -3.86701301e-02]\n",
            "   [-2.79729012e-02  2.00011078e-02 -1.31703299e-02 ... -2.00200267e-02\n",
            "    -7.25999195e-03  1.45357484e-02]\n",
            "   [-4.82261041e-03 -4.14834311e-03 -1.76655632e-02 ...  2.20327824e-02\n",
            "     1.72639880e-02 -7.53242476e-03]\n",
            "   ...\n",
            "   [ 1.73690319e-02  3.01635619e-02  1.45886336e-02 ...  1.34067582e-02\n",
            "     3.23755704e-02  1.59694552e-02]\n",
            "   [ 2.47067846e-02  7.35560572e-03 -1.88481305e-02 ...  2.58524362e-02\n",
            "     9.14169010e-04  2.94958130e-02]\n",
            "   [ 2.67407298e-02 -6.96273427e-03  2.19189376e-02 ... -3.23407352e-02\n",
            "     1.11467652e-02 -2.02568714e-02]]\n",
            "\n",
            "  [[-3.33763249e-02 -1.54417353e-02 -8.87046568e-03 ...  1.41540635e-02\n",
            "    -2.68381871e-02  1.22759230e-02]\n",
            "   [-1.30444350e-05 -7.20519293e-03  1.52943395e-02 ... -1.05463304e-02\n",
            "    -1.63246077e-02 -2.80507226e-02]\n",
            "   [ 1.94950942e-02  1.96460653e-02 -5.00125624e-03 ... -1.58436447e-02\n",
            "     1.41756414e-02  1.98035198e-03]\n",
            "   ...\n",
            "   [-2.91450340e-02  1.30721824e-02  1.83877610e-02 ... -1.90879926e-02\n",
            "     1.99749433e-02 -1.05333803e-02]\n",
            "   [ 1.72556620e-02  1.81617010e-02  1.24600148e-02 ...  1.88519955e-02\n",
            "    -8.84543266e-03 -1.60351787e-02]\n",
            "   [ 2.47481037e-02  2.93982169e-03  2.01242752e-02 ...  1.95950232e-02\n",
            "    -2.78105512e-02  2.05665398e-02]]\n",
            "\n",
            "  [[ 1.82851534e-02  3.44641991e-02 -2.00678073e-02 ... -3.24464031e-02\n",
            "    -3.23583074e-02 -2.66336314e-02]\n",
            "   [-1.30740115e-02 -2.40531545e-02  1.92862866e-03 ... -9.58005898e-03\n",
            "    -8.63340776e-03 -2.82395743e-02]\n",
            "   [ 4.19791276e-03  1.45691829e-02  3.42715830e-02 ...  4.06611152e-02\n",
            "    -2.05075163e-02 -3.97980548e-02]\n",
            "   ...\n",
            "   [ 1.23621235e-02 -3.30808535e-02  3.05603142e-03 ... -8.03769939e-03\n",
            "     2.39255354e-02  1.01700425e-02]\n",
            "   [ 1.93574950e-02  2.53207628e-02  3.19945849e-02 ... -1.29298661e-02\n",
            "    -9.71809588e-03 -3.35334092e-02]\n",
            "   [-4.02106047e-02 -2.33742259e-02 -2.70008687e-02 ... -5.98855503e-03\n",
            "    -1.24435341e-02  3.15479822e-02]]]\n",
            "\n",
            "\n",
            " [[[-2.30802242e-02 -1.40459323e-02 -6.23126328e-03 ...  1.52085479e-02\n",
            "    -2.52160486e-02  1.24641499e-02]\n",
            "   [ 1.96760800e-02  1.05630013e-03  2.54229661e-02 ...  1.62760932e-02\n",
            "     2.23252065e-02 -2.22447589e-02]\n",
            "   [ 3.04492004e-02 -1.94075168e-03 -1.97871421e-02 ... -9.06596240e-03\n",
            "     3.24702673e-02 -9.38400440e-03]\n",
            "   ...\n",
            "   [-2.87375692e-02 -1.13275591e-02 -1.56598929e-02 ... -3.06045953e-02\n",
            "    -3.27123553e-02  4.29812027e-03]\n",
            "   [-5.72555349e-04  9.24452208e-03 -1.79962069e-02 ... -1.38692930e-03\n",
            "    -1.69475167e-03 -2.07326356e-02]\n",
            "   [ 2.55298633e-02  2.39779558e-02 -4.83227056e-03 ... -1.02796387e-02\n",
            "    -1.41589378e-04 -1.67643074e-02]]\n",
            "\n",
            "  [[-2.23147380e-03  1.37838507e-02 -4.08266764e-03 ...  1.90702491e-02\n",
            "     9.72075947e-03 -2.66824216e-02]\n",
            "   [-1.86436921e-02 -2.82567251e-03 -1.35208173e-02 ...  3.81241441e-02\n",
            "    -1.62060019e-02 -3.96039486e-02]\n",
            "   [ 5.92509052e-03  1.42326870e-03  5.25515201e-03 ...  2.07302850e-02\n",
            "    -3.06541529e-02 -2.26684157e-02]\n",
            "   ...\n",
            "   [ 2.35446766e-02 -3.54932398e-02 -1.09605016e-02 ...  1.20483274e-02\n",
            "     3.52192447e-02 -8.96899775e-03]\n",
            "   [-1.91081129e-02 -7.72378687e-03  8.51210579e-03 ...  3.27213518e-02\n",
            "    -3.99521226e-03  2.70088650e-02]\n",
            "   [-1.36597576e-02  7.93528836e-03  4.57486464e-03 ... -3.79467532e-02\n",
            "    -1.68086924e-02  3.47109861e-03]]\n",
            "\n",
            "  [[-2.51405891e-02  3.37613821e-02 -1.24929231e-02 ... -4.84925555e-03\n",
            "     1.82562377e-02 -4.42078747e-02]\n",
            "   [-5.84426289e-03 -2.04253178e-02  1.42424544e-02 ...  2.39489395e-02\n",
            "    -3.39500532e-02 -7.58632645e-03]\n",
            "   [ 2.52021682e-02 -2.40255445e-02 -1.36912316e-02 ... -1.96786743e-04\n",
            "     7.05324765e-03 -1.00541944e-02]\n",
            "   ...\n",
            "   [ 9.71514825e-03 -7.74992211e-03 -3.24081630e-02 ...  1.33663723e-02\n",
            "     1.77465230e-02  2.45424472e-02]\n",
            "   [-1.41809247e-02  2.96245646e-02  3.87504548e-02 ...  1.54969441e-02\n",
            "    -2.57334486e-02 -4.18210924e-02]\n",
            "   [-7.17054168e-03  3.36966068e-02 -2.70571802e-02 ... -3.91547196e-03\n",
            "    -1.72355976e-02  2.01625824e-02]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjwfJo493IAV",
        "colab_type": "text"
      },
      "source": [
        "# Tensor to Array(ndarray) \n",
        "https://stackoverflow.com/questions/60824788/how-to-convert-tensor-to-ndarray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9cwPNdunwz7",
        "colab_type": "code",
        "outputId": "e6b65ff5-5de2-4eb5-d06b-cb19c5497844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!pip install tensorflow==2.1\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "output = model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))\n",
        "print(\"Output as a Tensor:\",output)\n",
        "\n",
        "out = np.array(output)\n",
        "print(\"Output as an Array:\",out)\n",
        "print(\"Type of the Array:\",type(out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.1.0\n",
            "Output as a Tensor: tf.Tensor([[-0.40550372]], shape=(1, 1), dtype=float32)\n",
            "Output as an Array: [[-0.40550372]]\n",
            "Type of the Array: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHp5zzm0jbd",
        "colab_type": "code",
        "outputId": "7e589da7-084f-4643-8810-5e40c4102e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(7,(3,3) , padding = \"same\" , input_shape = (28,28,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(50,activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model \n",
        "\n",
        "model_discriminator = make_discriminator_model()\n",
        "output = model_discriminator(np.random.rand(1,28,28,1).astype(\"float32\"))\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    print(\"Output as a Tensor:\",output)\n",
        "    out = np.array(sess.run(output))\n",
        "    print(\"Output as an Array:\",out)\n",
        "    print(\"Type of the Array:\",type(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 1.14.0\n",
            "Output as a Tensor: Tensor(\"sequential_7/dense_15/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
            "Output as an Array: [[-0.29746282]]\n",
            "Type of the Array: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEyyro-xMnwS",
        "colab_type": "text"
      },
      "source": [
        "# Switching between Tensorflow Versions without installing everytime\n",
        "https://stackoverflow.com/questions/60810400/how-to-upgrade-tensorflow-to-2-0-in-google-colab-permanently/60810715#60810715"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PKQyncnMmBa",
        "colab_type": "code",
        "outputId": "3e556b13-75f0-4eaf-a708-94638c6e8099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVg8VdqXNHeN",
        "colab_type": "code",
        "outputId": "5f1425f1-d300-47b4-8db3-7e3e900b2d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f2C617e-BFu",
        "colab_type": "text"
      },
      "source": [
        "# One Hot Encoding Using LabelBinarizer\n",
        "https://stackoverflow.com/questions/60868391/how-to-view-class-labels-after-one-hot-encoding-during-training-testing-and-afte/60871869#60871869"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsvwViobiReg",
        "colab_type": "code",
        "outputId": "52777050-e087-4be8-e5c1-aefd120f0c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# define example\n",
        "data = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
        "\n",
        "values = np.array(data)\n",
        "\n",
        "#Binary encode\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "labels = lb.fit_transform(values)\n",
        "labels = to_categorical(labels)\n",
        "print(\"which position represents for cat and dog?:\")\n",
        "print(\"Data is:\",data)\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which position represents for cat and dog?:\n",
            "Data is: ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ4RkAQAKsje",
        "colab_type": "code",
        "outputId": "6ccc26e1-0cbb-41e8-9c73-5ff4ac30442e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# define example\n",
        "data1 = ['cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat']\n",
        "data2 = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
        "\n",
        "values1 = np.array(data1)\n",
        "values2 = np.array(data2)\n",
        "\n",
        "#Binary encode\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "labels1 = lb.fit_transform(values1)\n",
        "labels1 = to_categorical(labels1)\n",
        "print(\"what is value for cat and dog?:\")\n",
        "print(\"Data is:\",data1)\n",
        "print(labels1)\n",
        "print(\"\\n\")\n",
        "\n",
        "labels2 = lb.fit_transform(values2)\n",
        "labels2 = to_categorical(labels2)\n",
        "print(\"what is value for cat and dog?:\")\n",
        "print(\"Data is:\",data2)\n",
        "print(labels2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what is value for cat and dog?:\n",
            "Data is: ['cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat']\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "\n",
            "\n",
            "what is value for cat and dog?:\n",
            "Data is: ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog']\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFIx6yucLI-K",
        "colab_type": "code",
        "outputId": "d99da379-cfe0-48ec-9e2e-41f6c23a10e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "rslt = np.array([[0.9550967,0.04490325]])\n",
        "rslt = np.argmax(rslt)\n",
        "print(rslt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIZpkS8Sh223",
        "colab_type": "code",
        "outputId": "0e98fc0b-6ee4-4012-fc7d-3b1563c3026e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "rslt = np.array([[0.04490325,0.9550967, 1]])\n",
        "rslt = np.argmax(rslt)\n",
        "print(rslt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_jgkP3sdF4r",
        "colab_type": "text"
      },
      "source": [
        "# Ragged Tensor\n",
        "https://stackoverflow.com/questions/60924624/is-there-a-way-to-normalize-a-ragged-tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dqzlnvmwrr3",
        "colab_type": "text"
      },
      "source": [
        "## Using math.l2_normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REq-0WuSdgT3",
        "colab_type": "code",
        "outputId": "142206b5-c025-4ce7-ee90-028d2ecc380b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Create a Ragged Tensor\n",
        "rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Normalize\n",
        "rt = tf.math.l2_normalize(rt, axis = None)\n",
        "print(\"Normalized Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Ragged Tensor\n",
        "rt = tf.RaggedTensor.from_tensor(rt, padding=0.0)\n",
        "print(\"Normalized Ragged Tensor:\",\"\\n\",rt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " <tf.RaggedTensor [[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]]> \n",
            "\n",
            "Tensor of same length: \n",
            " tf.Tensor(\n",
            "[[9. 8. 7.]\n",
            " [0. 0. 0.]\n",
            " [6. 5. 0.]\n",
            " [4. 0. 0.]], shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Tensor: \n",
            " tf.Tensor(\n",
            "[[0.546711   0.48596537 0.4252197 ]\n",
            " [0.         0.         0.        ]\n",
            " [0.36447403 0.30372834 0.        ]\n",
            " [0.24298269 0.         0.        ]], shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Ragged Tensor: \n",
            " <tf.RaggedTensor [[0.5467110276222229, 0.485965371131897, 0.42521971464157104], [], [0.36447402834892273, 0.3037283420562744], [0.2429826855659485]]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_FhnDE9wzlF",
        "colab_type": "text"
      },
      "source": [
        "## Using tf.linalg.normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHoyROQdpHI",
        "colab_type": "code",
        "outputId": "f16f1518-fc9a-4ed0-83aa-2f3f78f813d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Create a Ragged Tensor\n",
        "rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Normalize\n",
        "rt = tf.linalg.normalize(rt, axis = None)\n",
        "print(\"Normalized and Norm Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "# Get the normalized part\n",
        "rt = tf.convert_to_tensor(rt[0])\n",
        "print(\"Normalized Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Ragged Tensor\n",
        "rt = tf.RaggedTensor.from_tensor(rt, padding=0.0)\n",
        "print(\"Normalized Ragged Tensor:\",\"\\n\",rt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " tf.RaggedTensor(values=Tensor(\"RaggedConstant/values:0\", shape=(6,), dtype=float32), row_splits=Tensor(\"RaggedConstant/Const:0\", shape=(5,), dtype=int64)) \n",
            "\n",
            "Tensor of same length: \n",
            " Tensor(\"RaggedToTensor/GatherV2:0\", shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized and Norm Tensor: \n",
            " (<tf.Tensor 'normalize/truediv:0' shape=(4, 3) dtype=float32>, <tf.Tensor 'normalize/norm/Sqrt:0' shape=(1, 1) dtype=float32>) \n",
            "\n",
            "Normalized Tensor: \n",
            " Tensor(\"normalize/truediv:0\", shape=(4, 3), dtype=float32) \n",
            "\n",
            "Normalized Ragged Tensor: \n",
            " tf.RaggedTensor(values=Tensor(\"RaggedFromTensor/boolean_mask/GatherV2:0\", shape=(?,), dtype=float32), row_splits=Tensor(\"RaggedFromTensor/concat:0\", shape=(5,), dtype=int64))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVLkvAkPatDD",
        "colab_type": "text"
      },
      "source": [
        "# Deleting Layer using Keras Surgeon OR pop\n",
        "https://stackoverflow.com/questions/60637199/error-in-removing-the-first-layer-of-keras-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb4cJKwt2eIK",
        "colab_type": "text"
      },
      "source": [
        "## Deleting the first or middle layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcVNcMX4eV1A",
        "colab_type": "code",
        "outputId": "94ffb433-76fb-4c11-9c99-b449fd298fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install kerassurgeon"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerassurgeon\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/e7/8adbef95f56e2349bf9faf2aec462dee0a38cec7cd6bfb8895de83706762/kerassurgeon-0.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Installing collected packages: kerassurgeon\n",
            "Successfully installed kerassurgeon-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3d88fe8b-4d7c-4c16-9294-e641eefb5d1a",
        "id": "K9OBGZECaruM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon.operations import delete_layer, insert_layer, delete_channels\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# delete 3rd layer .i.e. Conv2D Layer from the model\n",
        "layer_3 = model.layers[2]\n",
        "model = delete_layer(model, layer_3)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19_input (InputLayer) (None, 24, 24, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 61,744\n",
            "Trainable params: 61,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJidi2xObYul",
        "colab_type": "code",
        "outputId": "ad1db41b-aa86-4bd1-f0c5-8cf2f485e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon import Surgeon\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# delete 3rd layer .i.e. Conv2D Layer from the model\n",
        "layer_3 = model.layers[2]\n",
        "surgeon = Surgeon(model)\n",
        "surgeon.add_job('delete_layer', layer_3)\n",
        "model = surgeon.operate()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-79f9b15a709b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0msurgeon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSurgeon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_layer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mnew_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_graph\u001b[0;34m(self, graph_inputs, output_nodes, graph_input_masks)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;31m# obtain its inputs and input masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 inputs, input_masks = zip(\n\u001b[0;32m--> 240\u001b[0;31m                     *[_rebuild_rec(n) for n in inbound_nodes])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mnew_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_delete_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# Record that this node has been rebuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of input shape to have '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                                 \u001b[0;34m'value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_2: expected axis -1 of input shape to have value 12 but got shape (None, 24, 24, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9f5b5a2-e93f-483d-c421-12e7b94213b6",
        "id": "GHOS2dQEvPkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model1 = model.layers.pop(0)\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_61 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 28,096,769\n",
            "Trainable params: 28,075,633\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d9f744fc3690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_5aAAf82LIE",
        "colab_type": "text"
      },
      "source": [
        "## To remove the last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aabcfd59-f6e6-4940-9749-cf6667dccbf5",
        "id": "JU19GZBdx4eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "\n",
        "import kerassurgeon\n",
        "from kerassurgeon import Surgeon\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=12, input_shape=(24,24,1), kernel_size=(3,3), activation='relu'))\n",
        " \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=24, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(5,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "model._layers.pop()\n",
        "\n",
        "new_model = Model(model.input,model.layers[-1].output)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_138 (Conv2D)          (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_139 (Conv2D)          (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_140 (Conv2D)          (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 66,952\n",
            "Trainable params: 66,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_138_input (InputLayer (None, 24, 24, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_138 (Conv2D)          (None, 22, 22, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_139 (Conv2D)          (None, 20, 20, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_140 (Conv2D)          (None, 20, 20, 24)        5208      \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 5)                 48005     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               600       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "=================================================================\n",
            "Total params: 66,649\n",
            "Trainable params: 66,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iah4GD0dbRBW",
        "colab_type": "text"
      },
      "source": [
        "# Multiple image input for keras application\n",
        "https://stackoverflow.com/questions/60582442/multiple-image-input-for-keras-application/60968842#60968842"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN-AY-jDdpLV",
        "colab_type": "code",
        "outputId": "9ab40775-483d-48cb-d651-e1d7b890a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.python.keras import layers, models, applications\n",
        "\n",
        "# Multiple inputs\n",
        "in1 = layers.Input(shape=(128,128,3))\n",
        "in2 = layers.Input(shape=(128,128,3))\n",
        "in3 = layers.Input(shape=(128,128,3))\n",
        "\n",
        "# CNN output\n",
        "cnn = applications.xception.Xception(include_top=False)\n",
        "cnn.summary()\n",
        "\n",
        "out1 = cnn(in1)\n",
        "out2 = cnn(in2)\n",
        "out3 = cnn(in3)\n",
        "\n",
        "# Flattening the output for the dense layer\n",
        "fout1 = layers.Flatten()(out1)\n",
        "fout2 = layers.Flatten()(out2)\n",
        "fout3 = layers.Flatten()(out3)\n",
        "\n",
        "# Getting the dense output\n",
        "dense = layers.Dense(100, activation='softmax')\n",
        "\n",
        "dout1 = dense(fout1)\n",
        "dout2 = dense(fout2)\n",
        "dout3 = dense(fout3)\n",
        "\n",
        "# Concatenating the final output\n",
        "out = layers.Concatenate(axis=-1)([dout1, dout2, dout3])\n",
        "\n",
        "# Creating the model\n",
        "model = models.Model(inputs=[in1,in2,in3], outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "xception (Model)                multiple             20861480    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32768)        0           xception[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32768)        0           xception[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 32768)        0           xception[3][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          3276900     flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 300)          0           dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "==================================================================================================\n",
            "Total params: 24,138,380\n",
            "Trainable params: 24,083,852\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsDMeCKnrbCJ",
        "colab_type": "code",
        "outputId": "b34b9515-b774-4e25-9bf3-be20aff29de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense\n",
        "from keras.activations import relu\n",
        "\n",
        "input_shape = (32,32,3)\n",
        "#[(None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3)]\n",
        "#rt = tf.ragged.constant([[9.0, 8.0, 7.0], [], [6.0, 5.0], [4.0]])\n",
        "\n",
        "in1 = Input(shape=(32,32,3))\n",
        "in2 = Input(shape=(32,32,3))\n",
        "in3 = Input(shape=(32,32,3))\n",
        "in4 = Input(shape=(32,32,3))\n",
        "in5 = Input(shape=(32,32,3))\n",
        "in6 = Input(shape=(32,32,3))\n",
        "in7 = Input(shape=(32,32,3))\n",
        "in8 = Input(shape=(32,32,3))\n",
        "in9 = Input(shape=(32,32,3))\n",
        "in10 = Input(shape=(32,32,3))\n",
        "in11 = Input(shape=(32,32,3))\n",
        "\n",
        "inputs = [in1,in2,in3,in4,in5,in6,in7,in8,in9,in10,in11]\n",
        "densenet_121_model = DenseNet121(include_top=False)(inputs)\n",
        "output = Dense(units=11, activation='relu')(densenet_121_model)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-49d38cc5c930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdensenet_121_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensenet_121_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             if all([s is not None\n\u001b[1;32m    467\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    597\u001b[0m             raise ValueError('Invalid input_shape argument ' +\n\u001b[1;32m    598\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': model has '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                              str(len(self._input_layers)) + ' tensor inputs.')\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid input_shape argument [(None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3), (None, 32, 32, 3)]: model has 1 tensor inputs."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYuZaIyrnGQ",
        "colab_type": "code",
        "outputId": "50552790-7d0e-481b-cf68-e7ce32cd4a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense, Flatten, Concatenate\n",
        "from keras.activations import relu\n",
        "\n",
        "# Multiple inputs\n",
        "in1 = Input(shape=(128,128,3))\n",
        "in2 = Input(shape=(128,128,3))\n",
        "in3 = Input(shape=(128,128,3))\n",
        "\n",
        "# CNN output\n",
        "cnn = DenseNet121(include_top=False)\n",
        "#cnn.summary()\n",
        "\n",
        "out1 = cnn(in1)\n",
        "out2 = cnn(in2)\n",
        "out3 = cnn(in3)\n",
        "\n",
        "# Flattening the output for the dense layer\n",
        "fout1 = Flatten()(out1)\n",
        "fout2 = Flatten()(out2)\n",
        "fout3 = Flatten()(out3)\n",
        "\n",
        "# Getting the dense output\n",
        "dense = Dense(1, activation='softmax')\n",
        "\n",
        "dout1 = dense(fout1)\n",
        "dout2 = dense(fout2)\n",
        "dout3 = dense(fout3)\n",
        "\n",
        "# Concatenating the final output\n",
        "out = Concatenate(axis=-1)([dout1, dout2, dout3])\n",
        "\n",
        "# Creating the model\n",
        "model = Model(inputs=[in1,in2,in3], outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_306 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_307 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_308 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "densenet121 (Model)             multiple             7037504     input_306[0][0]                  \n",
            "                                                                 input_307[0][0]                  \n",
            "                                                                 input_308[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 16384)        0           densenet121[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16384)        0           densenet121[2][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 16384)        0           densenet121[3][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1)            16385       flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3)            0           dense_12[0][0]                   \n",
            "                                                                 dense_12[1][0]                   \n",
            "                                                                 dense_12[2][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,053,889\n",
            "Trainable params: 6,970,241\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1vXRhpz0mou",
        "colab_type": "text"
      },
      "source": [
        "# Padding = Same and Padding = Valid \n",
        "https://stackoverflow.com/questions/60323897/tensorflow-keras-conv2d-layers-with-padding-same-behave-strangely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRHrSh0u0m5p",
        "colab_type": "code",
        "outputId": "4ecd0ad4-7a7e-469b-dc6a-c34a6a9a199a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(5,5,1), kernel_size=(2,2), strides =(2,2) ,padding='Same'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rooePLzj1y5h",
        "colab_type": "code",
        "outputId": "a73f7aa2-3b5b-46e3-a405-087f68ea8dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(5,5,1), kernel_size=(2,2), strides =(2,2) ,padding='Valid'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llW_6Wnp3izz",
        "colab_type": "code",
        "outputId": "c66f1c28-231e-4c32-85f0-eff16eb44b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model.add(Conv2D(filters=24, input_shape=(6,6,1), kernel_size=(2,2), strides =(2,2) ,padding='Valid'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 24)          120       \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk6am3SF58J6",
        "colab_type": "text"
      },
      "source": [
        "# model.fit_generator Plot\n",
        "https://stackoverflow.com/questions/60306753/drawing-the-accuracy-of-multiple-validation-of-diffferent-cnn-classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_MWlH9u58Xw",
        "colab_type": "code",
        "outputId": "ca563510-05a9-490c-e53c-97da4a3ff2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lr=0.01\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    adam = Adam(lr)\n",
        "\n",
        "    print(\"Model using learning rate of\",lr)\n",
        "\n",
        "    lr = lr + 0.01\n",
        "\n",
        "    model.compile(optimizer=adam, \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(\n",
        "              train_data_gen,\n",
        "              steps_per_epoch=total_train // batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=val_data_gen,\n",
        "              validation_steps=total_val // batch_size)\n",
        "    \n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['LR=0.01', 'LR=0.02', 'LR=0.03', 'LR=0.04', 'LR=0.05'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Model using learning rate of 0.01\n",
            "WARNING:tensorflow:From <ipython-input-1-bd4428ee6d16>:84: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 9s 587ms/step - loss: 7.5758 - accuracy: 0.5057 - val_loss: 0.6948 - val_accuracy: 0.4967\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 9s 601ms/step - loss: 0.6955 - accuracy: 0.4947 - val_loss: 0.6946 - val_accuracy: 0.5045\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 9s 602ms/step - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 9s 602ms/step - loss: 0.6936 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 9s 599ms/step - loss: 0.6933 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.4978\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6933 - accuracy: 0.4947 - val_loss: 0.6939 - val_accuracy: 0.5067\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6941 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4978\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 9s 590ms/step - loss: 0.6935 - accuracy: 0.5128 - val_loss: 0.6932 - val_accuracy: 0.5033\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6935 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.4978\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5067\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 9s 593ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5056\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6933 - accuracy: 0.5118 - val_loss: 0.6932 - val_accuracy: 0.4967\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6933 - accuracy: 0.4824 - val_loss: 0.6933 - val_accuracy: 0.5112\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6939 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6948 - accuracy: 0.5011 - val_loss: 0.6934 - val_accuracy: 0.5011\n",
            "Model using learning rate of 0.02\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 9s 603ms/step - loss: 0.6941 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.4978\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 9s 599ms/step - loss: 0.6933 - accuracy: 0.5037 - val_loss: 0.6932 - val_accuracy: 0.5033\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.6933 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 9s 618ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6934 - accuracy: 0.4931 - val_loss: 0.6936 - val_accuracy: 0.5067\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6935 - val_accuracy: 0.4877\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 9s 598ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6929 - val_accuracy: 0.5100\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6936 - accuracy: 0.4882 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 9s 591ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6934 - val_accuracy: 0.5123\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 589ms/step - loss: 0.6936 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6933 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.5045\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.4955\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6934 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 0.4933\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 9s 593ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 9s 599ms/step - loss: 0.6933 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.4978\n",
            "Model using learning rate of 0.03\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.6942 - accuracy: 0.5085 - val_loss: 0.6929 - val_accuracy: 0.5100\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6938 - accuracy: 0.5091 - val_loss: 0.6933 - val_accuracy: 0.5078\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6933 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5045\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 9s 592ms/step - loss: 0.6933 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5022\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.4933\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6933 - accuracy: 0.5069 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 9s 600ms/step - loss: 0.6934 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4955\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 9s 603ms/step - loss: 0.6933 - accuracy: 0.4904 - val_loss: 0.6932 - val_accuracy: 0.4967\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 599ms/step - loss: 0.6934 - accuracy: 0.5107 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6937 - accuracy: 0.4904 - val_loss: 0.6932 - val_accuracy: 0.5045\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6933 - accuracy: 0.5043 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5033\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 9s 592ms/step - loss: 0.6934 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5089\n",
            "Model using learning rate of 0.04\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6939 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4955\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6930 - val_accuracy: 0.4922\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6933 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4955\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6933 - accuracy: 0.5085 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6938 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6934 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.4933\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 9s 600ms/step - loss: 0.6934 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.4978\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 9s 618ms/step - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6933 - accuracy: 0.5037 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6933 - accuracy: 0.5101 - val_loss: 0.6933 - val_accuracy: 0.5033\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6942 - accuracy: 0.4904 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 9s 605ms/step - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6932 - val_accuracy: 0.4967\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 9s 595ms/step - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.4944\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 9s 594ms/step - loss: 0.6936 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 9s 596ms/step - loss: 0.6934 - accuracy: 0.5027 - val_loss: 0.6931 - val_accuracy: 0.4944\n",
            "Model using learning rate of 0.05\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 9s 609ms/step - loss: 0.6932 - accuracy: 0.5224 - val_loss: 0.6956 - val_accuracy: 0.5033\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.6976 - accuracy: 0.4845 - val_loss: 0.6937 - val_accuracy: 0.5011\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 9s 597ms/step - loss: 0.6937 - accuracy: 0.5037 - val_loss: 0.6932 - val_accuracy: 0.4955\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.6938 - accuracy: 0.4856 - val_loss: 0.6934 - val_accuracy: 0.4978\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 9s 607ms/step - loss: 0.6940 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 9s 611ms/step - loss: 0.6940 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6933 - val_accuracy: 0.5056\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 9s 601ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4967\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 9s 613ms/step - loss: 0.6940 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5067\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 623ms/step - loss: 0.6933 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.4911\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 9s 610ms/step - loss: 0.6934 - accuracy: 0.4963 - val_loss: 0.6933 - val_accuracy: 0.4978\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 9s 618ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.6933 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5033\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 9s 611ms/step - loss: 0.6934 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.5033\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 9s 614ms/step - loss: 0.6934 - accuracy: 0.5112 - val_loss: 0.6935 - val_accuracy: 0.5033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rJtqLmjYX1w",
        "colab_type": "code",
        "outputId": "da76c5d1-05fd-4ec8-83f6-5d12348adada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "\n",
        "for i in range(7):\n",
        "\n",
        "    print(\"Model using\",optimizer[i],\"optimizer\")\n",
        "\n",
        "    model.compile(optimizer=optimizer[i], \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(\n",
        "              train_data_gen,\n",
        "              steps_per_epoch=total_train // batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=val_data_gen,\n",
        "              validation_steps=total_val // batch_size)\n",
        "    \n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Validation Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-559fbc13edeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mvalidation_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnum_cats_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnum_dogs_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dogs_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_cats_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ip33pHpNOVU",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the Conv3D and Conv2D Kernel\n",
        "https://stackoverflow.com/questions/60456336/weight-visualization-of-3d-convolutional-kernel\n",
        "\n",
        "Interesting Read that helps in visualizing the image after every layer - https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "\n",
        "Params of a layer -\n",
        "“(n* m * l+1)*k”\n",
        "- The filter size is “n*m”.\n",
        "- “l” feature maps as the input \n",
        "- “k” feature maps as output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVB8mbWfNCIF",
        "colab_type": "text"
      },
      "source": [
        "## Conv3D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96V691CNOeP",
        "colab_type": "code",
        "outputId": "5c3e41e7-a9b8-4c40-a1d8-f3eb8d8390d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "x = np.expand_dims(x,-1)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv3D(filters=2, input_shape=(224,224,3,1), kernel_size=(3,3,3), strides=(4,4,4), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv3D(filters=4, kernel_size=(4,4,4), strides=(1,1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv3D(filters=2, kernel_size=(4,4,4), strides=(1,1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= 4, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_4 (Conv3D)            (None, 56, 56, 1, 2)      56        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 56, 56, 1, 2)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 56, 56, 1, 4)      516       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 56, 56, 1, 4)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 56, 56, 1, 2)      514       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 56, 56, 1, 2)      0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               627300    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 630,103\n",
            "Trainable params: 630,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "1088/1088 [==============================] - 1s 1ms/step - loss: 2.8280 - acc: 0.0524 - val_loss: 2.8091 - val_acc: 0.0699\n",
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 698us/step - loss: 2.7028 - acc: 0.1847 - val_loss: 2.5356 - val_acc: 0.2279\n",
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 713us/step - loss: 2.2128 - acc: 0.2978 - val_loss: 2.1192 - val_acc: 0.2574\n",
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 713us/step - loss: 1.7553 - acc: 0.4237 - val_loss: 1.9295 - val_acc: 0.3640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3d006f668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-P_eKgE1yqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = model.layers[4].kernel\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19bc9c7b-f444-42da-9dcf-0eb5cb000dbd",
        "id": "g6rmQdDrNeYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3d_4 (3, 3, 3, 1, 2)\n",
            "conv3d_5 (4, 4, 4, 2, 4)\n",
            "conv3d_6 (4, 4, 4, 4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vQ3EuZqoQi",
        "colab_type": "text"
      },
      "source": [
        "### To print Color Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c5d4258-e392-4964-d7ad-19ca8525ba37",
        "id": "PP5fNoi1qnHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming channels\n",
        "\tincoming_channels = 4\n",
        "\tfor j in range(incoming_channels):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = pyplot.subplot(3, incoming_channels, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tpyplot.imshow(f[:, :, :,j], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAACeCAYAAACGoUnQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBM6yqw3qh3Q",
        "colab_type": "text"
      },
      "source": [
        "### To print Gray scale image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnYdGbqnZ3pg",
        "colab_type": "code",
        "outputId": "dd2d112f-229d-4299-ee37-22e8f2b63000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming channels\n",
        "\tincoming_channels = 4\n",
        "\tfor j in range(incoming_channels):\n",
        "\t\t# Range of Depth of the kernel .i.e. 3\n",
        "\t\tDepth = 4\n",
        "\t\tfor k in range(Depth):\n",
        "\t\t\t# specify subplot and turn of axis\n",
        "\t\t\tax = pyplot.subplot((outgoing_channels*Depth), incoming_channels, ix)\n",
        "\t\t\tax.set_xticks([])\n",
        "\t\t\tax.set_yticks([])\n",
        "\t\t\t# plot filter channel in grayscale\n",
        "\t\t\tpyplot.imshow(f[:, :, k,j], cmap='gray')\n",
        "\t\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAADrCAYAAAA40BDOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAWF0lEQVR4nO3daWxUZRcH8DPdW4Yp3YECrYGyyiZ7\nQHxBBJUlCERQURAFJYgYUAEhIcoOYoxBWUJURAQNmxJRIeIGgiwpStmp6YIU6LRQug2Uzn0/GD+d\n8xAu7YSeuf/fxz8nvU9uL6d37jP3eVyWZREAgDYh93oAAAB3A80LAFRC8wIAldC8AEAlNC8AUAnN\nCwBUCrNTHBUVZbndbpZHR0eL9SEhcm/My8sTc8uyXHbGE0xCQ0Ot8PBwljdp0kSsz87OFvPExESW\nlZaWks/nc+y5jY+Pt1JTU1leUFAg1hcVFYl5WlqamOfm5noty0q6+xHqZrp2W7duLdaHhcltR/p9\nXLt2jcrLy8Vr11bzcrvdNHjwYJZ37NhRrI+JiRHzV155hWXV1dV2hhJ0wsPDxUb13nvvifUjRowQ\n8+HDh7Nsx44dNRuccqmpqbRt2zaWL1y4UKxfv369mM+bN0/MJ0yYkHv3o9MvPDycmjZtyvI9e/aI\n9dIfWCKi+fPns2zNmjXG4+JjIwCohOYFACqheQGASraeeRUVFdFnn33G8q+++kqslx7iERE9++yz\nLNu5c6edoQSd6upqKi0tZfnMmTPFetOkR+PGjVmWmZlZs8Epd+rUKerWrRvLDx8+LNZfvHhRzEtK\nSmp1XMGiYcOGNHv2bJZ3797d1s9p0KABy65evWqsx50XAKiE5gUAKqF5AYBKaF4AoBKaFwCoZGu2\nsUGDBtSvXz+Wm2Zntm/fLuYvvfQSy3755Rc7Qwk6bdq0oW+//ZblsbGxYv2oUaPEXPqWfk5OTo3G\npl2LFi3o448/ZnlGRoZY/9xzz4m56VUtp8vNzaUXX3yR5WvXrhXrJ06cKOaFhYUsGzBggPG4uPMC\nAJXQvABAJTQvAFAJzQsAVELzAgCVbM02lpSUiDNi06dPF+unTZsm5n6/n2UrVqywM5Sgk52dLa7R\n9cYbb4j1prWSpPdMnT6TGxUVRS1btmT5E088IdavWrVKzIcMGVKr4woWXbp0oSNHjrBcWriUiMQe\nQkQUHx/PMtPChUS48wIApdC8AEAlNC8AUAnNCwBUQvMCAJVclmXdebHLVUhEgdopJc3J20fh3AZO\ngM8tEc7vPbl2bTUvAIC6Ah8bAUAlNC8AUAnNCwBUsvV6kMvlEh+QJSXJzypN2xZ16NCBZbm5ueT1\nel12xhNMPB6PlZyczHLTKxaXLl0Sc9NihE4/tykpKSyXtpoj+vd1IklurvGZtNfhD+zFvtCuXTux\nvqKiQsylxQh9Ph9VVVWJ166t5kVE5HLxn2Na1XPLli1ifvDgQZb17NnT7lCCSnJysvh+Z+/evcX6\nJUuWiPm7777Lsq5du9ZscMqlpKTQe++9x/J9+/aJ9a1atRLzF154wXSIQM5kqrVt2zYxl96DJJLf\nKT127Jjx5+NjIwCohOYFACqheQGASraeeTVs2FD83G/aPUh6AEdE9Pjjj7Ps3LlzdoYSdGJjY+mx\nxx5jeWRkpFg/bNgwMce55dxuNz300EMsf/3118X6K1euiHmLFi3E/Pz583c/uCAQERFBjRs3Zvne\nvXvF+pdffvmOf/bcuXON/4Y7LwBQCc0LAFRC8wIAldC8AEAlNC8AUMnWbGNMTAx17NiR/xDDDh9j\nxowRc2lHnLFjx9oZStDJzMwUXwW6fv26WG/amembb75hWXl5ec0Gp1xlZSX99ddfLD9z5oxYf+DA\nATG/ceOGmPfr1+/uBxcEmjRpQkuXLmX5s88+K9bfd999Yp6dnc0y0zknwp0XACiF5gUAKqF5AYBK\naF4AoBKaFwCoZGu2MSwsjKQF8w4dOiTWb9q0ScxPnz7NspAQZ/fRDh060J49e1heUFAg1ns8HjGX\nZni++OKLmg1OuYiICGrWrBnL165dK9b36tVLzI8ePVqr4woWxcXFtHnzZpZHR0eL9SNHjhRzafHC\na9euGY/r7I4BAGqheQGASmheAKASmhcAqITmBQAquSxL3LVILna5CilwO6WkOXz7KJzbAAnwuSXC\n+b0n166t5gUAUFfgYyMAqITmBQAq2fqGfWRkpBUTE8PypCT5477f7xfzyspKll27do3Ky8sduyV9\nYmKilZaWxvLjx4+L9fXr1xfzqqoqlvl8Prp586ajz216ejrLq6urxXrpDZDb8fl8Xic/8/J4PJbU\nA/Lz88V66RolIpKu/6KiIiotLRWvXduLEUoLr02aNEmsl5oUEVFWVhbLVq9ebWcoQSctLY3279/P\n8oyMDLH+wQcfFHOv18uygwcP1mxwyqWnp4tbzJsWeuzdu7eY37p1S8xPnz4dyMmAOi8pKYkWLVrE\ncmnRUSJzU5s3bx7L3n77beNx8bERAFRC8wIAldC8AEAlNC8AUMnWA3ufz0fnzp1jubRWEhFR27Zt\nxbxnz54s27Jli52hBJ3KykpxImP06NFi/YoVK8Rc+tJx165dazY45bKysqh169Ys//rrr8X6NWvW\niLlphrdDhw53P7gg4Pf7xcm5YcOGifWNGzcW86effpplK1euNB4Xd14AoBKaFwCohOYFACqheQGA\nSmheAKCS3XcbxfePpk+fLtZLs2dE8qzC5cuX7Qwl6Fy6dEmcQRw1apRYP3DgQDHv0aMHy06dOlWz\nwSkXGhoqzhSePXtWrDfNkm3cuLFWxxUs8vPz6fXXX2f50qVLxfrmzZuL+ZQpU1iWl5dnPC7uvABA\nJTQvAFAJzQsAVELzAgCV0LwAQCVbs41VVVV06dIlls+aNUusN83OLF++3M5hHaFevXrUrVs3ltt9\nn27Hjh0sM60Y6hQZGRn0ww8/sHzcuHFifZcuXcQ8Li6uVscVLPx+P5WWlrI8MTFRrDe9U7pu3TqW\nHTt2zHhc3HkBgEpoXgCgEpoXAKiE5gUAKqF5AYBKLmnlTWOxy1VIRIHa5inNyXvf4dwGToDPLRHO\n7z25dm01LwCAugIfGwFAJTQvAFDJ1jfso6OjLekb39HR0WK96SPpP//8wzK/30+WZbnsjCeYREVF\nWW63m+WmLelN2rdvz7Lc3Fzyer2OPbcej8dKSuKPTS5cuCDWt2nTRsyrqqrE/OTJk14nP/Nyu91W\nQkICy03nNyYmRswzMjJYlpeXZ7x2bTWv+vXri4vjSf9hiIhu3bol5rNnz2aZtHWSk7jdbhoyZAjL\n9+zZI9aHhoaK+cGDB1kmbTXnJElJSbR48WKWS9chEdHu3bvFvKCgQMw7deoUyMmAOi8hIYHeeust\nls+YMUOs79Spk5h/9913LOvbt6/xuPjYCAAqoXkBgEpoXgCgkq1nXlevXqUtW7awXHoYSkS0d+9e\nMf/0009ZNnPmTDtDCTpVVVXiJiSZmZli/aRJk8T88OHDLCsvL6/Z4JSLi4ujJ598kuVDhw4V6x97\n7DExHzt2bK2OK1iY+sKECRPEeo/HI+bSBjTSElz/wZ0XAKiE5gUAKqF5AYBKaF4AoBKaFwCoZGu2\nMTk5WdySe86cOWK96fWg8+fPs8z0yoBTZGRkiN8wfvrpp8X6kSNHivmCBQtYZvpmuFMUFBTQokWL\nWN6iRQuxXnrTgejf16yAq1evHvXo0YPlpo12TLPf4eHhto6LOy8AUAnNCwBUQvMCAJXQvABAJTQv\nAFDJ1myjz+ejU6dOsfyPP/4Q6/1+v5ivXr2aZYWFhXaGEnSysrKoVatWLF+zZo1Y369fPzGXZtBu\n3LhRs8EpFxcXRyNGjGC5adFB0zpfbdu2rdVxBYvi4mLasGEDy03X3bhx48R8/PjxLNu5c6fxuLjz\nAgCV0LwAQCU0LwBQCc0LAFRC8wIAlWztmI0t6QMH5zZwAnxuiXB+78m1a6t5AQDUFfjYCAAqoXkB\ngEpoXgCgkq3XgxITE6309HSWl5WVifVnz54V85AQ3jP9fj/5/X6XnfEEkwYNGliNGjVi+blz58T6\n+Ph4MS8pKWHZrVu3qLq62rHn1uPxWMnJySyvrq4W62/evCnmpm24/H6/18kP7MPDw63IyEiWx8bG\nivVer1fMTefdsizx2rXVvNLT08V9AX/77Tex/tFHHxXzqKgoll2/ft3OUIJOo0aNaP369SwfNGiQ\nWD969Ggx/+abb1h2u73vnCA5OZmWLVvG8tLSUrE+Pz9fzJcuXSrmZWVljl5iNTIyku6//36WDx48\nWKyX9m0lIvr7779tHRcfGwFAJTQvAFAJzQsAVLL1zKu4uJg2btzI8sWLF4v1FRUVYp6Tk8OyYcOG\n2RlK0CkrK6Nff/2V5SkpKWL9ypUrxXzGjBks+/zzz2s2OOUuXrxI8+fPZ/mxY8fE+uzsbDGfO3eu\nmLtcjp0LISKi1q1b08GDB8Vc0qdPHzGXds+S1mH7D+68AEAlNC8AUAnNCwBUQvMCAJXQvABAJVuz\njZWVlXTixAmW79u3T6w3zcJIs41OFxISQm63m+VhYfKvyLSU0fDhw1nm8/lqNjjlKisr6fjx4yyf\nOXOmWH/x4kUxN71O5HR///03jRkzhuXTp08X6035+++/z7Lw8HDjcXHnBQAqoXkBgEpoXgCgEpoX\nAKiE5gUAKtmabayoqBDfB5PW5yIi2rx5s5gfPXpU/NlOduHCBXrzzTdZnpsrLxV14cIFMZ8yZQrL\nTp48WbPBKde2bVv68ssvWf7OO++I9abZWWkhTvh3Lb7du3ez3PSOaF5enpj36tWLZbf7ZgLuvABA\nJTQvAFAJzQsAVELzAgCV0LwAQCWX6R05sdjlKiSiQO2Ukubk7aNwbgMnwOeWCOf3nly7tpoXAEBd\ngY+NAKASmhcAqITmBQAq2Xo9qH79+lZCQgLLTdumm175adeuHctycnLI6/U6dg+p6Ohoy+PxsLyy\nslKsT01NFXNpwbzLly9TSUmJY8+ty+WyQkL43+nOnTuL9aZzHhERIebHjh3zOvmBfUREhBUTE8Py\npCT5lJheebv//vtZlpeXZ+wLtppXQkICzZs3j+V79uwR6zMzM8X8yJEjLOvataudoQQdj8dDo0eP\nZnlWVpZYv2jRIjEvKSlh2dSpU2s2OOVCQkJI+s8lXYdE5nPerFkzMY+NjQ3kTGadFxMTQ3379mX5\n5MmTxfqXXnpJzPfv38+y3r17G4+Lj40AoBKaFwCohOYFACrZeublcrkoNDSU5efOnRPrf/75ZzGf\nOHEiy0wP8ZyiadOm9MEHH7BceoZFRPTxxx+L+c2bN1nm9LXS/H4/lZWVsbxfv35i/dixY8V8wIAB\ntTquYBEbG0uDBw9mufQM63b5pk2bWFZcXGw8Lu68AEAlNC8AUAnNCwBUQvMCAJXQvABAJVuzjQUF\nBeI3u8+cOSPWm/IOHTqw7IcffrAzlKCTm5srzsKaZnKlmRkieWem6Ojomg1OOZfLJb7as2HDBrH+\n+vXrYr5mzRoxHz58+N0PLgiEhISIO4gtWLBArDe9wdC/f3+Wvf/+++bj3uH4AADqFDQvAFAJzQsA\nVELzAgCV0LwAQCVbs43Jyck0ZcoUli9btkys7969u5h/8sknLHP6+3der5fWrVvH8pycHLHe5/OJ\n+ZIlS1hWUFBQo7Fp16xZM5o7dy7LTeelvLxczPv06VOr4woWhYWFtHr1apaPHz9erL906ZKY79u3\nj2Wm3wUR7rwAQCk0LwBQCc0LAFRC8wIAldC8AEAll2VZd17schUSUaCWPE1z8vZROLeBE+BzS4Tz\ne0+uXVvNCwCgrsDHRgBQCc0LAFSy9Q37iIgIS1q3JyUlRaw37QjUqFEjlhUVFVFZWZljt6RPTEy0\n0tPT77g+Ly9PzJs0aSLWmrZMd4LIyEjL7Xaz/OrVq6Z6Ma9fv76YFxYWep38zMvtdlsJCQksN62L\nlpycLOZSfUlJCVVUVIjXrq3mFRUVRT169GD5q6++KtabtvWeM2cOyxYuXGhnKEEnPT1d3H7e7/eL\n9dJrWkREy5cvZ5m0FbuTuN1uGjRoEMu3b98u1pv+iPzvf/8T89WrVzt6376EhATx//T3338v1k+b\nNk3MpQVJpVcJ/4OPjQCgEpoXAKiE5gUAKqF5AYBKth7YR0dHU/v27Vn+1FNPifWmtXh27NjBsmvX\nrtkZStC5efOmOINoWitt9+7dYv7AAw+wrLi4uGaDUy45OVmcVJLOFZF58ujGjRu1Oq5gkZ+fT6+9\n9hrLH3roIbG+adOmYi7tTGa6zolw5wUASqF5AYBKaF4AoBKaFwCohOYFACrZfbeRmjVrxvLJkyeL\n9atWrRLzXbt2saxr1652hhJ0zp8/T0OHDmW5tCsLEdHhw4fFfP369Szzer01G5xy1dXVVFpayvI3\n3nhDrJdegSMi2rp1a62OK1iEhYVRXFwcy03vgjZv3lzMGzZsyLLbXbu48wIAldC8AEAlNC8AUAnN\nCwBUQvMCAJVszTZWVlbSn3/+yfIZM2aI9c8884yYS+88nTlzxs5Qgk5YWBglJfHFOFu2bCnWHzp0\nSMxPnTrFslGjRtVscMp5PB565JFHWL5z506xfuDAgWK+du1aMZ86derdDy4IWJZFVVVVLDd92+Cn\nn34Sc2kVYNNqrES48wIApdC8AEAlNC8AUAnNCwBUQvMCAJVclmXdebHLVUhEgdrmKc3Je9/h3AZO\ngM8tEc7vPbl2bTUvAIC6Ah8bAUAlNC8AUMnWN+zDw8OtqKgolickJIj1FRUVYi6t81NYWEjXr193\n2RlPMAkNDbXCwvivIyRE/vsirZ9ERHTlyhWW+f1+8vv9jj234eHhVmRkJMula5mIKDU1Vcxv3bol\n5idPnvQ6+ZmX6dpt166dWC+9pUP073UqsSxLvHZtNa+oqCjq1KkTy5977jmxPjMzU8z79+/Pspkz\nZ9oZStAJCwujxo0bs7xevXpi/ciRI8X8ww8/ZJnTt5WLjIwUt+wzvXq1ZMkSMZf+MBARderUKZCT\nAXVeWFgYNWrUiOX79+8X66VFB4lu/yqQBB8bAUAlNC8AUAnNCwBUsvXMq6ysjPbt28fy559/Xqz/\n6KOPxFx6kC9t9e0k8fHxNGbMGJafOHFCrP/xxx/FXNrEw7T0i1NYliU+bC8qKhLrpec3REQpKSm1\nOq5g4fF4aMCAASw3PWstKSkR8wMHDrBswoQJxuPizgsAVELzAgCV0LwAQCU0LwBQCc0LAFSyNdsY\nHR1NrVq1Ynnnzp3F+ieffFLMH374YZaZZn6cIjU1lRYvXszy33//XayfOHGimJeVlbHM9NqFU8TF\nxYmbkMyaNUusz8jIEPPvvvuuVscVLOLi4sT/6/n5+WL98uXLxVyqv3z5svG4uPMCAJXQvABAJTQv\nAFAJzQsAVELzAgCVbM02xsfHi7MKPXr0EOvnzJkj5tOnT2eZz+ezM5SgU1lZKS7StmnTJrF+8uTJ\nYu70reclCQkJNH78eJbHx8eL9Q0aNBDzXbt21eawgsaFCxfE9fiuXr0q1mdlZYn51q1bWXbkyBHj\ncXHnBQAqoXkBgEpoXgCgEpoXAKiE5gUAKtnaMRtb0gcOzm3gBPjcEuH83pNr11bzAgCoK/CxEQBU\nQvMCAJXQvABAJTQvAFAJzQsAVELzAgCV0LwAQCU0LwBQCc0LAFT6PxOqsLqyuQ7uAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4s_VHK_PNWCO"
      },
      "source": [
        "## Conv2D Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a13d4066-6386-4c6c-86c0-0d1d27415c05",
        "id": "1G6Jyc2_NP93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# (1) Importing dependency\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "    \n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "    \n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "    \n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=2, input_shape=(224,224,3), kernel_size=(3,3), strides=(4,4), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=4, kernel_size=(3,3), strides=(1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "    \n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=2, kernel_size=(3,3), strides=(1,1), padding='Same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epoch_gradient = []\n",
        "\n",
        "def get_gradient_func(model):\n",
        "    grads = K.gradients(model.total_loss, model.trainable_weights)\n",
        "    inputs = model.model._feed_inputs + model.model._feed_targets + model.model._feed_sample_weights\n",
        "    func = K.function(inputs, grads)\n",
        "    return func\n",
        "\n",
        "# Define the Required Callback Function\n",
        "class GradientCalcCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      get_gradient = get_gradient_func(model)\n",
        "      grads = get_gradient([x, y, np.ones(len(y))])\n",
        "      epoch_gradient.append(grads)\n",
        "    \n",
        "epoch = 4\n",
        "\n",
        "model.fit(x, y, batch_size=64, epochs= epoch, verbose=1, validation_split=0.2, shuffle=True, callbacks=[GradientCalcCallback()])\n",
        "    \n",
        "# (7) Convert to a 2 dimensiaonal array of (epoch, gradients) type\n",
        "gradient = np.asarray(epoch_gradient)\n",
        "print(\"Total number of epochs run:\", epoch)\n",
        "print(\"Gradient Array has the shape:\",gradient.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Succesfully downloaded', '17flowers.tgz', 60270631, 'bytes.')\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 2)         56        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 56, 56, 2)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 4)         76        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 56, 56, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 56, 56, 2)         74        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 56, 56, 2)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               627300    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 629,223\n",
            "Trainable params: 629,223\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1088/1088 [==============================] - 14s 13ms/step - loss: 2.8319 - acc: 0.0533 - val_loss: 2.8246 - val_acc: 0.0662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/4\n",
            "1088/1088 [==============================] - 1s 567us/step - loss: 2.7434 - acc: 0.2426 - val_loss: 2.7336 - val_acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/4\n",
            "1088/1088 [==============================] - 1s 579us/step - loss: 2.2730 - acc: 0.4384 - val_loss: 2.4033 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/4\n",
            "1088/1088 [==============================] - 1s 555us/step - loss: 1.3170 - acc: 0.6884 - val_loss: 2.2917 - val_acc: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of epochs run: 4\n",
            "Gradient Array has the shape: (4, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSYQQEW9vDj",
        "colab_type": "code",
        "outputId": "8cde4e2a-88f5-4416-9858-8523bfcfdb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import numpy as np\n",
        "x = model.layers[4].kernel\n",
        "gr = tf.get_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    conv1_kernel_val = gr.get_tensor_by_name('conv1/kernel:0').eval()\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.07628679  0.31725606]\n",
            "   [-0.29280648  0.10707554]\n",
            "   [-0.1409379  -0.14117424]\n",
            "   [-0.04934797 -0.17769067]]\n",
            "\n",
            "  [[-0.22811215  0.2088342 ]\n",
            "   [ 0.12845007 -0.10234594]\n",
            "   [ 0.29518536  0.22939327]\n",
            "   [-0.102254   -0.16633217]]\n",
            "\n",
            "  [[ 0.23566589  0.06252447]\n",
            "   [ 0.12485743 -0.2845057 ]\n",
            "   [ 0.17910227 -0.09911792]\n",
            "   [ 0.09142479 -0.17152238]]]\n",
            "\n",
            "\n",
            " [[[-0.23811015 -0.16541886]\n",
            "   [-0.33333215 -0.13665256]\n",
            "   [ 0.09643212  0.07662854]\n",
            "   [ 0.05305314 -0.23696613]]\n",
            "\n",
            "  [[ 0.0339109   0.16784325]\n",
            "   [-0.04169551 -0.0482665 ]\n",
            "   [ 0.08657351  0.12973014]\n",
            "   [ 0.05880824  0.05947757]]\n",
            "\n",
            "  [[ 0.11017862 -0.14729127]\n",
            "   [ 0.2464253  -0.19549426]\n",
            "   [-0.2609269   0.25060275]\n",
            "   [-0.26333413 -0.13276713]]]\n",
            "\n",
            "\n",
            " [[[-0.06246376  0.0363799 ]\n",
            "   [-0.02949128  0.32878068]\n",
            "   [ 0.15073076 -0.30452785]\n",
            "   [-0.24252614 -0.09735529]]\n",
            "\n",
            "  [[ 0.23945466  0.01562142]\n",
            "   [ 0.22383246  0.09923801]\n",
            "   [-0.2536789  -0.09304142]\n",
            "   [-0.22144732  0.3057051 ]]\n",
            "\n",
            "  [[ 0.05687061 -0.2811746 ]\n",
            "   [-0.2436115  -0.1616823 ]\n",
            "   [ 0.06709924 -0.24549572]\n",
            "   [ 0.04901949 -0.06542149]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a22d8ba-a297-43c2-b58a-36280e0b695c",
        "id": "lQneZbNRNP98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' in layer.name:\n",
        "\t  # get filter weights\n",
        "\t  filters, biases = layer.get_weights()\n",
        "\t  print(layer.name, filters.shape)\n",
        "\t \n",
        "#print(filters[:,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_4 (3, 3, 3, 2)\n",
            "conv2d_5 (3, 3, 2, 4)\n",
            "conv2d_6 (3, 3, 4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d82d2727-0fe7-4a83-cf25-de643d609776",
        "id": "xnNFITm2NP-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# # summarize filter shapes\n",
        "# for layer in model.layers:\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' in layer.name:\n",
        "# \t  # get filter weights\n",
        "# \t  filters, biases = layer.get_weights()\n",
        "   \n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[4].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing filters\n",
        "n_filters, ix = 2, 1 \n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t#print(f)\n",
        "\t# plot each channel separately\n",
        "\t# Range of incoming filters\n",
        "\tfor j in range(4):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = pyplot.subplot(3, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
        "\t  #print(f[:, :, j])\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAADrCAYAAADwvPoYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjw2f-GyThTk",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Reduce_max\n",
        "https://stackoverflow.com/questions/60277848/tensorflow-reduce-max-for-different-dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OCxARrThgJ",
        "colab_type": "code",
        "outputId": "d9069138-1565-411e-d052-fab527b16df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a Ragged Tensor of variable length\n",
        "rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
        "print(\"Ragged Tensor:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Convert to Tensor to have same length\n",
        "rt = rt.to_tensor()\n",
        "print(\"Tensor of same length:\",\"\\n\",rt,\"\\n\")\n",
        "\n",
        "# Apply reduce_max to get the max value along axis=1\n",
        "rt = tf.reduce_max(rt, axis=1)\n",
        "print(\"Reduce Max Tensor:\",\"\\n\",rt,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ragged Tensor: \n",
            " <tf.RaggedTensor [[9, 8, 7], [], [6, 5], [4]]> \n",
            "\n",
            "Tensor of same length: \n",
            " tf.Tensor(\n",
            "[[9 8 7]\n",
            " [0 0 0]\n",
            " [6 5 0]\n",
            " [4 0 0]], shape=(4, 3), dtype=int32) \n",
            "\n",
            "Reduce Max Tensor: \n",
            " tf.Tensor([9 0 6 4], shape=(4,), dtype=int32) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzPFRXDg4Di0",
        "colab_type": "text"
      },
      "source": [
        "# Save and Load Model\n",
        "https://stackoverflow.com/questions/60198878/proper-way-to-save-model-in-keras\n",
        "\n",
        "Good Article for Load and Save in Keras - https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kEKp1C76nw6",
        "colab_type": "text"
      },
      "source": [
        "## Build and Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeSykV1cqtSm",
        "colab_type": "code",
        "outputId": "6ba6877c-33f5-4a33-e2c3-4be5b2f7e936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "acc: 77.08%\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYVNZs-6ujU",
        "colab_type": "text"
      },
      "source": [
        "## Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7iWQwy5KP8",
        "colab_type": "code",
        "outputId": "eb78d817-a764-4b1a-9af3-68a3ea75f74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# summarize model.\n",
        "model.summary()\n",
        "\n",
        "# load dataset\n",
        "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "acc: 77.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fARWvSOS0xo",
        "colab_type": "text"
      },
      "source": [
        "# Feed Dict Example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYzDEyNw-qYu",
        "colab_type": "code",
        "outputId": "8adf273d-edbd-4d44-8412-f382940ad0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = x * 42\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  train_accuracy = y.eval(session=sess,feed_dict={x: (2, 4)})\n",
        "  print(train_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 84. 168.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvdRR4EyO6-",
        "colab_type": "text"
      },
      "source": [
        "# Dealing with Session Error Explained\n",
        "https://stackoverflow.com/questions/61006702/cannot-use-the-given-session-to-evaluate-tensor-the-tensors-graph-is-different"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1v2ptOIvyc",
        "colab_type": "text"
      },
      "source": [
        "## Simple Error and Fix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybmrlAanGFK",
        "colab_type": "code",
        "outputId": "765073db-13b0-4c71-b4fe-a04db6b5d3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "s = tf.Session(graph=g)\n",
        "with s.as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                  # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval()) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-56f6710c85ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5396\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5399\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhZjS6zEqHYg",
        "colab_type": "code",
        "outputId": "cdbf2509-90ca-4d6b-f90e-ce9741d8a828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "  y = tf.constant(2.0) # y is created in graph g\n",
        "\n",
        "s = tf.Session(graph=g)\n",
        "with s.as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  print(y.eval()) # y was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssuiDS6xJxkn",
        "colab_type": "text"
      },
      "source": [
        "## Error and Fix Explained in Detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvI2gcXuUZ_A",
        "colab_type": "text"
      },
      "source": [
        "### Error with default session and using variable created in another graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c68196dd-39c9-4e4f-b074-9630c2d3d207",
        "id": "_MjHucq4TEJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session().as_default() as sess:\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  \n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                  # which is tied to graph g, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f35cb204cf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, and is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0;31m# default session, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x was created in graph g and it is evaluated in session s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# which is tied to graph g, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyAx1Zp1Us4F",
        "colab_type": "text"
      },
      "source": [
        "### Error with graph session as default and using variable created in default graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og4q09R-GHlL",
        "colab_type": "code",
        "outputId": "08030e4e-bd58-4126-bad6-51e9a8e86096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval()) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6b8b687c5178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5396\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5399\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ecy2vH3X6gU"
      },
      "source": [
        "### Error with graph session as default and using variable created in default graph and also session=sess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6281a25e-0b0e-48a1-f713-0dc083f4d347",
        "id": "EoznhA2nX6gW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval(session=sess)) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, but it is evaluated in\n",
        "                  # session s which is tied to graph g => ERROR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-83809aa4e485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0;31m# which is tied to graph g, so everything is ok.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y is created in TensorFlow's default graph!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y was created in TF's default graph, but it is evaluated in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m# session s which is tied to graph g => ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0zJAoNLU7pu",
        "colab_type": "text"
      },
      "source": [
        "### Fix with default session and variable not assigned to any graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "42c47425-d833-4f5b-f9f3-196dbf8bef18",
        "id": "5Nx158TXTCT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(1.0)  # x is in not assigned to any graph\n",
        "\n",
        "with tf.Session().as_default() as sess:\n",
        "  y = tf.constant(2.0) # y is created in TensorFlow's default graph!!!\n",
        "  print(y.eval(session=sess)) # y was created in TF's default graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  \n",
        "  print(x.eval(session=sess)) # x not assigned to any graph, and is evaluated in\n",
        "                  # default session, so everything is ok.  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1qthgoVMUL",
        "colab_type": "text"
      },
      "source": [
        "### The best fix is to cleanly separate the construction phase and the execution phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UftJHIz3VM4d",
        "colab_type": "code",
        "outputId": "40824b97-fc1e-4135-ada3-a2f657975046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  x = tf.constant(1.0)  # x is created in graph g\n",
        "  y = tf.constant(2.0) # y is created in graph g\n",
        "\n",
        "with tf.Session(graph=g).as_default() as sess:\n",
        "  print(x.eval()) # x was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok.\n",
        "  print(y.eval()) # y was created in graph g and it is evaluated in session s\n",
        "                         # which is tied to graph g, so everything is ok."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x-CnHNIH0r1",
        "colab_type": "text"
      },
      "source": [
        "# softmax and log_softmax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odVe5AwJH023",
        "colab_type": "code",
        "outputId": "5624739e-54a9-4bf0-fe45-ffe44020d124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "x = tf.nn.softmax([0.12345,0.3256,0.2356,-0.3256,0.13562])\n",
        "y = -tf.nn.log_softmax([0.12345,0.3256,0.2356,-0.3256,0.13562])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "   print(x.eval())\n",
        "   print(y.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20027274 0.24514017 0.22404124 0.12782091 0.20272495]\n",
            "[1.6080751 1.4059252 1.4959252 2.057125  1.5959052]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDqxUBulbZua",
        "colab_type": "text"
      },
      "source": [
        "# Tensor to array\n",
        "https://stackoverflow.com/questions/59875172/typeerror-when-trying-to-use-earlystopping-with-f1-metric-as-stopping-criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syOHTseMZN5F",
        "colab_type": "code",
        "outputId": "9adb1ba5-0d4e-443a-e71b-468f7661ec19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "print(tf.__version__)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.constant([1,2,3,4,5,6])\n",
        "print(\"Type of x:\",x)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  y = np.array(x.eval())\n",
        "  print(\"Type of y:\",y.shape,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "Type of x: Tensor(\"Const_24:0\", shape=(6,), dtype=int32)\n",
            "Type of y: (6,) [1 2 3 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yg9AIIvdD7b",
        "colab_type": "text"
      },
      "source": [
        "# Fit_generator simple example\n",
        "https://stackoverflow.com/questions/59417210/keras-losing-axis-with-brightness-range-during-image-augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f3161cd1-305c-4a42-dcab-817db4a35bad",
        "id": "iJ2O5F28dF3i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,brightness_range=[0.5,1.5]) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", \n",
        "          loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "          train_data_gen,\n",
        "          steps_per_epoch=total_train // batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=val_data_gen,\n",
        "          validation_steps=total_val // batch_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From <ipython-input-2-2b8537e7d5b3>:74: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/15\n",
            "15/15 [==============================] - 9s 591ms/step - loss: 1.0527 - accuracy: 0.5010 - val_loss: 0.6918 - val_accuracy: 0.5089\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 9s 609ms/step - loss: 0.6790 - accuracy: 0.5337 - val_loss: 0.6473 - val_accuracy: 0.5647\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 9s 610ms/step - loss: 0.6340 - accuracy: 0.5983 - val_loss: 0.6208 - val_accuracy: 0.6172\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 9s 609ms/step - loss: 0.5899 - accuracy: 0.6464 - val_loss: 0.5938 - val_accuracy: 0.6585\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 9s 599ms/step - loss: 0.5182 - accuracy: 0.7286 - val_loss: 0.6165 - val_accuracy: 0.7042\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.4697 - accuracy: 0.7682 - val_loss: 0.5853 - val_accuracy: 0.7109\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.4393 - accuracy: 0.7746 - val_loss: 0.5826 - val_accuracy: 0.7132\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.4115 - accuracy: 0.7895 - val_loss: 0.6602 - val_accuracy: 0.7042\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 9s 598ms/step - loss: 0.3831 - accuracy: 0.8162 - val_loss: 0.6254 - val_accuracy: 0.7076\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 9s 601ms/step - loss: 0.3151 - accuracy: 0.8531 - val_loss: 0.5924 - val_accuracy: 0.7098\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 9s 611ms/step - loss: 0.2904 - accuracy: 0.8632 - val_loss: 0.6664 - val_accuracy: 0.6964\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 9s 604ms/step - loss: 0.2524 - accuracy: 0.8921 - val_loss: 0.7111 - val_accuracy: 0.6752\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 9s 592ms/step - loss: 0.2143 - accuracy: 0.9081 - val_loss: 0.7246 - val_accuracy: 0.6953\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 9s 599ms/step - loss: 0.1829 - accuracy: 0.9284 - val_loss: 0.7323 - val_accuracy: 0.7221\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 9s 598ms/step - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.8435 - val_accuracy: 0.6998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwhjPAkYvkBV",
        "colab_type": "text"
      },
      "source": [
        "# Convert Functional Model to Sequential and Vice Versa\n",
        "https://stackoverflow.com/questions/61130836/convert-functional-model-to-sequential-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWjlUrHl0Nr1",
        "colab_type": "text"
      },
      "source": [
        "## User Code has one functional model and another sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbKDJJn5vka7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "#load in data using imagedatagenreator\n",
        "input_img = Input(shape=(128, 128,3))\n",
        "\n",
        "x = Convolution2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (8, 4, 4) i.e. 128-dimensional\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Convolution2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Convolution2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "#compile and run\n",
        "\n",
        "##save weights and and model start conv network with these weights\n",
        "encoder = Model(input_img, encoded)\n",
        "encoder.save('Encoded.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-lHnunPzC4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "048645df-a065-4535-ae2e-fb70b895365f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#load in data using imagedatagenreator\n",
        "model = load_model('Encoded.h5')\n",
        "model.summary()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64,(3,3), input_shape=(424,424,3), activation='relu'))#3x3 is default\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "#model.add(Dropout(.1))#test\n",
        "model.add(Dense(32, activation='relu'))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(.3))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Flatten(input_shape=(424,424,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 128, 128, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 8)         0         \n",
            "=================================================================\n",
            "Total params: 2,192\n",
            "Trainable params: 2,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 422, 422, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 140, 140, 64)      0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 140, 140, 32)      2080      \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 138, 138, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 46, 46, 64)        4160      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 25090     \n",
            "=================================================================\n",
            "Total params: 138,722\n",
            "Trainable params: 113,634\n",
            "Non-trainable params: 25,088\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9_kieW013Bh"
      },
      "source": [
        "## Convert functional model to sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dFclXAGr1u3Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2aad0bd2-ed53-41c4-dbeb-a978e21b6d89"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "# Create the Sequential Model\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(16, (3, 3), input_shape=(424,424,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Save the Model and Architecture\n",
        "model.save('Encoded.h5')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 53, 53, 8)         0         \n",
            "=================================================================\n",
            "Total params: 2,192\n",
            "Trainable params: 2,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0b3bd82b-5ec8-4264-a6a0-ab73bf2b647c",
        "id": "PIp5DMAb1u3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the previoulsy saved enocdermodel \n",
        "model = load_model('Encoded.h5')\n",
        "\n",
        "# Add the additonal layers \n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#3x3 is default\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "#model.add(Dropout(.1))#test\n",
        "model.add(Dense(32, activation='relu'))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(.3))#test\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))#input_shape=(424,424,3)\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Flatten(input_shape=(424,424,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Model summary \n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 53, 53, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 51, 51, 64)        4672      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 17, 17, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 5, 5, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 68,914\n",
            "Trainable params: 68,786\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XjDDrht_4wca"
      },
      "source": [
        "## Convert sequential model to functional model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "283hoBLI49D4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e1e91253-5ea9-469b-b632-12ffa2414a2f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "#load in data using imagedatagenreator\n",
        "input_img = Input(shape=(424,424,3))\n",
        "\n",
        "x = Convolution2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Convolution2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "##save weights and and model start conv network with these weights\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# Model Summary\n",
        "encoder.summary()\n",
        "\n",
        "encoder.save('Encoded.h5')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 424, 424, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 53, 53, 8)         0         \n",
            "=================================================================\n",
            "Total params: 2,192\n",
            "Trainable params: 2,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e09aee33-71c0-4197-8acc-e2635825bd46",
        "id": "tlicujIp4wcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers, models, applications, Input, Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the previoulsy saved enocdermodel \n",
        "load_model('Encoded.h5')\n",
        "\n",
        "# Add the additonal layers \n",
        "x = Convolution2D(64,(3,3), activation='relu')(encoded)#3x3 is default\n",
        "x = MaxPooling2D(pool_size=(3,3))(x)\n",
        "#model.add(Dropout(.1))#test\n",
        "x = Dense(32, activation='relu')(x)#test\n",
        "x = Conv2D(64,(3,3), activation='relu')(x)#input_shape=(424,424,3)\n",
        "x = MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(.3)(x)#test\n",
        "x = Conv2D(64,(3,3), activation='relu')(x)#input_shape=(424,424,3)\n",
        "x = MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = Dropout(.3)(x)\n",
        "x = Flatten(input_shape=(424,424,3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "##save weights and and model start conv network with these weights\n",
        "model = Model(input_img, output)\n",
        "\n",
        "# Model summary \n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 424, 424, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 424, 424, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 212, 212, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 212, 212, 8)       1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 106, 106, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 106, 106, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 53, 53, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 51, 51, 64)        4672      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 17, 17, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 5, 5, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 68,914\n",
            "Trainable params: 68,786\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}